<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>grpc 的一些踩坑经验 | W41ter’s Bistro</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="grpc 的一些踩坑经验" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="最近的工作需要对某个系统的 RPC 部分做优化。这个系统有多个组件，分别使用不同语言编写，此次我需要优化的组件分别由 java 和 c++ 编写，java 使用 grpc 访问使用 brpc 的 c++ 服务。 该系统在编写之初为了省事，将 c++ 服务放在四层负载均衡 VIP 之后，以利用其提供的负载均衡、探活熔断的能力。这种图省事的操作为系统留下了几个隐患： 如果 java 组件部署数量不够，那么无法保证通过 VIP 建立的连接数能够均衡分布到每个 RS 如果不重启 java 组件，那么新加入的 RS 无法获得新连接。 一些尝试 刚开始接受这个任务时，我的思路主要集中在能否通过简单改造 rpc 来解决前面两个问题。 针对第一个问题，我的初步思路是能否为每个 VIP 提供一些 tag，这样 grpc 在建立 channel 时，可以为某个 IP 建立多个连接，并使用 round-robin 的方式提供负载均衡。 我首先尝试编写一个 Resolver，它在 DnsResolver 的基础上，为每个 EquivalentAddressGroup 增加一个描述 tag 的 Attribute。不过很快我就发现，grpc 默认提供的 RoundRobinLoadBalancer 会清除所有通过 Resolver 返回的 Attribute，因此这种办法是不可行的。 那么进一步就是增加自定义的 RoundRobinLoadBalaner，去掉清除 tag 的逻辑。不过我并未按照这个方案实施，主要是它太复杂，且只解决了一个问题，难以说服项目负责人接受。 其他视角的解决办法 改造 rpc 的方案不行后，我将目光放在了修改使用 rpc 的方式上，很快我就发现从这里入手会简单许多。 在目前的代码里，java 服务会建立一个 ManagedChannel，并通过该 channel 访问 C++ 服务。其中 ManagedChannel 是通过 NettyChannelBuilder 创建的，其底层会为每个 Resolver 返回的 EquivalentAddressGroup 创建一个 NettyTransport（也就是 socket）。而阿里云、腾讯云提供的 VIP 只有一个 IP 地址，因此每个 java 服务最终只会创建一条到 C++ 服务的 socket。显然，只需要创建多个 ManagedChannel，就能建立多条 socket；再通过模拟 round-robin 算法，每次发起 rpc 前选择一个 channel，就能在很大程度上保证每个 RS 接收到的 rpc 请求是均衡的。 当然这只解决了第一个问题。VIP 机制下没有渠道可以获取到 RS 是否发生变更，因此只能从连接本身入手。一种方式是使用短连接，但它在每次访问时都需要创建一个 ManagedChannel，且并发数受限于可用端口数量，因此不是最优选择；另一种方式是为每个连接设置一段时间，超过时间后回收并重建连接，这样就保证在一段时间后就能与新加入的 RS 建立连接。 我选择使用第二种方式，为每个连接设置一段存活时间，超过时间后回收连接。grpc 协议提供了类似的支持：A9-server-side-conn-mgt，它允许在 server 端配置每个连接的 MAX_CONNECTION_AGE，超过时间后 server 端会给 client 发送 GOAWAY 通知 client 关闭该连接。当然，这个协议只有 grpc server 才支持，而我们的 C++ 服务使用的 brpc 并没有提供类似的机制，所以我们需要自己提供类似的功能。该功能实现也比较简单，每次建立连接时，会在某个时间范围内随机选择一个值作为 deadline；每次发送 rpc 请求时，先判断 deadline 是否已经到达，如果超过了 deadline，那么会调用 ManagedChannel.terminate() 并重建连接。 Connection refused 问题 在实施上述方案的过程中，我们还碰到了另一个 grpc 的问题：尽管后端 C++ 服务已经启动，java client 仍然会不时抛出 Connection refused 异常。 通过分析代码，我们发现 grpc netty 实现中，如果碰到了连接异常，会调用 InternalSubChannel::scheduleBackoff。它主要做了两件事情： 在一段时间后，调用 InternalSubChannel::startNewTransport 重新建立连接。 调用 gotoState(ConnectivityStateInfo.forTransactionFailure(status))，将错误信息保存到 subchannel picker 中。 而 ManagedChannelImpl::ChannelTransportProvider::get() 中会读取 subchannel picker 中保存的状态，如果对应的状态满足 isWaitForReady() == false，那么直接返回 FaillingClientTransport，最终抛出 Connection refused 异常。 也就是说，在 backoff 期间，所有在该 channel 上发起的 rpc 请求都会抛出 Connection refused 异常。而不幸的是：InternalChannel.backoffPolicy 是在 AbstractManagedChannelImplBuilder 中通过 new ExponentialBackoffPolicy.Provider() 设置的，没有提供自定义选项；而 ExponentialBackoffPolicy 中时间相关参数为常数，没有提供可修改选项，最大时间间隔为两分钟。显然，grpc java 的作者希望通过 backoff 来减小对 server 重连的压力，而我们则希望尽可能减少服务不可用时间。 幸运的是 ManagedChannel 提供了一个方法可以获取当前 channel 的状态。我们通过使用该接口，在每次请求前获取当前 channel 状态，如果是 TRANSIENT_FAILURE， 则关闭 channel 并重建。" />
<meta property="og:description" content="最近的工作需要对某个系统的 RPC 部分做优化。这个系统有多个组件，分别使用不同语言编写，此次我需要优化的组件分别由 java 和 c++ 编写，java 使用 grpc 访问使用 brpc 的 c++ 服务。 该系统在编写之初为了省事，将 c++ 服务放在四层负载均衡 VIP 之后，以利用其提供的负载均衡、探活熔断的能力。这种图省事的操作为系统留下了几个隐患： 如果 java 组件部署数量不够，那么无法保证通过 VIP 建立的连接数能够均衡分布到每个 RS 如果不重启 java 组件，那么新加入的 RS 无法获得新连接。 一些尝试 刚开始接受这个任务时，我的思路主要集中在能否通过简单改造 rpc 来解决前面两个问题。 针对第一个问题，我的初步思路是能否为每个 VIP 提供一些 tag，这样 grpc 在建立 channel 时，可以为某个 IP 建立多个连接，并使用 round-robin 的方式提供负载均衡。 我首先尝试编写一个 Resolver，它在 DnsResolver 的基础上，为每个 EquivalentAddressGroup 增加一个描述 tag 的 Attribute。不过很快我就发现，grpc 默认提供的 RoundRobinLoadBalancer 会清除所有通过 Resolver 返回的 Attribute，因此这种办法是不可行的。 那么进一步就是增加自定义的 RoundRobinLoadBalaner，去掉清除 tag 的逻辑。不过我并未按照这个方案实施，主要是它太复杂，且只解决了一个问题，难以说服项目负责人接受。 其他视角的解决办法 改造 rpc 的方案不行后，我将目光放在了修改使用 rpc 的方式上，很快我就发现从这里入手会简单许多。 在目前的代码里，java 服务会建立一个 ManagedChannel，并通过该 channel 访问 C++ 服务。其中 ManagedChannel 是通过 NettyChannelBuilder 创建的，其底层会为每个 Resolver 返回的 EquivalentAddressGroup 创建一个 NettyTransport（也就是 socket）。而阿里云、腾讯云提供的 VIP 只有一个 IP 地址，因此每个 java 服务最终只会创建一条到 C++ 服务的 socket。显然，只需要创建多个 ManagedChannel，就能建立多条 socket；再通过模拟 round-robin 算法，每次发起 rpc 前选择一个 channel，就能在很大程度上保证每个 RS 接收到的 rpc 请求是均衡的。 当然这只解决了第一个问题。VIP 机制下没有渠道可以获取到 RS 是否发生变更，因此只能从连接本身入手。一种方式是使用短连接，但它在每次访问时都需要创建一个 ManagedChannel，且并发数受限于可用端口数量，因此不是最优选择；另一种方式是为每个连接设置一段时间，超过时间后回收并重建连接，这样就保证在一段时间后就能与新加入的 RS 建立连接。 我选择使用第二种方式，为每个连接设置一段存活时间，超过时间后回收连接。grpc 协议提供了类似的支持：A9-server-side-conn-mgt，它允许在 server 端配置每个连接的 MAX_CONNECTION_AGE，超过时间后 server 端会给 client 发送 GOAWAY 通知 client 关闭该连接。当然，这个协议只有 grpc server 才支持，而我们的 C++ 服务使用的 brpc 并没有提供类似的机制，所以我们需要自己提供类似的功能。该功能实现也比较简单，每次建立连接时，会在某个时间范围内随机选择一个值作为 deadline；每次发送 rpc 请求时，先判断 deadline 是否已经到达，如果超过了 deadline，那么会调用 ManagedChannel.terminate() 并重建连接。 Connection refused 问题 在实施上述方案的过程中，我们还碰到了另一个 grpc 的问题：尽管后端 C++ 服务已经启动，java client 仍然会不时抛出 Connection refused 异常。 通过分析代码，我们发现 grpc netty 实现中，如果碰到了连接异常，会调用 InternalSubChannel::scheduleBackoff。它主要做了两件事情： 在一段时间后，调用 InternalSubChannel::startNewTransport 重新建立连接。 调用 gotoState(ConnectivityStateInfo.forTransactionFailure(status))，将错误信息保存到 subchannel picker 中。 而 ManagedChannelImpl::ChannelTransportProvider::get() 中会读取 subchannel picker 中保存的状态，如果对应的状态满足 isWaitForReady() == false，那么直接返回 FaillingClientTransport，最终抛出 Connection refused 异常。 也就是说，在 backoff 期间，所有在该 channel 上发起的 rpc 请求都会抛出 Connection refused 异常。而不幸的是：InternalChannel.backoffPolicy 是在 AbstractManagedChannelImplBuilder 中通过 new ExponentialBackoffPolicy.Provider() 设置的，没有提供自定义选项；而 ExponentialBackoffPolicy 中时间相关参数为常数，没有提供可修改选项，最大时间间隔为两分钟。显然，grpc java 的作者希望通过 backoff 来减小对 server 重连的压力，而我们则希望尽可能减少服务不可用时间。 幸运的是 ManagedChannel 提供了一个方法可以获取当前 channel 的状态。我们通过使用该接口，在每次请求前获取当前 channel 状态，如果是 TRANSIENT_FAILURE， 则关闭 channel 并重建。" />
<link rel="canonical" href="/2023/07/09/grpc-and-vip.html" />
<meta property="og:url" content="/2023/07/09/grpc-and-vip.html" />
<meta property="og:site_name" content="W41ter’s Bistro" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-09T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="grpc 的一些踩坑经验" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-07-09T00:00:00+08:00","datePublished":"2023-07-09T00:00:00+08:00","description":"最近的工作需要对某个系统的 RPC 部分做优化。这个系统有多个组件，分别使用不同语言编写，此次我需要优化的组件分别由 java 和 c++ 编写，java 使用 grpc 访问使用 brpc 的 c++ 服务。 该系统在编写之初为了省事，将 c++ 服务放在四层负载均衡 VIP 之后，以利用其提供的负载均衡、探活熔断的能力。这种图省事的操作为系统留下了几个隐患： 如果 java 组件部署数量不够，那么无法保证通过 VIP 建立的连接数能够均衡分布到每个 RS 如果不重启 java 组件，那么新加入的 RS 无法获得新连接。 一些尝试 刚开始接受这个任务时，我的思路主要集中在能否通过简单改造 rpc 来解决前面两个问题。 针对第一个问题，我的初步思路是能否为每个 VIP 提供一些 tag，这样 grpc 在建立 channel 时，可以为某个 IP 建立多个连接，并使用 round-robin 的方式提供负载均衡。 我首先尝试编写一个 Resolver，它在 DnsResolver 的基础上，为每个 EquivalentAddressGroup 增加一个描述 tag 的 Attribute。不过很快我就发现，grpc 默认提供的 RoundRobinLoadBalancer 会清除所有通过 Resolver 返回的 Attribute，因此这种办法是不可行的。 那么进一步就是增加自定义的 RoundRobinLoadBalaner，去掉清除 tag 的逻辑。不过我并未按照这个方案实施，主要是它太复杂，且只解决了一个问题，难以说服项目负责人接受。 其他视角的解决办法 改造 rpc 的方案不行后，我将目光放在了修改使用 rpc 的方式上，很快我就发现从这里入手会简单许多。 在目前的代码里，java 服务会建立一个 ManagedChannel，并通过该 channel 访问 C++ 服务。其中 ManagedChannel 是通过 NettyChannelBuilder 创建的，其底层会为每个 Resolver 返回的 EquivalentAddressGroup 创建一个 NettyTransport（也就是 socket）。而阿里云、腾讯云提供的 VIP 只有一个 IP 地址，因此每个 java 服务最终只会创建一条到 C++ 服务的 socket。显然，只需要创建多个 ManagedChannel，就能建立多条 socket；再通过模拟 round-robin 算法，每次发起 rpc 前选择一个 channel，就能在很大程度上保证每个 RS 接收到的 rpc 请求是均衡的。 当然这只解决了第一个问题。VIP 机制下没有渠道可以获取到 RS 是否发生变更，因此只能从连接本身入手。一种方式是使用短连接，但它在每次访问时都需要创建一个 ManagedChannel，且并发数受限于可用端口数量，因此不是最优选择；另一种方式是为每个连接设置一段时间，超过时间后回收并重建连接，这样就保证在一段时间后就能与新加入的 RS 建立连接。 我选择使用第二种方式，为每个连接设置一段存活时间，超过时间后回收连接。grpc 协议提供了类似的支持：A9-server-side-conn-mgt，它允许在 server 端配置每个连接的 MAX_CONNECTION_AGE，超过时间后 server 端会给 client 发送 GOAWAY 通知 client 关闭该连接。当然，这个协议只有 grpc server 才支持，而我们的 C++ 服务使用的 brpc 并没有提供类似的机制，所以我们需要自己提供类似的功能。该功能实现也比较简单，每次建立连接时，会在某个时间范围内随机选择一个值作为 deadline；每次发送 rpc 请求时，先判断 deadline 是否已经到达，如果超过了 deadline，那么会调用 ManagedChannel.terminate() 并重建连接。 Connection refused 问题 在实施上述方案的过程中，我们还碰到了另一个 grpc 的问题：尽管后端 C++ 服务已经启动，java client 仍然会不时抛出 Connection refused 异常。 通过分析代码，我们发现 grpc netty 实现中，如果碰到了连接异常，会调用 InternalSubChannel::scheduleBackoff。它主要做了两件事情： 在一段时间后，调用 InternalSubChannel::startNewTransport 重新建立连接。 调用 gotoState(ConnectivityStateInfo.forTransactionFailure(status))，将错误信息保存到 subchannel picker 中。 而 ManagedChannelImpl::ChannelTransportProvider::get() 中会读取 subchannel picker 中保存的状态，如果对应的状态满足 isWaitForReady() == false，那么直接返回 FaillingClientTransport，最终抛出 Connection refused 异常。 也就是说，在 backoff 期间，所有在该 channel 上发起的 rpc 请求都会抛出 Connection refused 异常。而不幸的是：InternalChannel.backoffPolicy 是在 AbstractManagedChannelImplBuilder 中通过 new ExponentialBackoffPolicy.Provider() 设置的，没有提供自定义选项；而 ExponentialBackoffPolicy 中时间相关参数为常数，没有提供可修改选项，最大时间间隔为两分钟。显然，grpc java 的作者希望通过 backoff 来减小对 server 重连的压力，而我们则希望尽可能减少服务不可用时间。 幸运的是 ManagedChannel 提供了一个方法可以获取当前 channel 的状态。我们通过使用该接口，在每次请求前获取当前 channel 状态，如果是 TRANSIENT_FAILURE， 则关闭 channel 并重建。","headline":"grpc 的一些踩坑经验","mainEntityOfPage":{"@type":"WebPage","@id":"/2023/07/09/grpc-and-vip.html"},"url":"/2023/07/09/grpc-and-vip.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="W41ter's Bistro" /><!-- for mathjax support -->
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          extensions: [
          "tex2jax.js",
          "MathMenu.js",
          "MathZoom.js",
          "AssistiveMML.js",
          "a11y/accessibility-menu.js"
        ],
        tex2jax: {      // AND HERE
          inlineMath: [['$', '$']],
          displayMath: [['$$', '$$']]
        },
        jax: ["input/TeX", "output/CommonHTML"],
        TeX: {
          extensions: [
            "AMSmath.js",
            "AMSsymbols.js",
            "noErrors.js",
            "noUndefined.js",
          ],
          equationNumbers: { autoNumber: "AMS" }
        }
      });
    </script>
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">W41ter&#39;s Bistro</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">grpc 的一些踩坑经验</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2023-07-09T00:00:00+08:00" itemprop="datePublished">Jul 9, 2023
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>最近的工作需要对某个系统的 RPC 部分做优化。这个系统有多个组件，分别使用不同语言编写，此次我需要优化的组件分别由 java 和 c++ 编写，java 使用 grpc 访问使用 brpc 的 c++ 服务。</p>

<p>该系统在编写之初为了省事，将 c++ 服务放在四层负载均衡 VIP 之后，以利用其提供的负载均衡、探活熔断的能力。这种图省事的操作为系统留下了几个隐患：</p>
<ol>
  <li>如果 java 组件部署数量不够，那么无法保证通过 VIP 建立的连接数能够均衡分布到每个 RS</li>
  <li>如果不重启 java 组件，那么新加入的 RS 无法获得新连接。</li>
</ol>

<h2 id="一些尝试">一些尝试</h2>

<p>刚开始接受这个任务时，我的思路主要集中在能否通过简单改造 rpc 来解决前面两个问题。</p>

<p>针对第一个问题，我的初步思路是能否为每个 VIP 提供一些 tag，这样 grpc 在建立 channel 时，可以为某个 IP 建立多个连接，并使用 round-robin 的方式提供负载均衡。</p>

<p>我首先尝试编写一个 <code class="language-plaintext highlighter-rouge">Resolver</code>，它在 <code class="language-plaintext highlighter-rouge">DnsResolver</code> 的基础上，为每个 <code class="language-plaintext highlighter-rouge">EquivalentAddressGroup</code> 增加一个描述 tag 的 <code class="language-plaintext highlighter-rouge">Attribute</code>。不过很快我就发现，grpc 默认提供的 <code class="language-plaintext highlighter-rouge">RoundRobinLoadBalancer</code> 会清除所有通过 <code class="language-plaintext highlighter-rouge">Resolver</code> 返回的 <code class="language-plaintext highlighter-rouge">Attribute</code>，因此这种办法是不可行的。</p>

<p>那么进一步就是增加自定义的 <code class="language-plaintext highlighter-rouge">RoundRobinLoadBalaner</code>，去掉清除 tag 的逻辑。不过我并未按照这个方案实施，主要是它太复杂，且只解决了一个问题，难以说服项目负责人接受。</p>

<h2 id="其他视角的解决办法">其他视角的解决办法</h2>

<p>改造 rpc 的方案不行后，我将目光放在了修改使用 rpc 的方式上，很快我就发现从这里入手会简单许多。</p>

<p>在目前的代码里，java 服务会建立一个 <code class="language-plaintext highlighter-rouge">ManagedChannel</code>，并通过该 channel 访问 C++ 服务。其中 <code class="language-plaintext highlighter-rouge">ManagedChannel</code> 是通过 <code class="language-plaintext highlighter-rouge">NettyChannelBuilder</code> 创建的，其底层会为每个 <code class="language-plaintext highlighter-rouge">Resolver</code> 返回的 <code class="language-plaintext highlighter-rouge">EquivalentAddressGroup</code> 创建一个 <code class="language-plaintext highlighter-rouge">NettyTransport</code>（也就是 socket）。而阿里云、腾讯云提供的 VIP 只有一个 IP 地址，因此每个 java 服务最终只会创建一条到 C++ 服务的 socket。显然，只需要创建多个 <code class="language-plaintext highlighter-rouge">ManagedChannel</code>，就能建立多条 socket；再通过模拟 round-robin 算法，每次发起 rpc 前选择一个 channel，就能在很大程度上保证每个 RS 接收到的 rpc 请求是均衡的。</p>

<p>当然这只解决了第一个问题。VIP 机制下没有渠道可以获取到 RS 是否发生变更，因此只能从连接本身入手。一种方式是使用短连接，但它在每次访问时都需要创建一个 <code class="language-plaintext highlighter-rouge">ManagedChannel</code>，且并发数受限于可用端口数量，因此不是最优选择；另一种方式是为每个连接设置一段时间，超过时间后回收并重建连接，这样就保证在一段时间后就能与新加入的 RS 建立连接。</p>

<p>我选择使用第二种方式，为每个连接设置一段存活时间，超过时间后回收连接。grpc 协议提供了类似的支持：<a href="https://github.com/grpc/proposal/blob/master/A9-server-side-conn-mgt.md">A9-server-side-conn-mgt</a>，它允许在 server 端配置每个连接的 <code class="language-plaintext highlighter-rouge">MAX_CONNECTION_AGE</code>，超过时间后 server 端会给 client 发送 <code class="language-plaintext highlighter-rouge">GOAWAY</code> 通知 client 关闭该连接。当然，这个协议只有 grpc server 才支持，而我们的 C++ 服务使用的 brpc 并没有提供类似的机制，所以我们需要自己提供类似的功能。该功能实现也比较简单，每次建立连接时，会在某个时间范围内随机选择一个值作为 deadline；每次发送 rpc 请求时，先判断 deadline 是否已经到达，如果超过了 deadline，那么会调用 <code class="language-plaintext highlighter-rouge">ManagedChannel.terminate()</code> 并重建连接。</p>

<h2 id="connection-refused-问题">Connection refused 问题</h2>

<p>在实施上述方案的过程中，我们还碰到了另一个 grpc 的问题：尽管后端 C++ 服务已经启动，java client 仍然会不时抛出 <code class="language-plaintext highlighter-rouge">Connection refused</code> 异常。</p>

<p>通过分析代码，我们发现 grpc netty 实现中，如果碰到了连接异常，会调用 <code class="language-plaintext highlighter-rouge">InternalSubChannel::scheduleBackoff</code>。它主要做了两件事情：</p>
<ol>
  <li>在一段时间后，调用 <code class="language-plaintext highlighter-rouge">InternalSubChannel::startNewTransport</code> 重新建立连接。</li>
  <li>调用 <code class="language-plaintext highlighter-rouge">gotoState(ConnectivityStateInfo.forTransactionFailure(status))</code>，将错误信息保存到 subchannel picker 中。</li>
</ol>

<p>而 <code class="language-plaintext highlighter-rouge">ManagedChannelImpl::ChannelTransportProvider::get()</code> 中会读取 subchannel picker 中保存的状态，如果对应的状态满足 <code class="language-plaintext highlighter-rouge">isWaitForReady() == false</code>，那么直接返回 <code class="language-plaintext highlighter-rouge">FaillingClientTransport</code>，最终抛出 <code class="language-plaintext highlighter-rouge">Connection refused</code> 异常。</p>

<p>也就是说，在 backoff 期间，所有在该 channel 上发起的 rpc 请求都会抛出 <code class="language-plaintext highlighter-rouge">Connection refused</code> 异常。而不幸的是：<code class="language-plaintext highlighter-rouge">InternalChannel.backoffPolicy</code> 是在 <code class="language-plaintext highlighter-rouge">AbstractManagedChannelImplBuilder</code> 中通过 <code class="language-plaintext highlighter-rouge">new ExponentialBackoffPolicy.Provider()</code> 设置的，没有提供自定义选项；而 <code class="language-plaintext highlighter-rouge">ExponentialBackoffPolicy</code> 中时间相关参数为常数，没有提供可修改选项，最大时间间隔为两分钟。显然，grpc java 的作者希望通过 backoff 来减小对 server 重连的压力，而我们则希望尽可能减少服务不可用时间。</p>

<p>幸运的是 <code class="language-plaintext highlighter-rouge">ManagedChannel</code> 提供了一个方法可以获取当前 channel 的状态。我们通过使用该接口，在每次请求前获取当前 channel 状态，如果是 <code class="language-plaintext highlighter-rouge">TRANSIENT_FAILURE</code>， 则关闭 channel 并重建。</p>


  </div><a class="u-url" href="/2023/07/09/grpc-and-vip.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">W41ter&#39;s Bistro</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">W41ter&#39;s Bistro</li><li><a class="u-email" href="mailto:w41ter.l@gmail.com">w41ter.l@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/w41ter"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">w41ter</span></a></li><li><a href="https://www.twitter.com/WalterM56697798"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">WalterM56697798</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Focus on distributed storage system, compiler.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
