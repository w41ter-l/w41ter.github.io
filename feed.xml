<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-10-28T12:18:41+08:00</updated><id>/feed.xml</id><title type="html">W41ter’s Bistro</title><subtitle>Focus on distributed storage system, compiler.</subtitle><entry><title type="html">grpc 的一些踩坑经验</title><link href="/2023/07/09/grpc-and-vip.html" rel="alternate" type="text/html" title="grpc 的一些踩坑经验" /><published>2023-07-09T00:00:00+08:00</published><updated>2023-07-09T00:00:00+08:00</updated><id>/2023/07/09/grpc-and-vip</id><content type="html" xml:base="/2023/07/09/grpc-and-vip.html"><![CDATA[<p>最近的工作需要对某个系统的 RPC 部分做优化。这个系统有多个组件，分别使用不同语言编写，此次我需要优化的组件分别由 java 和 c++ 编写，java 使用 grpc 访问使用 brpc 的 c++ 服务。</p>

<p>该系统在编写之初为了省事，将 c++ 服务放在四层负载均衡 VIP 之后，以利用其提供的负载均衡、探活熔断的能力。这种图省事的操作为系统留下了几个隐患：</p>
<ol>
  <li>如果 java 组件部署数量不够，那么无法保证通过 VIP 建立的连接数能够均衡分布到每个 RS</li>
  <li>如果不重启 java 组件，那么新加入的 RS 无法获得新连接。</li>
</ol>

<h2 id="一些尝试">一些尝试</h2>

<p>刚开始接受这个任务时，我的思路主要集中在能否通过简单改造 rpc 来解决前面两个问题。</p>

<p>针对第一个问题，我的初步思路是能否为每个 VIP 提供一些 tag，这样 grpc 在建立 channel 时，可以为某个 IP 建立多个连接，并使用 round-robin 的方式提供负载均衡。</p>

<p>我首先尝试编写一个 <code class="language-plaintext highlighter-rouge">Resolver</code>，它在 <code class="language-plaintext highlighter-rouge">DnsResolver</code> 的基础上，为每个 <code class="language-plaintext highlighter-rouge">EquivalentAddressGroup</code> 增加一个描述 tag 的 <code class="language-plaintext highlighter-rouge">Attribute</code>。不过很快我就发现，grpc 默认提供的 <code class="language-plaintext highlighter-rouge">RoundRobinLoadBalancer</code> 会清除所有通过 <code class="language-plaintext highlighter-rouge">Resolver</code> 返回的 <code class="language-plaintext highlighter-rouge">Attribute</code>，因此这种办法是不可行的。</p>

<p>那么进一步就是增加自定义的 <code class="language-plaintext highlighter-rouge">RoundRobinLoadBalaner</code>，去掉清除 tag 的逻辑。不过我并未按照这个方案实施，主要是它太复杂，且只解决了一个问题，难以说服项目负责人接受。</p>

<h2 id="其他视角的解决办法">其他视角的解决办法</h2>

<p>改造 rpc 的方案不行后，我将目光放在了修改使用 rpc 的方式上，很快我就发现从这里入手会简单许多。</p>

<p>在目前的代码里，java 服务会建立一个 <code class="language-plaintext highlighter-rouge">ManagedChannel</code>，并通过该 channel 访问 C++ 服务。其中 <code class="language-plaintext highlighter-rouge">ManagedChannel</code> 是通过 <code class="language-plaintext highlighter-rouge">NettyChannelBuilder</code> 创建的，其底层会为每个 <code class="language-plaintext highlighter-rouge">Resolver</code> 返回的 <code class="language-plaintext highlighter-rouge">EquivalentAddressGroup</code> 创建一个 <code class="language-plaintext highlighter-rouge">NettyTransport</code>（也就是 socket）。而阿里云、腾讯云提供的 VIP 只有一个 IP 地址，因此每个 java 服务最终只会创建一条到 C++ 服务的 socket。显然，只需要创建多个 <code class="language-plaintext highlighter-rouge">ManagedChannel</code>，就能建立多条 socket；再通过模拟 round-robin 算法，每次发起 rpc 前选择一个 channel，就能在很大程度上保证每个 RS 接收到的 rpc 请求是均衡的。</p>

<p>当然这只解决了第一个问题。VIP 机制下没有渠道可以获取到 RS 是否发生变更，因此只能从连接本身入手。一种方式是使用短连接，但它在每次访问时都需要创建一个 <code class="language-plaintext highlighter-rouge">ManagedChannel</code>，且并发数受限于可用端口数量，因此不是最优选择；另一种方式是为每个连接设置一段时间，超过时间后回收并重建连接，这样就保证在一段时间后就能与新加入的 RS 建立连接。</p>

<p>我选择使用第二种方式，为每个连接设置一段存活时间，超过时间后回收连接。grpc 协议提供了类似的支持：<a href="https://github.com/grpc/proposal/blob/master/A9-server-side-conn-mgt.md">A9-server-side-conn-mgt</a>，它允许在 server 端配置每个连接的 <code class="language-plaintext highlighter-rouge">MAX_CONNECTION_AGE</code>，超过时间后 server 端会给 client 发送 <code class="language-plaintext highlighter-rouge">GOAWAY</code> 通知 client 关闭该连接。当然，这个协议只有 grpc server 才支持，而我们的 C++ 服务使用的 brpc 并没有提供类似的机制，所以我们需要自己提供类似的功能。该功能实现也比较简单，每次建立连接时，会在某个时间范围内随机选择一个值作为 deadline；每次发送 rpc 请求时，先判断 deadline 是否已经到达，如果超过了 deadline，那么会调用 <code class="language-plaintext highlighter-rouge">ManagedChannel.terminate()</code> 并重建连接。</p>

<h2 id="connection-refused-问题">Connection refused 问题</h2>

<p>在实施上述方案的过程中，我们还碰到了另一个 grpc 的问题：尽管后端 C++ 服务已经启动，java client 仍然会不时抛出 <code class="language-plaintext highlighter-rouge">Connection refused</code> 异常。</p>

<p>通过分析代码，我们发现 grpc netty 实现中，如果碰到了连接异常，会调用 <code class="language-plaintext highlighter-rouge">InternalSubChannel::scheduleBackoff</code>。它主要做了两件事情：</p>
<ol>
  <li>在一段时间后，调用 <code class="language-plaintext highlighter-rouge">InternalSubChannel::startNewTransport</code> 重新建立连接。</li>
  <li>调用 <code class="language-plaintext highlighter-rouge">gotoState(ConnectivityStateInfo.forTransactionFailure(status))</code>，将错误信息保存到 subchannel picker 中。</li>
</ol>

<p>而 <code class="language-plaintext highlighter-rouge">ManagedChannelImpl::ChannelTransportProvider::get()</code> 中会读取 subchannel picker 中保存的状态，如果对应的状态满足 <code class="language-plaintext highlighter-rouge">isWaitForReady() == false</code>，那么直接返回 <code class="language-plaintext highlighter-rouge">FaillingClientTransport</code>，最终抛出 <code class="language-plaintext highlighter-rouge">Connection refused</code> 异常。</p>

<p>也就是说，在 backoff 期间，所有在该 channel 上发起的 rpc 请求都会抛出 <code class="language-plaintext highlighter-rouge">Connection refused</code> 异常。而不幸的是：<code class="language-plaintext highlighter-rouge">InternalChannel.backoffPolicy</code> 是在 <code class="language-plaintext highlighter-rouge">AbstractManagedChannelImplBuilder</code> 中通过 <code class="language-plaintext highlighter-rouge">new ExponentialBackoffPolicy.Provider()</code> 设置的，没有提供自定义选项；而 <code class="language-plaintext highlighter-rouge">ExponentialBackoffPolicy</code> 中时间相关参数为常数，没有提供可修改选项，最大时间间隔为两分钟。显然，grpc java 的作者希望通过 backoff 来减小对 server 重连的压力，而我们则希望尽可能减少服务不可用时间。</p>

<p>幸运的是 <code class="language-plaintext highlighter-rouge">ManagedChannel</code> 提供了一个方法可以获取当前 channel 的状态。我们通过使用该接口，在每次请求前获取当前 channel 状态，如果是 <code class="language-plaintext highlighter-rouge">TRANSIENT_FAILURE</code>， 则关闭 channel 并重建。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[最近的工作需要对某个系统的 RPC 部分做优化。这个系统有多个组件，分别使用不同语言编写，此次我需要优化的组件分别由 java 和 c++ 编写，java 使用 grpc 访问使用 brpc 的 c++ 服务。 该系统在编写之初为了省事，将 c++ 服务放在四层负载均衡 VIP 之后，以利用其提供的负载均衡、探活熔断的能力。这种图省事的操作为系统留下了几个隐患： 如果 java 组件部署数量不够，那么无法保证通过 VIP 建立的连接数能够均衡分布到每个 RS 如果不重启 java 组件，那么新加入的 RS 无法获得新连接。 一些尝试 刚开始接受这个任务时，我的思路主要集中在能否通过简单改造 rpc 来解决前面两个问题。 针对第一个问题，我的初步思路是能否为每个 VIP 提供一些 tag，这样 grpc 在建立 channel 时，可以为某个 IP 建立多个连接，并使用 round-robin 的方式提供负载均衡。 我首先尝试编写一个 Resolver，它在 DnsResolver 的基础上，为每个 EquivalentAddressGroup 增加一个描述 tag 的 Attribute。不过很快我就发现，grpc 默认提供的 RoundRobinLoadBalancer 会清除所有通过 Resolver 返回的 Attribute，因此这种办法是不可行的。 那么进一步就是增加自定义的 RoundRobinLoadBalaner，去掉清除 tag 的逻辑。不过我并未按照这个方案实施，主要是它太复杂，且只解决了一个问题，难以说服项目负责人接受。 其他视角的解决办法 改造 rpc 的方案不行后，我将目光放在了修改使用 rpc 的方式上，很快我就发现从这里入手会简单许多。 在目前的代码里，java 服务会建立一个 ManagedChannel，并通过该 channel 访问 C++ 服务。其中 ManagedChannel 是通过 NettyChannelBuilder 创建的，其底层会为每个 Resolver 返回的 EquivalentAddressGroup 创建一个 NettyTransport（也就是 socket）。而阿里云、腾讯云提供的 VIP 只有一个 IP 地址，因此每个 java 服务最终只会创建一条到 C++ 服务的 socket。显然，只需要创建多个 ManagedChannel，就能建立多条 socket；再通过模拟 round-robin 算法，每次发起 rpc 前选择一个 channel，就能在很大程度上保证每个 RS 接收到的 rpc 请求是均衡的。 当然这只解决了第一个问题。VIP 机制下没有渠道可以获取到 RS 是否发生变更，因此只能从连接本身入手。一种方式是使用短连接，但它在每次访问时都需要创建一个 ManagedChannel，且并发数受限于可用端口数量，因此不是最优选择；另一种方式是为每个连接设置一段时间，超过时间后回收并重建连接，这样就保证在一段时间后就能与新加入的 RS 建立连接。 我选择使用第二种方式，为每个连接设置一段存活时间，超过时间后回收连接。grpc 协议提供了类似的支持：A9-server-side-conn-mgt，它允许在 server 端配置每个连接的 MAX_CONNECTION_AGE，超过时间后 server 端会给 client 发送 GOAWAY 通知 client 关闭该连接。当然，这个协议只有 grpc server 才支持，而我们的 C++ 服务使用的 brpc 并没有提供类似的机制，所以我们需要自己提供类似的功能。该功能实现也比较简单，每次建立连接时，会在某个时间范围内随机选择一个值作为 deadline；每次发送 rpc 请求时，先判断 deadline 是否已经到达，如果超过了 deadline，那么会调用 ManagedChannel.terminate() 并重建连接。 Connection refused 问题 在实施上述方案的过程中，我们还碰到了另一个 grpc 的问题：尽管后端 C++ 服务已经启动，java client 仍然会不时抛出 Connection refused 异常。 通过分析代码，我们发现 grpc netty 实现中，如果碰到了连接异常，会调用 InternalSubChannel::scheduleBackoff。它主要做了两件事情： 在一段时间后，调用 InternalSubChannel::startNewTransport 重新建立连接。 调用 gotoState(ConnectivityStateInfo.forTransactionFailure(status))，将错误信息保存到 subchannel picker 中。 而 ManagedChannelImpl::ChannelTransportProvider::get() 中会读取 subchannel picker 中保存的状态，如果对应的状态满足 isWaitForReady() == false，那么直接返回 FaillingClientTransport，最终抛出 Connection refused 异常。 也就是说，在 backoff 期间，所有在该 channel 上发起的 rpc 请求都会抛出 Connection refused 异常。而不幸的是：InternalChannel.backoffPolicy 是在 AbstractManagedChannelImplBuilder 中通过 new ExponentialBackoffPolicy.Provider() 设置的，没有提供自定义选项；而 ExponentialBackoffPolicy 中时间相关参数为常数，没有提供可修改选项，最大时间间隔为两分钟。显然，grpc java 的作者希望通过 backoff 来减小对 server 重连的压力，而我们则希望尽可能减少服务不可用时间。 幸运的是 ManagedChannel 提供了一个方法可以获取当前 channel 的状态。我们通过使用该接口，在每次请求前获取当前 channel 状态，如果是 TRANSIENT_FAILURE， 则关闭 channel 并重建。]]></summary></entry><entry><title type="html">The space reclaiming of PhotonDB</title><link href="/2022/12/07/The-space-reclaiming-of-PhotonDB.html" rel="alternate" type="text/html" title="The space reclaiming of PhotonDB" /><published>2022-12-07T00:00:00+08:00</published><updated>2022-12-07T00:00:00+08:00</updated><id>/2022/12/07/The-space-reclaiming-of-PhotonDB</id><content type="html" xml:base="/2022/12/07/The-space-reclaiming-of-PhotonDB.html"><![CDATA[<p>最近的一段时间我们分析并改进了 PhotonDB 的空间回收机制。</p>

<h1 id="background">Background</h1>

<p>PhotonDB 的 page store 可以视作一个 log structured page allocator。</p>

<p>在实现上，它分为持久化和内存中的两部分，其中内存部分由串有序的 write buffer 组成。write buffer 是一段连续的内存空间，新的 delta page 从最后一个 write buffer 中分配。每个 delta page 均有唯一的逻辑地址，该地址按照分配次序递增；其他 page 可以通过这个逻辑地址访问到该 delta page。其中从根节点出发能访问到的 delta page 称为活跃的；当 page 更新后，相关的 delta page 将不再被访问，所以会被归还（dealloc）给 page store。</p>

<p>当 write buffer 的空间分配完后，其中仍活跃的 delta page 会持久化到存储设备上，保存到一个新的 page file 中。除了记录 delta page 外，Page file 还记录了一些元数据，包括 delta page 到 page id 的映射；先前生成的 page files 中已经归还（dealloc）的 delta page 的地址；每个 delta page 的在 write buffer 中的偏移。每个 page file 在内存中维护着一个数据结构：<code class="language-plaintext highlighter-rouge">FileMeta</code>，其中记录着 delta page 的逻辑地址到文件偏移的映射关系。</p>

<p>每个 write buffer 有一个唯一且递增的 ID，它是 delta page 的逻辑地址的组成部分：逻辑地址由 buffer id 和 delta page 在 buffer 中的偏移组成（<code class="language-plaintext highlighter-rouge">logical address = (buffer id &lt;&lt; 32) | offset</code>）。Write buffer 转储时生成的 page file 拥有相同的 ID，因此对于任意一个逻辑地址，可以直接定位到 write buffer 或者 page file，并找到 delta page （对 page file ，还需要通过查询 <code class="language-plaintext highlighter-rouge">FileMeta</code>，找到文件偏移）。</p>

<p>前面提到了 page files 中还记录着已归还的 delta pages 的逻辑地址，虽然这些地址对应的数据将不再会被访问，但它们占用的磁盘空间仍然被保留着。我们称这部分空间为空白页。为了保证有足够的空间容纳新写入的数据，这些具有空白页的 page files 需要被整理，释放出空白页占据的空间。找到合适的 page files 并进行过程称为空间回收。</p>

<h1 id="framework">Framework</h1>

<p>空间回收实现时需要回答三个问题，何时进行？最优化目标？处理方法？这三个问题勾勒出空间回收机制实现的基本轮廓：</p>
<ol>
  <li>空间回收触发时机</li>
  <li>候选 page file 的选择策略</li>
  <li>page file 的处理方法</li>
</ol>

<p>当某些指标达到触发条件时，使用选择策略选择出候选 page files，并对 page file 按照某种方法进行处理，最终释放出空闲空间。后文将按照顺序，依次介绍 PhotonDB 解决这三个问题的方案。</p>

<h2 id="trigger">Trigger</h2>

<p>首先讨论的是空间回收的触发机制。PhotonDB 关注两个指标：1、使用空间；2、空间放大。在使用空间超过高水位线或者空间放大超过上限时，PhotonDB 触发空间回收，直到相关指标落到阈值下。为使用空间设置水位线，用于保证在剩余空间的比例；为空间放大设置上线，用于将整体的回收代价均摊到程序的整个运行时间段上。当然，只有存在过期 delta page 时，才能释放出空闲空间；因此只有拥有可回收空间时，使用空间的指标才会生效。</p>

<h2 id="efficient-strategy">Efficient strategy</h2>

<p>空间回收需要占用 IO 资源，它需要重定位候选 page files 中的活跃 delta page。这个过程的开销与过期 delta page 的数量有关系。显然过期的 delta page 越多，重定位的 IO 开销就越小。</p>

<p>候选文件选择策略的目标就是找到最适合回收的 page files，使得总的 IO 开销最小。</p>

<h3 id="minimize-of-io-cost">Minimize of IO cost</h3>

<p>为了找到这样的一个策略，我们不妨假设某个 page file $i$ 在时刻 $t_n$ 被回收的代价为 $C_i$，回收成本的下降速率（decline rate）为 $\frac{dc_i(t_0)}{dt}$；如果某个时间点 $t_0$ 回收成本为 $C_0$，那么对任意未来的时间 $t$，回收该 page file 的成本为：</p>

<p>$C_i(t) \approx C_i(t_0) + \frac{dc_i(t_0)}{dt} (t - t_0)$</p>

<p>假设有 $k$ 个 page file，每次处理一个，那么总的成本为：</p>

<p>$Cost = \sum_{i=1}^{k} c_i(t_0) - \sum_{i=1}^{k}-\frac{dc_i(t_0)}{dt}(t_i-t_0)$</p>

<p>观察发现，上述公式后半部分的值越大，最终的成本越小。显然当 $-\frac{dc_i(t_0)}{dt}$ 按照顺序排列时，后半部分的值越大。因此，优先处理 decline rate 最小的 page files，最后处理 decline rate 最大的 page files，总的代价最小。</p>

<p>我们把上述公式给出的回收策略称为 Min Decline Rate 策略。它显然符合直觉：如果成本能在未来一段时间内大幅下降，那么等待一段时间再处理是值得的。</p>

<h3 id="decline-rate">Decline rate</h3>

<p>有了理论指导后，下一步是为每个 page file 计算 decline rate。假设一个 page file 中空白页占比为 $E$，那么回收一个文件的空间，需要回收 $1/E$ 个有空闲页的 page file。其中放大部分为 $1/E(1-E)$。那么，写一个 page file 的 IO 成本为：</p>

<p>$Cost = \frac{1}{E} reads + \frac{1}{E} (1-E) writes + 1 = \frac{2}{E}$</p>

<p>进一步，IO 成本的 decline rate 为：</p>

<p>$\frac{d(Cost)}{dt} = (\frac{-2}{E^2})(\frac{dF}{du}) \approx \frac{−2(1 − E)}{E^2}f\Delta E$</p>

<p>其中 $f$ 是每个 page 的更新频率，$\Delta E$ 是每次更新时 $E$ 的变化率。文件的更新频率为 $f$ 乘上活跃 page 数。</p>

<p>每个 page 的更新频率可以通过如下方式估计：</p>

<p>$f = \frac{2}{t_{now}-t_{up2}}$</p>

<p>其中 $t_{up2}$ 表示倒数第二次更新某个 page 时的逻辑时间。</p>

<p>Min Decline Rate 策略来自于论文：<a href="https://arxiv.org/abs/2005.00044">Efficiently Reclaiming Space in a Log Structured Store</a>，如果对推导过程感兴趣，可以参考原论文。PhotonDB 使用 Min Decline Rate 作为候选 page files 选择策略。每次进行空间回收时，使用上面的公式计算每个 page file 的 decline rate 并排序。除了成本的计算外，原论文还指出，回收过程中可以使用更新频率对 delta page 进行分类，进一步降低回收成本。</p>

<h2 id="reclaim-file">Reclaim file</h2>

<p>处理候选 page file 时，需要保证活跃的 delta page 在处理完成后仍然能够访问。由于不考虑原地更新，那么回收一个 page file 就要求实现将其中仍活跃的 delta page 复制到其他位置。</p>

<p>最直接的办法是将 delta page 复制到一块新开辟的空间里，同时更新对 delta page 的引用，将其指向复制后的位置。这个过程我们称为重定向，它有一个明显的缺陷：更换了 delta page 的逻辑地址。每个活跃的 delta page 均可从根节点访问到，对它的引用可能存在于 page table 中，也可能存在于同一 delta chain 上的前驱节点；对于后者，更换逻辑地址意味着需要遍历整个 delta chain，找到对应的前驱节点进行替换。对于 immutable 的数据结构而言，替换就意味着需要引入一种新的 delta page，它负责将原逻辑地址映射到新的逻辑地址上。</p>

<p>为了避免额外的复杂度，0.2 版本的 PhotonDB 使用了 page rewriting 的机制来避免上述问题。</p>

<h3 id="problem-with-page-rewriting">Problem with page rewriting</h3>

<p>PhotonDB 使用的 page rewriting 机制类似于 consolidation 操作，因此它们能够复用一些逻辑。consolidation 会将 delta chain 合并，并使用生成的 delta page 替换掉 delta chain。</p>

<p>page rewriting 与 consolidation 略有不同，主要分两个方面：</p>
<ol>
  <li>page rewriting 仍然有重定位的作用，即使 delta chain 长度为 1，页需要生成新的 delta page 并替换。</li>
  <li>page rewriting 可能会生成一条 delta chain，而不是一个 delta page。比如 split delta 在没有应用到父节点前，不能被合并到新 delta page 中。</li>
</ol>

<p>Page rewriting 机制的缺点也是明显的，合并 delta chain 的过程中有大量的 IO 扇入扇出。Page rewriting 的另一个问题是没有跟踪这些新 delta page 的更新频率。与论文中的做法不同，出于性能考虑 PhotonDB 只跟踪了 page file 的更新频率，没有跟踪 delta page 的更新频率。这些 rewriting 生成的 delta page 被当作全新的写入，与用户写入的 delta page 混合到一起，导致了更新频率的失真。</p>

<h3 id="solution">Solution</h3>

<p>如果我们引入一层全局的转换层，它负责将逻辑地址中的 page file ID 映射到物理地址（文件，偏移）上，那么也可以做到不修改 delta page 的逻辑地址的同时回收 page file。显然这个转换层已经存在了，它就是前面提到的 FileMeta。因此，我们只需要将活跃的 delta page 复制到新的文件中，并修改 FileMeta 中的映射，就完成了 page file 的回收。</p>

<p>不过随着归还的 delta page 越来越多，新文件会越来越小、越来越碎片化，需要付出更大的开销来维护这些小文件的元数据；同时 IO 的预取、批处理等效率也有较低。为此，我们引入了一种新的文件格式：mapping file。Mapping file 将多个 page files 中活跃的 delta page 打包到一个文件中，同时记录下逻辑地址与物理地址的映射关系。</p>

<p>除了减少碎片化、避免 page rewriting 引入的 IO 放大外，mapping file 提供了提到的按照更新频率对 delta page 分类的能力；将更新频率接近的 delta page 放到一起，可以达到冷热分离的效果。从实验数据上看，mapping file 的引入，让 0.3 版本的 PhotonDB 在 zipfan 和 uniform workload 下较前一个版本分别减少了 ~5 倍和 ~2.5 倍的写放大。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[最近的一段时间我们分析并改进了 PhotonDB 的空间回收机制。 Background PhotonDB 的 page store 可以视作一个 log structured page allocator。 在实现上，它分为持久化和内存中的两部分，其中内存部分由串有序的 write buffer 组成。write buffer 是一段连续的内存空间，新的 delta page 从最后一个 write buffer 中分配。每个 delta page 均有唯一的逻辑地址，该地址按照分配次序递增；其他 page 可以通过这个逻辑地址访问到该 delta page。其中从根节点出发能访问到的 delta page 称为活跃的；当 page 更新后，相关的 delta page 将不再被访问，所以会被归还（dealloc）给 page store。 当 write buffer 的空间分配完后，其中仍活跃的 delta page 会持久化到存储设备上，保存到一个新的 page file 中。除了记录 delta page 外，Page file 还记录了一些元数据，包括 delta page 到 page id 的映射；先前生成的 page files 中已经归还（dealloc）的 delta page 的地址；每个 delta page 的在 write buffer 中的偏移。每个 page file 在内存中维护着一个数据结构：FileMeta，其中记录着 delta page 的逻辑地址到文件偏移的映射关系。 每个 write buffer 有一个唯一且递增的 ID，它是 delta page 的逻辑地址的组成部分：逻辑地址由 buffer id 和 delta page 在 buffer 中的偏移组成（logical address = (buffer id &lt;&lt; 32) | offset）。Write buffer 转储时生成的 page file 拥有相同的 ID，因此对于任意一个逻辑地址，可以直接定位到 write buffer 或者 page file，并找到 delta page （对 page file ，还需要通过查询 FileMeta，找到文件偏移）。 前面提到了 page files 中还记录着已归还的 delta pages 的逻辑地址，虽然这些地址对应的数据将不再会被访问，但它们占用的磁盘空间仍然被保留着。我们称这部分空间为空白页。为了保证有足够的空间容纳新写入的数据，这些具有空白页的 page files 需要被整理，释放出空白页占据的空间。找到合适的 page files 并进行过程称为空间回收。 Framework 空间回收实现时需要回答三个问题，何时进行？最优化目标？处理方法？这三个问题勾勒出空间回收机制实现的基本轮廓： 空间回收触发时机 候选 page file 的选择策略 page file 的处理方法 当某些指标达到触发条件时，使用选择策略选择出候选 page files，并对 page file 按照某种方法进行处理，最终释放出空闲空间。后文将按照顺序，依次介绍 PhotonDB 解决这三个问题的方案。 Trigger 首先讨论的是空间回收的触发机制。PhotonDB 关注两个指标：1、使用空间；2、空间放大。在使用空间超过高水位线或者空间放大超过上限时，PhotonDB 触发空间回收，直到相关指标落到阈值下。为使用空间设置水位线，用于保证在剩余空间的比例；为空间放大设置上线，用于将整体的回收代价均摊到程序的整个运行时间段上。当然，只有存在过期 delta page 时，才能释放出空闲空间；因此只有拥有可回收空间时，使用空间的指标才会生效。 Efficient strategy 空间回收需要占用 IO 资源，它需要重定位候选 page files 中的活跃 delta page。这个过程的开销与过期 delta page 的数量有关系。显然过期的 delta page 越多，重定位的 IO 开销就越小。 候选文件选择策略的目标就是找到最适合回收的 page files，使得总的 IO 开销最小。 Minimize of IO cost 为了找到这样的一个策略，我们不妨假设某个 page file $i$ 在时刻 $t_n$ 被回收的代价为 $C_i$，回收成本的下降速率（decline rate）为 $\frac{dc_i(t_0)}{dt}$；如果某个时间点 $t_0$ 回收成本为 $C_0$，那么对任意未来的时间 $t$，回收该 page file 的成本为： $C_i(t) \approx C_i(t_0) + \frac{dc_i(t_0)}{dt} (t - t_0)$ 假设有 $k$ 个 page file，每次处理一个，那么总的成本为： $Cost = \sum_{i=1}^{k} c_i(t_0) - \sum_{i=1}^{k}-\frac{dc_i(t_0)}{dt}(t_i-t_0)$ 观察发现，上述公式后半部分的值越大，最终的成本越小。显然当 $-\frac{dc_i(t_0)}{dt}$ 按照顺序排列时，后半部分的值越大。因此，优先处理 decline rate 最小的 page files，最后处理 decline rate 最大的 page files，总的代价最小。 我们把上述公式给出的回收策略称为 Min Decline Rate 策略。它显然符合直觉：如果成本能在未来一段时间内大幅下降，那么等待一段时间再处理是值得的。 Decline rate 有了理论指导后，下一步是为每个 page file 计算 decline rate。假设一个 page file 中空白页占比为 $E$，那么回收一个文件的空间，需要回收 $1/E$ 个有空闲页的 page file。其中放大部分为 $1/E(1-E)$。那么，写一个 page file 的 IO 成本为： $Cost = \frac{1}{E} reads + \frac{1}{E} (1-E) writes + 1 = \frac{2}{E}$ 进一步，IO 成本的 decline rate 为： $\frac{d(Cost)}{dt} = (\frac{-2}{E^2})(\frac{dF}{du}) \approx \frac{−2(1 − E)}{E^2}f\Delta E$ 其中 $f$ 是每个 page 的更新频率，$\Delta E$ 是每次更新时 $E$ 的变化率。文件的更新频率为 $f$ 乘上活跃 page 数。 每个 page 的更新频率可以通过如下方式估计： $f = \frac{2}{t_{now}-t_{up2}}$ 其中 $t_{up2}$ 表示倒数第二次更新某个 page 时的逻辑时间。 Min Decline Rate 策略来自于论文：Efficiently Reclaiming Space in a Log Structured Store，如果对推导过程感兴趣，可以参考原论文。PhotonDB 使用 Min Decline Rate 作为候选 page files 选择策略。每次进行空间回收时，使用上面的公式计算每个 page file 的 decline rate 并排序。除了成本的计算外，原论文还指出，回收过程中可以使用更新频率对 delta page 进行分类，进一步降低回收成本。 Reclaim file 处理候选 page file 时，需要保证活跃的 delta page 在处理完成后仍然能够访问。由于不考虑原地更新，那么回收一个 page file 就要求实现将其中仍活跃的 delta page 复制到其他位置。 最直接的办法是将 delta page 复制到一块新开辟的空间里，同时更新对 delta page 的引用，将其指向复制后的位置。这个过程我们称为重定向，它有一个明显的缺陷：更换了 delta page 的逻辑地址。每个活跃的 delta page 均可从根节点访问到，对它的引用可能存在于 page table 中，也可能存在于同一 delta chain 上的前驱节点；对于后者，更换逻辑地址意味着需要遍历整个 delta chain，找到对应的前驱节点进行替换。对于 immutable 的数据结构而言，替换就意味着需要引入一种新的 delta page，它负责将原逻辑地址映射到新的逻辑地址上。 为了避免额外的复杂度，0.2 版本的 PhotonDB 使用了 page rewriting 的机制来避免上述问题。 Problem with page rewriting PhotonDB 使用的 page rewriting 机制类似于 consolidation 操作，因此它们能够复用一些逻辑。consolidation 会将 delta chain 合并，并使用生成的 delta page 替换掉 delta chain。 page rewriting 与 consolidation 略有不同，主要分两个方面： page rewriting 仍然有重定位的作用，即使 delta chain 长度为 1，页需要生成新的 delta page 并替换。 page rewriting 可能会生成一条 delta chain，而不是一个 delta page。比如 split delta 在没有应用到父节点前，不能被合并到新 delta page 中。 Page rewriting 机制的缺点也是明显的，合并 delta chain 的过程中有大量的 IO 扇入扇出。Page rewriting 的另一个问题是没有跟踪这些新 delta page 的更新频率。与论文中的做法不同，出于性能考虑 PhotonDB 只跟踪了 page file 的更新频率，没有跟踪 delta page 的更新频率。这些 rewriting 生成的 delta page 被当作全新的写入，与用户写入的 delta page 混合到一起，导致了更新频率的失真。 Solution 如果我们引入一层全局的转换层，它负责将逻辑地址中的 page file ID 映射到物理地址（文件，偏移）上，那么也可以做到不修改 delta page 的逻辑地址的同时回收 page file。显然这个转换层已经存在了，它就是前面提到的 FileMeta。因此，我们只需要将活跃的 delta page 复制到新的文件中，并修改 FileMeta 中的映射，就完成了 page file 的回收。 不过随着归还的 delta page 越来越多，新文件会越来越小、越来越碎片化，需要付出更大的开销来维护这些小文件的元数据；同时 IO 的预取、批处理等效率也有较低。为此，我们引入了一种新的文件格式：mapping file。Mapping file 将多个 page files 中活跃的 delta page 打包到一个文件中，同时记录下逻辑地址与物理地址的映射关系。 除了减少碎片化、避免 page rewriting 引入的 IO 放大外，mapping file 提供了提到的按照更新频率对 delta page 分类的能力；将更新频率接近的 delta page 放到一起，可以达到冷热分离的效果。从实验数据上看，mapping file 的引入，让 0.3 版本的 PhotonDB 在 zipfan 和 uniform workload 下较前一个版本分别减少了 ~5 倍和 ~2.5 倍的写放大。]]></summary></entry><entry><title type="html">Rust - The `async fn` generated `Future` is too large?</title><link href="/2022/09/05/rust-async-fn-genrated-futures-is-too-large.html" rel="alternate" type="text/html" title="Rust - The `async fn` generated `Future` is too large?" /><published>2022-09-05T00:00:00+08:00</published><updated>2022-09-05T00:00:00+08:00</updated><id>/2022/09/05/rust-async-fn-genrated-futures-is-too-large</id><content type="html" xml:base="/2022/09/05/rust-async-fn-genrated-futures-is-too-large.html"><![CDATA[<h1 id="背景">背景</h1>

<p>最近开始对 engula 进行性能测试，发现 async fn 的性能损耗非常大，这不符合 zero overhead abstraction，因此开始对 async fn 的性能做一些研究。</p>

<p>通过增加参数 <code class="language-plaintext highlighter-rouge">-Z print-type-size</code>，可以输出每种类型的大小。发现很多 generator 内存大小非常大，其中最不符合直觉的是下面这几个：</p>

<pre><code class="language-log">print-type-size type: `std::future::from_generator::GenFuture&lt;[static generator@src/client/src/node_client.rs:39:69: 44:6]&gt;`: 1248 bytes, alignment: 8 bytes
print-type-size     field `.0`: 1248 bytes
print-type-size type: `std::future::from_generator::GenFuture&lt;[static generator@src/client/src/node_client.rs:79:52: 83:6]&gt;`: 1408 bytes, alignment: 8 bytes
print-type-size     field `.0`: 1408 bytes
print-type-size type: `std::future::from_generator::GenFuture&lt;[static generator@src/client/src/node_client.rs:88:51: 92:6]&gt;`: 1408 bytes, alignment: 8 bytes
print-type-size     field `.0`: 1408 bytes
</code></pre>

<p>node_client.rs 是 tonic grpc client 的简单封装:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">tonic</span><span class="p">::</span><span class="nn">transport</span><span class="p">::</span><span class="n">Channel</span><span class="p">;</span>

<span class="nd">#[derive(Debug,</span> <span class="nd">Clone)]</span>
<span class="k">pub</span> <span class="k">struct</span> <span class="n">Client</span> <span class="p">{</span>
    <span class="n">client</span><span class="p">:</span> <span class="nn">node_client</span><span class="p">::</span><span class="n">NodeClient</span><span class="o">&lt;</span><span class="n">Channel</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">pub</span> <span class="k">async</span> <span class="k">fn</span> <span class="nf">root_heartbeat</span><span class="p">(</span>
    <span class="o">&amp;</span><span class="k">self</span><span class="p">,</span>
    <span class="n">req</span><span class="p">:</span> <span class="n">HeartbeatRequest</span><span class="p">,</span>
<span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">HeartbeatResponse</span><span class="p">,</span> <span class="nn">tonic</span><span class="p">::</span><span class="n">Status</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">client</span> <span class="o">=</span> <span class="k">self</span><span class="py">.client</span><span class="nf">.clone</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="n">client</span><span class="nf">.root_heartbeat</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="o">?</span><span class="p">;</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="n">res</span><span class="nf">.into_inner</span><span class="p">())</span>
<span class="p">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">node_client::NodeClient</code> 是 tonic_build 生成的代码：</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">NodeClient</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span>
<span class="k">where</span>
    <span class="n">T</span><span class="p">:</span> <span class="nn">tonic</span><span class="p">::</span><span class="nn">client</span><span class="p">::</span><span class="n">GrpcService</span><span class="o">&lt;</span><span class="nn">tonic</span><span class="p">::</span><span class="nn">body</span><span class="p">::</span><span class="n">BoxBody</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="nn">T</span><span class="p">::</span><span class="n">Error</span><span class="p">:</span> <span class="nb">Into</span><span class="o">&lt;</span><span class="n">StdError</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="nn">T</span><span class="p">::</span><span class="n">ResponseBody</span><span class="p">:</span> <span class="n">Body</span><span class="o">&lt;</span><span class="n">Data</span> <span class="o">=</span> <span class="n">Bytes</span><span class="o">&gt;</span> <span class="o">+</span> <span class="nb">Send</span> <span class="o">+</span> <span class="k">'static</span><span class="p">,</span>
    <span class="o">&lt;</span><span class="nn">T</span><span class="p">::</span><span class="n">ResponseBody</span> <span class="k">as</span> <span class="n">Body</span><span class="o">&gt;</span><span class="p">::</span><span class="n">Error</span><span class="p">:</span> <span class="nb">Into</span><span class="o">&lt;</span><span class="n">StdError</span><span class="o">&gt;</span> <span class="o">+</span> <span class="nb">Send</span><span class="p">,</span>
<span class="p">{</span>
    <span class="k">pub</span> <span class="k">fn</span> <span class="nf">new</span><span class="p">(</span><span class="n">inner</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">inner</span> <span class="o">=</span> <span class="nn">tonic</span><span class="p">::</span><span class="nn">client</span><span class="p">::</span><span class="nn">Grpc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">inner</span><span class="p">);</span>
        <span class="k">Self</span> <span class="p">{</span> <span class="n">inner</span> <span class="p">}</span>
    <span class="p">}</span>    
<span class="p">}</span>

<span class="k">pub</span> <span class="k">async</span> <span class="k">fn</span> <span class="nf">root_heartbeat</span><span class="p">(</span>
    <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span>
    <span class="n">request</span><span class="p">:</span> <span class="k">impl</span> <span class="nn">tonic</span><span class="p">::</span><span class="n">IntoRequest</span><span class="o">&lt;</span><span class="k">super</span><span class="p">::</span><span class="n">HeartbeatRequest</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nn">tonic</span><span class="p">::</span><span class="n">Response</span><span class="o">&lt;</span><span class="k">super</span><span class="p">::</span><span class="n">HeartbeatResponse</span><span class="o">&gt;</span><span class="p">,</span> <span class="nn">tonic</span><span class="p">::</span><span class="n">Status</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">self</span><span class="py">.inner</span>
        <span class="nf">.ready</span><span class="p">()</span>
        <span class="k">.await</span>
        <span class="nf">.map_err</span><span class="p">(|</span><span class="n">e</span><span class="p">|</span> <span class="p">{</span>
            <span class="nn">tonic</span><span class="p">::</span><span class="nn">Status</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span>
                <span class="nn">tonic</span><span class="p">::</span><span class="nn">Code</span><span class="p">::</span><span class="n">Unknown</span><span class="p">,</span>
                <span class="nd">format!</span><span class="p">(</span><span class="s">"Service was not ready: {}"</span><span class="p">,</span> <span class="n">e</span><span class="nf">.into</span><span class="p">()),</span>
            <span class="p">)</span>
        <span class="p">})</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">codec</span> <span class="o">=</span> <span class="nn">tonic</span><span class="p">::</span><span class="nn">codec</span><span class="p">::</span><span class="nn">ProstCodec</span><span class="p">::</span><span class="nf">default</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">path</span> <span class="o">=</span> <span class="nn">http</span><span class="p">::</span><span class="nn">uri</span><span class="p">::</span><span class="nn">PathAndQuery</span><span class="p">::</span><span class="nf">from_static</span><span class="p">(</span>
        <span class="s">"/engula.server.v1.Node/RootHeartbeat"</span><span class="p">,</span>
    <span class="p">);</span>
    <span class="k">self</span><span class="py">.inner</span><span class="nf">.unary</span><span class="p">(</span><span class="n">request</span><span class="nf">.into_request</span><span class="p">(),</span> <span class="n">path</span><span class="p">,</span> <span class="n">codec</span><span class="p">)</span><span class="k">.await</span>
<span class="p">}</span>
</code></pre></div></div>

<p>也就是说，每次调用 <code class="language-plaintext highlighter-rouge">Grpc::unary</code> 需要在栈上开辟 1K+ 的空间。如果最后使用了 <code class="language-plaintext highlighter-rouge">tokio::spawn</code>，那么还需要将它复制到堆上。无论是内存分配还是复制上的开销，对于一个高性能存储服务都是不可接受的。并且随着 <code class="language-plaintext highlighter-rouge">async fn</code> 的调用层数增加，<code class="language-plaintext highlighter-rouge">Future</code> 大小还会呈现指数增长，这一点我后面会分析。</p>

<h1 id="grpcunary-的-memory-layout-是怎样的">Grpc::unary 的 memory layout 是怎样的？</h1>

<p>那么，为何 <code class="language-plaintext highlighter-rouge">Grpc::unary</code> 返回的 <code class="language-plaintext highlighter-rouge">Future</code> 需要消耗 1K+ 的内存空间呢？</p>

<p>在 tonic/src/client/grpc.rs 中，<code class="language-plaintext highlighter-rouge">unary</code> 最终被委托给 <code class="language-plaintext highlighter-rouge">Grpc::streaming</code>，后者调用 <code class="language-plaintext highlighter-rouge">Channel::call</code> 并返回 <code class="language-plaintext highlighter-rouge">ResponseFuture</code>。</p>

<pre><code class="language-Rust">/// Send a single unary gRPC request.
pub async fn unary&lt;M1, M2, C&gt;(
    &amp;mut self,
    request: Request&lt;M1&gt;,
    path: PathAndQuery,
    codec: C,
) -&gt; Result&lt;Response&lt;M2&gt;, Status&gt;
where
    T: GrpcService&lt;BoxBody&gt;,
    T::ResponseBody: Body + Send + 'static,
    &lt;T::ResponseBody as Body&gt;::Error: Into&lt;crate::Error&gt;,
    C: Codec&lt;Encode = M1, Decode = M2&gt;,
    M1: Send + Sync + 'static,
    M2: Send + Sync + 'static,
{
    let request = request.map(|m| stream::once(future::ready(m)));
    self.client_streaming(request, path, codec).await
}

/// Send a client side streaming gRPC request.
pub async fn client_streaming&lt;S, M1, M2, C&gt;(
    &amp;mut self,
    request: Request&lt;S&gt;,
    path: PathAndQuery,
    codec: C,
) -&gt; Result&lt;Response&lt;M2&gt;, Status&gt;
where
    T: GrpcService&lt;BoxBody&gt;,
    T::ResponseBody: Body + Send + 'static,
    &lt;T::ResponseBody as Body&gt;::Error: Into&lt;crate::Error&gt;,
    S: Stream&lt;Item = M1&gt; + Send + 'static,
    C: Codec&lt;Encode = M1, Decode = M2&gt;,
    M1: Send + Sync + 'static,
    M2: Send + Sync + 'static,
{
    let (mut parts, body, extensions) =
        self.streaming(request, path, codec).await?.into_parts();

    futures_util::pin_mut!(body);

    let message = body
        .try_next()
        .await
        .map_err(|mut status| {
            status.metadata_mut().merge(parts.clone());
            status
        })?
        .ok_or_else(|| Status::new(Code::Internal, "Missing response message."))?;

    if let Some(trailers) = body.trailers().await? {
        parts.merge(trailers);
    }

    Ok(Response::from_parts(parts, message, extensions))
}

/// Send a bi-directional streaming gRPC request.
pub async fn streaming&lt;S, M1, M2, C&gt;(
    &amp;mut self,
    request: Request&lt;S&gt;,
    path: PathAndQuery,
    mut codec: C,
) -&gt; Result&lt;Response&lt;Streaming&lt;M2&gt;&gt;, Status&gt;
where
    T: GrpcService&lt;BoxBody&gt;,
    T::ResponseBody: Body + Send + 'static,
    &lt;T::ResponseBody as Body&gt;::Error: Into&lt;crate::Error&gt;,
    S: Stream&lt;Item = M1&gt; + Send + 'static,
    C: Codec&lt;Encode = M1, Decode = M2&gt;,
    M1: Send + Sync + 'static,
    M2: Send + Sync + 'static,
{
    let mut parts = Parts::default();
    parts.path_and_query = Some(path);

    let uri = Uri::from_parts(parts).expect("path_and_query only is valid Uri");

    let request = request
        .map(|s| {
            encode_client(
                codec.encoder(),
                s,
                #[cfg(feature = "compression")]
                self.send_compression_encodings,
            )
        })
        .map(BoxBody::new);

    let mut request = request.into_http(
        uri,
        http::Method::POST,
        http::Version::HTTP_2,
        SanitizeHeaders::Yes,
    );

    // Add the gRPC related HTTP headers
    request
        .headers_mut()
        .insert(TE, HeaderValue::from_static("trailers"));

    // Set the content type
    request
        .headers_mut()
        .insert(CONTENT_TYPE, HeaderValue::from_static("application/grpc"));

    #[cfg(feature = "compression")]
    {
        if let Some(encoding) = self.send_compression_encodings {
            request.headers_mut().insert(
                crate::codec::compression::ENCODING_HEADER,
                encoding.into_header_value(),
            );
        }

        if let Some(header_value) = self
            .accept_compression_encodings
            .into_accept_encoding_header_value()
        {
            request.headers_mut().insert(
                crate::codec::compression::ACCEPT_ENCODING_HEADER,
                header_value,
            );
        }
    }

    let response = self
        .inner
        .call(request)
        .await
        .map_err(|err| Status::from_error(err.into()))?;

    #[cfg(feature = "compression")]
    let encoding = CompressionEncoding::from_encoding_header(
        response.headers(),
        self.accept_compression_encodings,
    )?;

    let status_code = response.status();
    let trailers_only_status = Status::from_header_map(response.headers());

    // We do not need to check for trailers if the `grpc-status` header is present
    // with a valid code.
    let expect_additional_trailers = if let Some(status) = trailers_only_status {
        if status.code() != Code::Ok {
            return Err(status);
        }

        false
    } else {
        true
    };

    let response = response.map(|body| {
        if expect_additional_trailers {
            Streaming::new_response(
                codec.decoder(),
                body,
                status_code,
                #[cfg(feature = "compression")]
                encoding,
            )
        } else {
            Streaming::new_empty(codec.decoder(), body)
        }
    });

    Ok(Response::from_http(response))
}
</code></pre>

<p>以前面的 <code class="language-plaintext highlighter-rouge">root_heartbeat</code> 为例，最终实例化的 <code class="language-plaintext highlighter-rouge">streaming</code> 的签名为：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tonic::client::Grpc&lt;tonic::transport::Channel&gt;::streaming&lt;
    futures::stream::Once&lt;
        futures::future::Ready&lt;
            engula_api::server::v1::HeartbeatRequest&gt;&gt;,
    engula_api::server::v1::HeartbeatRequest,
    engula_api::server::v1::HeartbeatResponse,
    tonic::codec::ProstCodec&lt;
        engula_api::server::v1::HeartbeatRequest,
        engula_api::server::v1::HeartbeatResponse&gt;&gt;
</code></pre></div></div>

<p>而 <code class="language-plaintext highlighter-rouge">async fn streaming()</code> 脱糖后，经过 transform 生成的状态机的内存布局为：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>generator layout ([static generator@tonic::client::Grpc&lt;tonic::transport::Channel&gt;::streaming&lt;futures::stream::Once&lt;futures::future::Ready&lt;engula_api::server::v1::HeartbeatRequest&gt;&gt;, engula_api::server::v1::HeartbeatRequest, engula_api::server::v1::HeartbeatResponse, tonic::codec::ProstCodec&lt;engula_api::server::v1::HeartbeatRequest, engula_api::server::v1::HeartbeatResponse&gt;&gt;::{closure#0}]): Layout {
    size: Size(560 bytes),
    align: AbiAndPrefAlign {
        abi: Align(8 bytes),
        pref: Align(8 bytes),
    },
    abi: Aggregate {
        sized: true,
    },
    fields: Arbitrary {
        offsets: [
        Size(0 bytes),
        Size(8 bytes),
        Size(152 bytes),
        Size(0 bytes),
        Size(552 bytes),
        ],
    }
}
</code></pre></div></div>

<p>仔细分析 <code class="language-plaintext highlighter-rouge">streaming</code> 的代码可以发现，跨过 <code class="language-plaintext highlighter-rouge">suspend point</code> 的变量只有本地变量 <code class="language-plaintext highlighter-rouge">request</code>，预留空间 <code class="language-plaintext highlighter-rouge">response</code>:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">request</code>: <code class="language-plaintext highlighter-rouge">http::request::Request&lt;http_body::combinators::box_body::UnsyncBoxBody&lt;prost::bytes::Bytes, tonic::Status&gt;&gt;</code> size = 240 bytes</li>
  <li><code class="language-plaintext highlighter-rouge">response</code>: <code class="language-plaintext highlighter-rouge">tonic::transport::channel::ResponseFuture</code> size = 32 bytes</li>
</ul>

<p>那么 <code class="language-plaintext highlighter-rouge">request</code> + <code class="language-plaintext highlighter-rouge">response</code> + <code class="language-plaintext highlighter-rouge">tag</code> （手写状态机的理论值）应该是远小于 560 bytes。到了 <code class="language-plaintext highlighter-rouge">client_streaming</code> 这里，内存空间就增长到了 1056 bytes。</p>

<h1 id="async-fn-的-layout-是如何计算的">async fn 的 layout 是如何计算的？</h1>

<p>这里进一步分析编译器内部是如何处理 <code class="language-plaintext highlighter-rouge">async</code>, <code class="language-plaintext highlighter-rouge">await</code> 和产生状态机的，看看不符合直觉的结果是如何产生的。</p>

<h2 id="实际上-async-fn-是-generator-的语法糖">实际上 async fn 是 generator 的语法糖</h2>

<p><code class="language-plaintext highlighter-rouge">async</code> 和 <code class="language-plaintext highlighter-rouge">await</code> 都是语法糖，rust compiler 在 ast lowering 过程中进行了 desugar，并生成 hir。其中 <code class="language-plaintext highlighter-rouge">async fn</code> 会被替换为 generator (compiler/rustc_ast_lowering/src/item.rs)：</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">lower_maybe_async_body</span><span class="p">(</span>
    <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span>
    <span class="n">span</span><span class="p">:</span> <span class="n">Span</span><span class="p">,</span>
    <span class="n">decl</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">FnDecl</span><span class="p">,</span>
    <span class="n">asyncness</span><span class="p">:</span> <span class="n">Async</span><span class="p">,</span>
    <span class="n">body</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;&amp;</span><span class="n">Block</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">)</span> <span class="k">-&gt;</span> <span class="nn">hir</span><span class="p">::</span><span class="n">BodyId</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">closure_id</span> <span class="o">=</span> <span class="k">match</span> <span class="n">asyncness</span> <span class="p">{</span>
        <span class="nn">Async</span><span class="p">::</span><span class="n">Yes</span> <span class="p">{</span> <span class="n">closure_id</span><span class="p">,</span> <span class="o">..</span> <span class="p">}</span> <span class="k">=&gt;</span> <span class="n">closure_id</span><span class="p">,</span>
        <span class="nn">Async</span><span class="p">::</span><span class="n">No</span> <span class="k">=&gt;</span> <span class="k">return</span> <span class="k">self</span><span class="nf">.lower_fn_body_block</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">decl</span><span class="p">,</span> <span class="n">body</span><span class="p">),</span>
    <span class="p">};</span>

    <span class="k">self</span><span class="nf">.lower_body</span><span class="p">(|</span><span class="n">this</span><span class="p">|</span> <span class="p">{</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">parameters</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nn">hir</span><span class="p">::</span><span class="n">Param</span><span class="o">&lt;</span><span class="nv">'_</span><span class="o">&gt;&gt;</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">statements</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nn">hir</span><span class="p">::</span><span class="n">Stmt</span><span class="o">&lt;</span><span class="nv">'_</span><span class="o">&gt;&gt;</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>

        <span class="c1">// Async function parameters are lowered into the closure body so that they are</span>
        <span class="c1">// captured and so that the drop order matches the equivalent non-async functions.</span>
        <span class="c1">//</span>
        <span class="c1">// from:</span>
        <span class="c1">//</span>
        <span class="c1">//     async fn foo(&lt;pattern&gt;: &lt;ty&gt;, &lt;pattern&gt;: &lt;ty&gt;, &lt;pattern&gt;: &lt;ty&gt;) {</span>
        <span class="c1">//         &lt;body&gt;</span>
        <span class="c1">//     }</span>
        <span class="c1">//</span>
        <span class="c1">// into:</span>
        <span class="c1">//</span>
        <span class="c1">//     fn foo(__arg0: &lt;ty&gt;, __arg1: &lt;ty&gt;, __arg2: &lt;ty&gt;) {</span>
        <span class="c1">//       async move {</span>
        <span class="c1">//         let __arg2 = __arg2;</span>
        <span class="c1">//         let &lt;pattern&gt; = __arg2;</span>
        <span class="c1">//         let __arg1 = __arg1;</span>
        <span class="c1">//         let &lt;pattern&gt; = __arg1;</span>
        <span class="c1">//         let __arg0 = __arg0;</span>
        <span class="c1">//         let &lt;pattern&gt; = __arg0;</span>
        <span class="c1">//         drop-temps { &lt;body&gt; } // see comments later in fn for details</span>
        <span class="c1">//       }</span>
        <span class="c1">//     }</span>
        <span class="c1">//</span>
        <span class="c1">// If `&lt;pattern&gt;` is a simple ident, then it is lowered to a single</span>
        <span class="c1">// `let &lt;pattern&gt; = &lt;pattern&gt;;` statement as an optimization.</span>
        <span class="c1">//</span>
        <span class="c1">// Note that the body is embedded in `drop-temps`; an</span>
        <span class="c1">// equivalent desugaring would be `return { &lt;body&gt;</span>
        <span class="c1">// };`. The key point is that we wish to drop all the</span>
        <span class="c1">// let-bound variables and temporaries created in the body</span>
        <span class="c1">// (and its tail expression!) before we drop the</span>
        <span class="c1">// parameters (c.f. rust-lang/rust#64512).</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">parameter</span><span class="p">)</span> <span class="k">in</span> <span class="n">decl</span><span class="py">.inputs</span><span class="nf">.iter</span><span class="p">()</span><span class="nf">.enumerate</span><span class="p">()</span> <span class="p">{</span>
            <span class="k">let</span> <span class="n">parameter</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.lower_param</span><span class="p">(</span><span class="n">parameter</span><span class="p">);</span>
            <span class="k">let</span> <span class="n">span</span> <span class="o">=</span> <span class="n">parameter</span><span class="py">.pat.span</span><span class="p">;</span>

            <span class="c1">// Check if this is a binding pattern, if so, we can optimize and avoid adding a</span>
            <span class="c1">// `let &lt;pat&gt; = __argN;` statement. In this case, we do not rename the parameter.</span>
            <span class="k">let</span> <span class="p">(</span><span class="n">ident</span><span class="p">,</span> <span class="n">is_simple_parameter</span><span class="p">)</span> <span class="o">=</span> <span class="k">match</span> <span class="n">parameter</span><span class="py">.pat.kind</span> <span class="p">{</span>
                <span class="nn">hir</span><span class="p">::</span><span class="nn">PatKind</span><span class="p">::</span><span class="nf">Binding</span><span class="p">(</span>
                    <span class="nn">hir</span><span class="p">::</span><span class="nn">BindingAnnotation</span><span class="p">::</span><span class="n">Unannotated</span> <span class="p">|</span> <span class="nn">hir</span><span class="p">::</span><span class="nn">BindingAnnotation</span><span class="p">::</span><span class="n">Mutable</span><span class="p">,</span>
                    <span class="n">_</span><span class="p">,</span>
                    <span class="n">ident</span><span class="p">,</span>
                    <span class="n">_</span><span class="p">,</span>
                <span class="p">)</span> <span class="k">=&gt;</span> <span class="p">(</span><span class="n">ident</span><span class="p">,</span> <span class="k">true</span><span class="p">),</span>
                <span class="c1">// For `ref mut` or wildcard arguments, we can't reuse the binding, but</span>
                <span class="c1">// we can keep the same name for the parameter.</span>
                <span class="c1">// This lets rustdoc render it correctly in documentation.</span>
                <span class="nn">hir</span><span class="p">::</span><span class="nn">PatKind</span><span class="p">::</span><span class="nf">Binding</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">ident</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">(</span><span class="n">ident</span><span class="p">,</span> <span class="k">false</span><span class="p">),</span>
                <span class="nn">hir</span><span class="p">::</span><span class="nn">PatKind</span><span class="p">::</span><span class="n">Wild</span> <span class="k">=&gt;</span> <span class="p">{</span>
                    <span class="p">(</span><span class="nn">Ident</span><span class="p">::</span><span class="nf">with_dummy_span</span><span class="p">(</span><span class="nn">rustc_span</span><span class="p">::</span><span class="nn">symbol</span><span class="p">::</span><span class="nn">kw</span><span class="p">::</span><span class="n">Underscore</span><span class="p">),</span> <span class="k">false</span><span class="p">)</span>
                <span class="p">}</span>
                <span class="n">_</span> <span class="k">=&gt;</span> <span class="p">{</span>
                    <span class="c1">// Replace the ident for bindings that aren't simple.</span>
                    <span class="k">let</span> <span class="n">name</span> <span class="o">=</span> <span class="nd">format!</span><span class="p">(</span><span class="s">"__arg{}"</span><span class="p">,</span> <span class="n">index</span><span class="p">);</span>
                    <span class="k">let</span> <span class="n">ident</span> <span class="o">=</span> <span class="nn">Ident</span><span class="p">::</span><span class="nf">from_str</span><span class="p">(</span><span class="o">&amp;</span><span class="n">name</span><span class="p">);</span>

                    <span class="p">(</span><span class="n">ident</span><span class="p">,</span> <span class="k">false</span><span class="p">)</span>
                <span class="p">}</span>
            <span class="p">};</span>

            <span class="k">let</span> <span class="n">desugared_span</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.mark_span_with_reason</span><span class="p">(</span><span class="nn">DesugaringKind</span><span class="p">::</span><span class="n">Async</span><span class="p">,</span> <span class="n">span</span><span class="p">,</span> <span class="nb">None</span><span class="p">);</span>

            <span class="c1">// Construct a parameter representing `__argN: &lt;ty&gt;` to replace the parameter of the</span>
            <span class="c1">// async function.</span>
            <span class="c1">//</span>
            <span class="c1">// If this is the simple case, this parameter will end up being the same as the</span>
            <span class="c1">// original parameter, but with a different pattern id.</span>
            <span class="k">let</span> <span class="n">stmt_attrs</span> <span class="o">=</span> <span class="n">this</span><span class="py">.attrs</span><span class="nf">.get</span><span class="p">(</span><span class="o">&amp;</span><span class="n">parameter</span><span class="py">.hir_id.local_id</span><span class="p">)</span><span class="nf">.copied</span><span class="p">();</span>
            <span class="k">let</span> <span class="p">(</span><span class="n">new_parameter_pat</span><span class="p">,</span> <span class="n">new_parameter_id</span><span class="p">)</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.pat_ident</span><span class="p">(</span><span class="n">desugared_span</span><span class="p">,</span> <span class="n">ident</span><span class="p">);</span>
            <span class="k">let</span> <span class="n">new_parameter</span> <span class="o">=</span> <span class="nn">hir</span><span class="p">::</span><span class="n">Param</span> <span class="p">{</span>
                <span class="n">hir_id</span><span class="p">:</span> <span class="n">parameter</span><span class="py">.hir_id</span><span class="p">,</span>
                <span class="n">pat</span><span class="p">:</span> <span class="n">new_parameter_pat</span><span class="p">,</span>
                <span class="n">ty_span</span><span class="p">:</span> <span class="n">this</span><span class="nf">.lower_span</span><span class="p">(</span><span class="n">parameter</span><span class="py">.ty_span</span><span class="p">),</span>
                <span class="n">span</span><span class="p">:</span> <span class="n">this</span><span class="nf">.lower_span</span><span class="p">(</span><span class="n">parameter</span><span class="py">.span</span><span class="p">),</span>
            <span class="p">};</span>

            <span class="k">if</span> <span class="n">is_simple_parameter</span> <span class="p">{</span>
                <span class="c1">// If this is the simple case, then we only insert one statement that is</span>
                <span class="c1">// `let &lt;pat&gt; = &lt;pat&gt;;`. We re-use the original argument's pattern so that</span>
                <span class="c1">// `HirId`s are densely assigned.</span>
                <span class="k">let</span> <span class="n">expr</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.expr_ident</span><span class="p">(</span><span class="n">desugared_span</span><span class="p">,</span> <span class="n">ident</span><span class="p">,</span> <span class="n">new_parameter_id</span><span class="p">);</span>
                <span class="k">let</span> <span class="n">stmt</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.stmt_let_pat</span><span class="p">(</span>
                    <span class="n">stmt_attrs</span><span class="p">,</span>
                    <span class="n">desugared_span</span><span class="p">,</span>
                    <span class="nf">Some</span><span class="p">(</span><span class="n">expr</span><span class="p">),</span>
                    <span class="n">parameter</span><span class="py">.pat</span><span class="p">,</span>
                    <span class="nn">hir</span><span class="p">::</span><span class="nn">LocalSource</span><span class="p">::</span><span class="n">AsyncFn</span><span class="p">,</span>
                <span class="p">);</span>
                <span class="n">statements</span><span class="nf">.push</span><span class="p">(</span><span class="n">stmt</span><span class="p">);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="c1">// If this is not the simple case, then we construct two statements:</span>
                <span class="c1">//</span>
                <span class="c1">// ```</span>
                <span class="c1">// let __argN = __argN;</span>
                <span class="c1">// let &lt;pat&gt; = __argN;</span>
                <span class="c1">// ```</span>
                <span class="c1">//</span>
                <span class="c1">// The first statement moves the parameter into the closure and thus ensures</span>
                <span class="c1">// that the drop order is correct.</span>
                <span class="c1">//</span>
                <span class="c1">// The second statement creates the bindings that the user wrote.</span>

                <span class="c1">// Construct the `let mut __argN = __argN;` statement. It must be a mut binding</span>
                <span class="c1">// because the user may have specified a `ref mut` binding in the next</span>
                <span class="c1">// statement.</span>
                <span class="k">let</span> <span class="p">(</span><span class="n">move_pat</span><span class="p">,</span> <span class="n">move_id</span><span class="p">)</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.pat_ident_binding_mode</span><span class="p">(</span>
                    <span class="n">desugared_span</span><span class="p">,</span>
                    <span class="n">ident</span><span class="p">,</span>
                    <span class="nn">hir</span><span class="p">::</span><span class="nn">BindingAnnotation</span><span class="p">::</span><span class="n">Mutable</span><span class="p">,</span>
                <span class="p">);</span>
                <span class="k">let</span> <span class="n">move_expr</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.expr_ident</span><span class="p">(</span><span class="n">desugared_span</span><span class="p">,</span> <span class="n">ident</span><span class="p">,</span> <span class="n">new_parameter_id</span><span class="p">);</span>
                <span class="k">let</span> <span class="n">move_stmt</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.stmt_let_pat</span><span class="p">(</span>
                    <span class="nb">None</span><span class="p">,</span>
                    <span class="n">desugared_span</span><span class="p">,</span>
                    <span class="nf">Some</span><span class="p">(</span><span class="n">move_expr</span><span class="p">),</span>
                    <span class="n">move_pat</span><span class="p">,</span>
                    <span class="nn">hir</span><span class="p">::</span><span class="nn">LocalSource</span><span class="p">::</span><span class="n">AsyncFn</span><span class="p">,</span>
                <span class="p">);</span>

                <span class="c1">// Construct the `let &lt;pat&gt; = __argN;` statement. We re-use the original</span>
                <span class="c1">// parameter's pattern so that `HirId`s are densely assigned.</span>
                <span class="k">let</span> <span class="n">pattern_expr</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.expr_ident</span><span class="p">(</span><span class="n">desugared_span</span><span class="p">,</span> <span class="n">ident</span><span class="p">,</span> <span class="n">move_id</span><span class="p">);</span>
                <span class="k">let</span> <span class="n">pattern_stmt</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.stmt_let_pat</span><span class="p">(</span>
                    <span class="n">stmt_attrs</span><span class="p">,</span>
                    <span class="n">desugared_span</span><span class="p">,</span>
                    <span class="nf">Some</span><span class="p">(</span><span class="n">pattern_expr</span><span class="p">),</span>
                    <span class="n">parameter</span><span class="py">.pat</span><span class="p">,</span>
                    <span class="nn">hir</span><span class="p">::</span><span class="nn">LocalSource</span><span class="p">::</span><span class="n">AsyncFn</span><span class="p">,</span>
                <span class="p">);</span>

                <span class="n">statements</span><span class="nf">.push</span><span class="p">(</span><span class="n">move_stmt</span><span class="p">);</span>
                <span class="n">statements</span><span class="nf">.push</span><span class="p">(</span><span class="n">pattern_stmt</span><span class="p">);</span>
            <span class="p">};</span>

            <span class="n">parameters</span><span class="nf">.push</span><span class="p">(</span><span class="n">new_parameter</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="k">let</span> <span class="n">body_span</span> <span class="o">=</span> <span class="n">body</span><span class="nf">.map_or</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="p">|</span><span class="n">b</span><span class="p">|</span> <span class="n">b</span><span class="py">.span</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">async_expr</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.make_async_expr</span><span class="p">(</span>
            <span class="nn">CaptureBy</span><span class="p">::</span><span class="n">Value</span><span class="p">,</span>
            <span class="n">closure_id</span><span class="p">,</span>
            <span class="nb">None</span><span class="p">,</span>
            <span class="n">body_span</span><span class="p">,</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">AsyncGeneratorKind</span><span class="p">::</span><span class="nb">Fn</span><span class="p">,</span>
            <span class="p">|</span><span class="n">this</span><span class="p">|</span> <span class="p">{</span>
                <span class="c1">// Create a block from the user's function body:</span>
                <span class="k">let</span> <span class="n">user_body</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.lower_block_expr_opt</span><span class="p">(</span><span class="n">body_span</span><span class="p">,</span> <span class="n">body</span><span class="p">);</span>

                <span class="c1">// Transform into `drop-temps { &lt;user-body&gt; }`, an expression:</span>
                <span class="k">let</span> <span class="n">desugared_span</span> <span class="o">=</span>
                    <span class="n">this</span><span class="nf">.mark_span_with_reason</span><span class="p">(</span><span class="nn">DesugaringKind</span><span class="p">::</span><span class="n">Async</span><span class="p">,</span> <span class="n">user_body</span><span class="py">.span</span><span class="p">,</span> <span class="nb">None</span><span class="p">);</span>
                <span class="k">let</span> <span class="n">user_body</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.expr_drop_temps</span><span class="p">(</span>
                    <span class="n">desugared_span</span><span class="p">,</span>
                    <span class="n">this</span><span class="py">.arena</span><span class="nf">.alloc</span><span class="p">(</span><span class="n">user_body</span><span class="p">),</span>
                    <span class="nn">AttrVec</span><span class="p">::</span><span class="nf">new</span><span class="p">(),</span>
                <span class="p">);</span>

                <span class="c1">// As noted above, create the final block like</span>
                <span class="c1">//</span>
                <span class="c1">// ```</span>
                <span class="c1">// {</span>
                <span class="c1">//   let $param_pattern = $raw_param;</span>
                <span class="c1">//   ...</span>
                <span class="c1">//   drop-temps { &lt;user-body&gt; }</span>
                <span class="c1">// }</span>
                <span class="c1">// ```</span>
                <span class="k">let</span> <span class="n">body</span> <span class="o">=</span> <span class="n">this</span><span class="nf">.block_all</span><span class="p">(</span>
                    <span class="n">desugared_span</span><span class="p">,</span>
                    <span class="n">this</span><span class="py">.arena</span><span class="nf">.alloc_from_iter</span><span class="p">(</span><span class="n">statements</span><span class="p">),</span>
                    <span class="nf">Some</span><span class="p">(</span><span class="n">user_body</span><span class="p">),</span>
                <span class="p">);</span>

                <span class="n">this</span><span class="nf">.expr_block</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="nn">AttrVec</span><span class="p">::</span><span class="nf">new</span><span class="p">())</span>
            <span class="p">},</span>
        <span class="p">);</span>

        <span class="p">(</span>
            <span class="n">this</span><span class="py">.arena</span><span class="nf">.alloc_from_iter</span><span class="p">(</span><span class="n">parameters</span><span class="p">),</span>
            <span class="n">this</span><span class="nf">.expr</span><span class="p">(</span><span class="n">body_span</span><span class="p">,</span> <span class="n">async_expr</span><span class="p">,</span> <span class="nn">AttrVec</span><span class="p">::</span><span class="nf">new</span><span class="p">()),</span>
        <span class="p">)</span>
    <span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">async fn</code> 被替换为 generator 后，它的参数作为 captured variable 保存在 closure 中，后续称它为 upvars，在计算 <code class="language-plaintext highlighter-rouge">Layout</code> 是会使用到。</p>

<p><code class="language-plaintext highlighter-rouge">await</code> 则会被替换为 <code class="language-plaintext highlighter-rouge">poll()</code>(compiler/rustc_ast_lowering/src/expr.rs):</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cd">/// Desugar `&lt;expr&gt;.await` into:</span>
<span class="cd">/// ```ignore (pseudo-rust)</span>
<span class="cd">/// match ::std::future::IntoFuture::into_future(&lt;expr&gt;) {</span>
<span class="cd">///     mut __awaitee =&gt; loop {</span>
<span class="cd">///         match unsafe { ::std::future::Future::poll(</span>
<span class="cd">///             &lt;::std::pin::Pin&gt;::new_unchecked(&amp;mut __awaitee),</span>
<span class="cd">///             ::std::future::get_context(task_context),</span>
<span class="cd">///         ) } {</span>
<span class="cd">///             ::std::task::Poll::Ready(result) =&gt; break result,</span>
<span class="cd">///             ::std::task::Poll::Pending =&gt; {}</span>
<span class="cd">///         }</span>
<span class="cd">///         task_context = yield ();</span>
<span class="cd">///     }</span>
<span class="cd">/// }</span>
<span class="cd">/// ```</span>
<span class="k">fn</span> <span class="nf">lower_expr_await</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">dot_await_span</span><span class="p">:</span> <span class="n">Span</span><span class="p">,</span> <span class="n">expr</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Expr</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nn">hir</span><span class="p">::</span><span class="n">ExprKind</span><span class="o">&lt;</span><span class="nv">'hir</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">full_span</span> <span class="o">=</span> <span class="n">expr</span><span class="py">.span</span><span class="nf">.to</span><span class="p">(</span><span class="n">dot_await_span</span><span class="p">);</span>
    <span class="k">match</span> <span class="k">self</span><span class="py">.generator_kind</span> <span class="p">{</span>
        <span class="nf">Some</span><span class="p">(</span><span class="nn">hir</span><span class="p">::</span><span class="nn">GeneratorKind</span><span class="p">::</span><span class="nf">Async</span><span class="p">(</span><span class="n">_</span><span class="p">))</span> <span class="k">=&gt;</span> <span class="p">{}</span>
        <span class="nf">Some</span><span class="p">(</span><span class="nn">hir</span><span class="p">::</span><span class="nn">GeneratorKind</span><span class="p">::</span><span class="n">Gen</span><span class="p">)</span> <span class="p">|</span> <span class="nb">None</span> <span class="k">=&gt;</span> <span class="p">{</span>
            <span class="k">self</span><span class="py">.tcx.sess</span><span class="nf">.emit_err</span><span class="p">(</span><span class="n">AwaitOnlyInAsyncFnAndBlocks</span> <span class="p">{</span>
                <span class="n">dot_await_span</span><span class="p">,</span>
                <span class="n">item_span</span><span class="p">:</span> <span class="k">self</span><span class="py">.current_item</span><span class="p">,</span>
            <span class="p">});</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">let</span> <span class="n">span</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.mark_span_with_reason</span><span class="p">(</span><span class="nn">DesugaringKind</span><span class="p">::</span><span class="n">Await</span><span class="p">,</span> <span class="n">dot_await_span</span><span class="p">,</span> <span class="nb">None</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">gen_future_span</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.mark_span_with_reason</span><span class="p">(</span>
        <span class="nn">DesugaringKind</span><span class="p">::</span><span class="n">Await</span><span class="p">,</span>
        <span class="n">full_span</span><span class="p">,</span>
        <span class="k">self</span><span class="py">.allow_gen_future</span><span class="nf">.clone</span><span class="p">(),</span>
    <span class="p">);</span>
    <span class="k">let</span> <span class="n">expr</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.lower_expr_mut</span><span class="p">(</span><span class="n">expr</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">expr_hir_id</span> <span class="o">=</span> <span class="n">expr</span><span class="py">.hir_id</span><span class="p">;</span>

    <span class="c1">// Note that the name of this binding must not be changed to something else because</span>
    <span class="c1">// debuggers and debugger extensions expect it to be called `__awaitee`. They use</span>
    <span class="c1">// this name to identify what is being awaited by a suspended async functions.</span>
    <span class="k">let</span> <span class="n">awaitee_ident</span> <span class="o">=</span> <span class="nn">Ident</span><span class="p">::</span><span class="nf">with_dummy_span</span><span class="p">(</span><span class="nn">sym</span><span class="p">::</span><span class="n">__awaitee</span><span class="p">);</span>
    <span class="k">let</span> <span class="p">(</span><span class="n">awaitee_pat</span><span class="p">,</span> <span class="n">awaitee_pat_hid</span><span class="p">)</span> <span class="o">=</span>
        <span class="k">self</span><span class="nf">.pat_ident_binding_mode</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">awaitee_ident</span><span class="p">,</span> <span class="nn">hir</span><span class="p">::</span><span class="nn">BindingAnnotation</span><span class="p">::</span><span class="n">Mutable</span><span class="p">);</span>

    <span class="k">let</span> <span class="n">task_context_ident</span> <span class="o">=</span> <span class="nn">Ident</span><span class="p">::</span><span class="nf">with_dummy_span</span><span class="p">(</span><span class="nn">sym</span><span class="p">::</span><span class="n">_task_context</span><span class="p">);</span>

    <span class="c1">// unsafe {</span>
    <span class="c1">//     ::std::future::Future::poll(</span>
    <span class="c1">//         ::std::pin::Pin::new_unchecked(&amp;mut __awaitee),</span>
    <span class="c1">//         ::std::future::get_context(task_context),</span>
    <span class="c1">//     )</span>
    <span class="c1">// }</span>
    <span class="k">let</span> <span class="n">poll_expr</span> <span class="o">=</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">awaitee</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_ident</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">awaitee_ident</span><span class="p">,</span> <span class="n">awaitee_pat_hid</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">ref_mut_awaitee</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_mut_addr_of</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">awaitee</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">task_context</span> <span class="o">=</span> <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">task_context_hid</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.task_context</span> <span class="p">{</span>
            <span class="k">self</span><span class="nf">.expr_ident_mut</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">task_context_ident</span><span class="p">,</span> <span class="n">task_context_hid</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="c1">// Use of `await` outside of an async context, we cannot use `task_context` here.</span>
            <span class="k">self</span><span class="nf">.expr_err</span><span class="p">(</span><span class="n">span</span><span class="p">)</span>
        <span class="p">};</span>
        <span class="k">let</span> <span class="n">new_unchecked</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_call_lang_item_fn_mut</span><span class="p">(</span>
            <span class="n">span</span><span class="p">,</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">LangItem</span><span class="p">::</span><span class="n">PinNewUnchecked</span><span class="p">,</span>
            <span class="nd">arena_vec!</span><span class="p">[</span><span class="k">self</span><span class="p">;</span> <span class="n">ref_mut_awaitee</span><span class="p">],</span>
            <span class="nf">Some</span><span class="p">(</span><span class="n">expr_hir_id</span><span class="p">),</span>
        <span class="p">);</span>
        <span class="k">let</span> <span class="n">get_context</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_call_lang_item_fn_mut</span><span class="p">(</span>
            <span class="n">gen_future_span</span><span class="p">,</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">LangItem</span><span class="p">::</span><span class="n">GetContext</span><span class="p">,</span>
            <span class="nd">arena_vec!</span><span class="p">[</span><span class="k">self</span><span class="p">;</span> <span class="n">task_context</span><span class="p">],</span>
            <span class="nf">Some</span><span class="p">(</span><span class="n">expr_hir_id</span><span class="p">),</span>
        <span class="p">);</span>
        <span class="k">let</span> <span class="n">call</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_call_lang_item_fn</span><span class="p">(</span>
            <span class="n">span</span><span class="p">,</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">LangItem</span><span class="p">::</span><span class="n">FuturePoll</span><span class="p">,</span>
            <span class="nd">arena_vec!</span><span class="p">[</span><span class="k">self</span><span class="p">;</span> <span class="n">new_unchecked</span><span class="p">,</span> <span class="n">get_context</span><span class="p">],</span>
            <span class="nf">Some</span><span class="p">(</span><span class="n">expr_hir_id</span><span class="p">),</span>
        <span class="p">);</span>
        <span class="k">self</span><span class="py">.arena</span><span class="nf">.alloc</span><span class="p">(</span><span class="k">self</span><span class="nf">.expr_unsafe</span><span class="p">(</span><span class="n">call</span><span class="p">))</span>
    <span class="p">};</span>

    <span class="c1">// `::std::task::Poll::Ready(result) =&gt; break result`</span>
    <span class="k">let</span> <span class="n">loop_node_id</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.next_node_id</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">loop_hir_id</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.lower_node_id</span><span class="p">(</span><span class="n">loop_node_id</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">ready_arm</span> <span class="o">=</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">x_ident</span> <span class="o">=</span> <span class="nn">Ident</span><span class="p">::</span><span class="nf">with_dummy_span</span><span class="p">(</span><span class="nn">sym</span><span class="p">::</span><span class="n">result</span><span class="p">);</span>
        <span class="k">let</span> <span class="p">(</span><span class="n">x_pat</span><span class="p">,</span> <span class="n">x_pat_hid</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.pat_ident</span><span class="p">(</span><span class="n">gen_future_span</span><span class="p">,</span> <span class="n">x_ident</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">x_expr</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_ident</span><span class="p">(</span><span class="n">gen_future_span</span><span class="p">,</span> <span class="n">x_ident</span><span class="p">,</span> <span class="n">x_pat_hid</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">ready_field</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.single_pat_field</span><span class="p">(</span><span class="n">gen_future_span</span><span class="p">,</span> <span class="n">x_pat</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">ready_pat</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.pat_lang_item_variant</span><span class="p">(</span>
            <span class="n">span</span><span class="p">,</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">LangItem</span><span class="p">::</span><span class="n">PollReady</span><span class="p">,</span>
            <span class="n">ready_field</span><span class="p">,</span>
            <span class="nf">Some</span><span class="p">(</span><span class="n">expr_hir_id</span><span class="p">),</span>
        <span class="p">);</span>
        <span class="k">let</span> <span class="n">break_x</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.with_loop_scope</span><span class="p">(</span><span class="n">loop_node_id</span><span class="p">,</span> <span class="k">move</span> <span class="p">|</span><span class="n">this</span><span class="p">|</span> <span class="p">{</span>
            <span class="k">let</span> <span class="n">expr_break</span> <span class="o">=</span>
                <span class="nn">hir</span><span class="p">::</span><span class="nn">ExprKind</span><span class="p">::</span><span class="nf">Break</span><span class="p">(</span><span class="n">this</span><span class="nf">.lower_loop_destination</span><span class="p">(</span><span class="nb">None</span><span class="p">),</span> <span class="nf">Some</span><span class="p">(</span><span class="n">x_expr</span><span class="p">));</span>
            <span class="n">this</span><span class="py">.arena</span><span class="nf">.alloc</span><span class="p">(</span><span class="n">this</span><span class="nf">.expr</span><span class="p">(</span><span class="n">gen_future_span</span><span class="p">,</span> <span class="n">expr_break</span><span class="p">,</span> <span class="nn">AttrVec</span><span class="p">::</span><span class="nf">new</span><span class="p">()))</span>
        <span class="p">});</span>
        <span class="k">self</span><span class="nf">.arm</span><span class="p">(</span><span class="n">ready_pat</span><span class="p">,</span> <span class="n">break_x</span><span class="p">)</span>
    <span class="p">};</span>

    <span class="c1">// `::std::task::Poll::Pending =&gt; {}`</span>
    <span class="k">let</span> <span class="n">pending_arm</span> <span class="o">=</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">pending_pat</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.pat_lang_item_variant</span><span class="p">(</span>
            <span class="n">span</span><span class="p">,</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">LangItem</span><span class="p">::</span><span class="n">PollPending</span><span class="p">,</span>
            <span class="o">&amp;</span><span class="p">[],</span>
            <span class="nf">Some</span><span class="p">(</span><span class="n">expr_hir_id</span><span class="p">),</span>
        <span class="p">);</span>
        <span class="k">let</span> <span class="n">empty_block</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_block_empty</span><span class="p">(</span><span class="n">span</span><span class="p">);</span>
        <span class="k">self</span><span class="nf">.arm</span><span class="p">(</span><span class="n">pending_pat</span><span class="p">,</span> <span class="n">empty_block</span><span class="p">)</span>
    <span class="p">};</span>

    <span class="k">let</span> <span class="n">inner_match_stmt</span> <span class="o">=</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">match_expr</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_match</span><span class="p">(</span>
            <span class="n">span</span><span class="p">,</span>
            <span class="n">poll_expr</span><span class="p">,</span>
            <span class="nd">arena_vec!</span><span class="p">[</span><span class="k">self</span><span class="p">;</span> <span class="n">ready_arm</span><span class="p">,</span> <span class="n">pending_arm</span><span class="p">],</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">MatchSource</span><span class="p">::</span><span class="n">AwaitDesugar</span><span class="p">,</span>
        <span class="p">);</span>
        <span class="k">self</span><span class="nf">.stmt_expr</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">match_expr</span><span class="p">)</span>
    <span class="p">};</span>

    <span class="c1">// task_context = yield ();</span>
    <span class="k">let</span> <span class="n">yield_stmt</span> <span class="o">=</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">unit</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_unit</span><span class="p">(</span><span class="n">span</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">yield_expr</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr</span><span class="p">(</span>
            <span class="n">span</span><span class="p">,</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">ExprKind</span><span class="p">::</span><span class="nf">Yield</span><span class="p">(</span><span class="n">unit</span><span class="p">,</span> <span class="nn">hir</span><span class="p">::</span><span class="nn">YieldSource</span><span class="p">::</span><span class="n">Await</span> <span class="p">{</span> <span class="n">expr</span><span class="p">:</span> <span class="nf">Some</span><span class="p">(</span><span class="n">expr_hir_id</span><span class="p">)</span> <span class="p">}),</span>
            <span class="nn">AttrVec</span><span class="p">::</span><span class="nf">new</span><span class="p">(),</span>
        <span class="p">);</span>
        <span class="k">let</span> <span class="n">yield_expr</span> <span class="o">=</span> <span class="k">self</span><span class="py">.arena</span><span class="nf">.alloc</span><span class="p">(</span><span class="n">yield_expr</span><span class="p">);</span>

        <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">task_context_hid</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.task_context</span> <span class="p">{</span>
            <span class="k">let</span> <span class="n">lhs</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_ident</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">task_context_ident</span><span class="p">,</span> <span class="n">task_context_hid</span><span class="p">);</span>
            <span class="k">let</span> <span class="n">assign</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr</span><span class="p">(</span>
                <span class="n">span</span><span class="p">,</span>
                <span class="nn">hir</span><span class="p">::</span><span class="nn">ExprKind</span><span class="p">::</span><span class="nf">Assign</span><span class="p">(</span><span class="n">lhs</span><span class="p">,</span> <span class="n">yield_expr</span><span class="p">,</span> <span class="k">self</span><span class="nf">.lower_span</span><span class="p">(</span><span class="n">span</span><span class="p">)),</span>
                <span class="nn">AttrVec</span><span class="p">::</span><span class="nf">new</span><span class="p">(),</span>
            <span class="p">);</span>
            <span class="k">self</span><span class="nf">.stmt_expr</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">assign</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="c1">// Use of `await` outside of an async context. Return `yield_expr` so that we can</span>
            <span class="c1">// proceed with type checking.</span>
            <span class="k">self</span><span class="nf">.stmt</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="nn">hir</span><span class="p">::</span><span class="nn">StmtKind</span><span class="p">::</span><span class="nf">Semi</span><span class="p">(</span><span class="n">yield_expr</span><span class="p">))</span>
        <span class="p">}</span>
    <span class="p">};</span>

    <span class="k">let</span> <span class="n">loop_block</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.block_all</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="nd">arena_vec!</span><span class="p">[</span><span class="k">self</span><span class="p">;</span> <span class="n">inner_match_stmt</span><span class="p">,</span> <span class="n">yield_stmt</span><span class="p">],</span> <span class="nb">None</span><span class="p">);</span>

    <span class="c1">// loop { .. }</span>
    <span class="k">let</span> <span class="n">loop_expr</span> <span class="o">=</span> <span class="k">self</span><span class="py">.arena</span><span class="nf">.alloc</span><span class="p">(</span><span class="nn">hir</span><span class="p">::</span><span class="n">Expr</span> <span class="p">{</span>
        <span class="n">hir_id</span><span class="p">:</span> <span class="n">loop_hir_id</span><span class="p">,</span>
        <span class="n">kind</span><span class="p">:</span> <span class="nn">hir</span><span class="p">::</span><span class="nn">ExprKind</span><span class="p">::</span><span class="nf">Loop</span><span class="p">(</span>
            <span class="n">loop_block</span><span class="p">,</span>
            <span class="nb">None</span><span class="p">,</span>
            <span class="nn">hir</span><span class="p">::</span><span class="nn">LoopSource</span><span class="p">::</span><span class="n">Loop</span><span class="p">,</span>
            <span class="k">self</span><span class="nf">.lower_span</span><span class="p">(</span><span class="n">span</span><span class="p">),</span>
        <span class="p">),</span>
        <span class="n">span</span><span class="p">:</span> <span class="k">self</span><span class="nf">.lower_span</span><span class="p">(</span><span class="n">span</span><span class="p">),</span>
    <span class="p">});</span>

    <span class="c1">// mut __awaitee =&gt; loop { ... }</span>
    <span class="k">let</span> <span class="n">awaitee_arm</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.arm</span><span class="p">(</span><span class="n">awaitee_pat</span><span class="p">,</span> <span class="n">loop_expr</span><span class="p">);</span>

    <span class="c1">// `match ::std::future::IntoFuture::into_future(&lt;expr&gt;) { ... }`</span>
    <span class="k">let</span> <span class="n">into_future_span</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.mark_span_with_reason</span><span class="p">(</span>
        <span class="nn">DesugaringKind</span><span class="p">::</span><span class="n">Await</span><span class="p">,</span>
        <span class="n">dot_await_span</span><span class="p">,</span>
        <span class="k">self</span><span class="py">.allow_into_future</span><span class="nf">.clone</span><span class="p">(),</span>
    <span class="p">);</span>
    <span class="k">let</span> <span class="n">into_future_expr</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.expr_call_lang_item_fn</span><span class="p">(</span>
        <span class="n">into_future_span</span><span class="p">,</span>
        <span class="nn">hir</span><span class="p">::</span><span class="nn">LangItem</span><span class="p">::</span><span class="n">IntoFutureIntoFuture</span><span class="p">,</span>
        <span class="nd">arena_vec!</span><span class="p">[</span><span class="k">self</span><span class="p">;</span> <span class="n">expr</span><span class="p">],</span>
        <span class="nf">Some</span><span class="p">(</span><span class="n">expr_hir_id</span><span class="p">),</span>
    <span class="p">);</span>

    <span class="c1">// match &lt;into_future_expr&gt; {</span>
    <span class="c1">//     mut __awaitee =&gt; loop { .. }</span>
    <span class="c1">// }</span>
    <span class="nn">hir</span><span class="p">::</span><span class="nn">ExprKind</span><span class="p">::</span><span class="nf">Match</span><span class="p">(</span>
        <span class="n">into_future_expr</span><span class="p">,</span>
        <span class="nd">arena_vec!</span><span class="p">[</span><span class="k">self</span><span class="p">;</span> <span class="n">awaitee_arm</span><span class="p">],</span>
        <span class="nn">hir</span><span class="p">::</span><span class="nn">MatchSource</span><span class="p">::</span><span class="n">AwaitDesugar</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="generator-会被替换为-generatorstate">generator 会被替换为 GeneratorState</h2>

<p>此后 hir 会转换为 mir，generator 在 mir_transform 中被替换为 <code class="language-plaintext highlighter-rouge">GeneratorState</code>(compiler/rustc_mir_transform/src/generator.rs):</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;</span> <span class="n">MirPass</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;</span> <span class="k">for</span> <span class="n">StateTransform</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">run_pass</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="n">tcx</span><span class="p">:</span> <span class="n">TyCtxt</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">body</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Body</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">yield_ty</span><span class="p">)</span> <span class="o">=</span> <span class="n">body</span><span class="nf">.yield_ty</span><span class="p">()</span> <span class="k">else</span> <span class="p">{</span>
            <span class="c1">// This only applies to generators</span>
            <span class="k">return</span><span class="p">;</span>
        <span class="p">};</span>

        <span class="nd">assert!</span><span class="p">(</span><span class="n">body</span><span class="nf">.generator_drop</span><span class="p">()</span><span class="nf">.is_none</span><span class="p">());</span>
        <span class="nf">dump_mir</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="nb">None</span><span class="p">,</span> <span class="s">"generator_before"</span><span class="p">,</span> <span class="o">&amp;</span><span class="mi">0</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="p">|</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">|</span> <span class="nf">Ok</span><span class="p">(()));</span>

        <span class="c1">// The first argument is the generator type passed by value</span>
        <span class="k">let</span> <span class="n">gen_ty</span> <span class="o">=</span> <span class="n">body</span><span class="py">.local_decls.raw</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="py">.ty</span><span class="p">;</span>

        <span class="c1">// Get the interior types and substs which typeck computed</span>
        <span class="k">let</span> <span class="p">(</span><span class="n">upvars</span><span class="p">,</span> <span class="n">interior</span><span class="p">,</span> <span class="n">discr_ty</span><span class="p">,</span> <span class="n">movable</span><span class="p">)</span> <span class="o">=</span> <span class="k">match</span> <span class="o">*</span><span class="n">gen_ty</span><span class="nf">.kind</span><span class="p">()</span> <span class="p">{</span>
            <span class="nn">ty</span><span class="p">::</span><span class="nf">Generator</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">substs</span><span class="p">,</span> <span class="n">movability</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
                <span class="k">let</span> <span class="n">substs</span> <span class="o">=</span> <span class="n">substs</span><span class="nf">.as_generator</span><span class="p">();</span>
                <span class="p">(</span>
                    <span class="n">substs</span><span class="nf">.upvar_tys</span><span class="p">()</span><span class="nf">.collect</span><span class="p">(),</span>
                    <span class="n">substs</span><span class="nf">.witness</span><span class="p">(),</span>
                    <span class="n">substs</span><span class="nf">.discr_ty</span><span class="p">(</span><span class="n">tcx</span><span class="p">),</span>
                    <span class="n">movability</span> <span class="o">==</span> <span class="nn">hir</span><span class="p">::</span><span class="nn">Movability</span><span class="p">::</span><span class="n">Movable</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">}</span>
            <span class="n">_</span> <span class="k">=&gt;</span> <span class="p">{</span>
                <span class="n">tcx</span><span class="py">.sess</span>
                    <span class="nf">.delay_span_bug</span><span class="p">(</span><span class="n">body</span><span class="py">.span</span><span class="p">,</span> <span class="o">&amp;</span><span class="nd">format!</span><span class="p">(</span><span class="s">"unexpected generator type {}"</span><span class="p">,</span> <span class="n">gen_ty</span><span class="p">));</span>
                <span class="k">return</span><span class="p">;</span>
            <span class="p">}</span>
        <span class="p">};</span>

        <span class="c1">// Compute GeneratorState&lt;yield_ty, return_ty&gt;</span>
        <span class="k">let</span> <span class="n">state_did</span> <span class="o">=</span> <span class="n">tcx</span><span class="nf">.require_lang_item</span><span class="p">(</span><span class="nn">LangItem</span><span class="p">::</span><span class="n">GeneratorState</span><span class="p">,</span> <span class="nb">None</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">state_adt_ref</span> <span class="o">=</span> <span class="n">tcx</span><span class="nf">.adt_def</span><span class="p">(</span><span class="n">state_did</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">state_substs</span> <span class="o">=</span> <span class="n">tcx</span><span class="nf">.intern_substs</span><span class="p">(</span><span class="o">&amp;</span><span class="p">[</span><span class="n">yield_ty</span><span class="nf">.into</span><span class="p">(),</span> <span class="n">body</span><span class="nf">.return_ty</span><span class="p">()</span><span class="nf">.into</span><span class="p">()]);</span>
        <span class="k">let</span> <span class="n">ret_ty</span> <span class="o">=</span> <span class="n">tcx</span><span class="nf">.mk_adt</span><span class="p">(</span><span class="n">state_adt_ref</span><span class="p">,</span> <span class="n">state_substs</span><span class="p">);</span>

        <span class="c1">// We rename RETURN_PLACE which has type mir.return_ty to new_ret_local</span>
        <span class="c1">// RETURN_PLACE then is a fresh unused local with type ret_ty.</span>
        <span class="k">let</span> <span class="n">new_ret_local</span> <span class="o">=</span> <span class="nf">replace_local</span><span class="p">(</span><span class="n">RETURN_PLACE</span><span class="p">,</span> <span class="n">ret_ty</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">tcx</span><span class="p">);</span>

        <span class="c1">// We also replace the resume argument and insert an `Assign`.</span>
        <span class="c1">// This is needed because the resume argument `_2` might be live across a `yield`, in which</span>
        <span class="c1">// case there is no `Assign` to it that the transform can turn into a store to the generator</span>
        <span class="c1">// state. After the yield the slot in the generator state would then be uninitialized.</span>
        <span class="k">let</span> <span class="n">resume_local</span> <span class="o">=</span> <span class="nn">Local</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">new_resume_local</span> <span class="o">=</span>
            <span class="nf">replace_local</span><span class="p">(</span><span class="n">resume_local</span><span class="p">,</span> <span class="n">body</span><span class="py">.local_decls</span><span class="p">[</span><span class="n">resume_local</span><span class="p">]</span><span class="py">.ty</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">tcx</span><span class="p">);</span>

        <span class="c1">// When first entering the generator, move the resume argument into its new local.</span>
        <span class="k">let</span> <span class="n">source_info</span> <span class="o">=</span> <span class="nn">SourceInfo</span><span class="p">::</span><span class="nf">outermost</span><span class="p">(</span><span class="n">body</span><span class="py">.span</span><span class="p">);</span>
        <span class="k">let</span> <span class="n">stmts</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">body</span><span class="nf">.basic_blocks_mut</span><span class="p">()[</span><span class="nn">BasicBlock</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span><span class="py">.statements</span><span class="p">;</span>
        <span class="n">stmts</span><span class="nf">.insert</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span>
            <span class="n">Statement</span> <span class="p">{</span>
                <span class="n">source_info</span><span class="p">,</span>
                <span class="n">kind</span><span class="p">:</span> <span class="nn">StatementKind</span><span class="p">::</span><span class="nf">Assign</span><span class="p">(</span><span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">((</span>
                    <span class="n">new_resume_local</span><span class="nf">.into</span><span class="p">(),</span>
                    <span class="nn">Rvalue</span><span class="p">::</span><span class="nf">Use</span><span class="p">(</span><span class="nn">Operand</span><span class="p">::</span><span class="nf">Move</span><span class="p">(</span><span class="n">resume_local</span><span class="nf">.into</span><span class="p">())),</span>
                <span class="p">))),</span>
            <span class="p">},</span>
        <span class="p">);</span>

        <span class="k">let</span> <span class="n">always_live_locals</span> <span class="o">=</span> <span class="nf">always_storage_live_locals</span><span class="p">(</span><span class="o">&amp;</span><span class="n">body</span><span class="p">);</span>

        <span class="k">let</span> <span class="n">liveness_info</span> <span class="o">=</span>
            <span class="nf">locals_live_across_suspend_points</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">always_live_locals</span><span class="p">,</span> <span class="n">movable</span><span class="p">);</span>

        <span class="nf">sanitize_witness</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">interior</span><span class="p">,</span> <span class="n">upvars</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">liveness_info</span><span class="py">.saved_locals</span><span class="p">);</span>

        <span class="k">if</span> <span class="n">tcx</span><span class="py">.sess.opts.unstable_opts.validate_mir</span> <span class="p">{</span>
            <span class="k">let</span> <span class="k">mut</span> <span class="n">vis</span> <span class="o">=</span> <span class="n">EnsureGeneratorFieldAssignmentsNeverAlias</span> <span class="p">{</span>
                <span class="n">assigned_local</span><span class="p">:</span> <span class="nb">None</span><span class="p">,</span>
                <span class="n">saved_locals</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">liveness_info</span><span class="py">.saved_locals</span><span class="p">,</span>
                <span class="n">storage_conflicts</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">liveness_info</span><span class="py">.storage_conflicts</span><span class="p">,</span>
            <span class="p">};</span>

            <span class="n">vis</span><span class="nf">.visit_body</span><span class="p">(</span><span class="n">body</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="c1">// Extract locals which are live across suspension point into `layout`</span>
        <span class="c1">// `remap` gives a mapping from local indices onto generator struct indices</span>
        <span class="c1">// `storage_liveness` tells us which locals have live storage at suspension points</span>
        <span class="k">let</span> <span class="p">(</span><span class="n">remap</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">storage_liveness</span><span class="p">)</span> <span class="o">=</span> <span class="nf">compute_layout</span><span class="p">(</span><span class="n">liveness_info</span><span class="p">,</span> <span class="n">body</span><span class="p">);</span>

        <span class="k">let</span> <span class="n">can_return</span> <span class="o">=</span> <span class="nf">can_return</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">tcx</span><span class="nf">.param_env</span><span class="p">(</span><span class="n">body</span><span class="py">.source</span><span class="nf">.def_id</span><span class="p">()));</span>

        <span class="c1">// Run the transformation which converts Places from Local to generator struct</span>
        <span class="c1">// accesses for locals in `remap`.</span>
        <span class="c1">// It also rewrites `return x` and `yield y` as writing a new generator state and returning</span>
        <span class="c1">// GeneratorState::Complete(x) and GeneratorState::Yielded(y) respectively.</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">transform</span> <span class="o">=</span> <span class="n">TransformVisitor</span> <span class="p">{</span>
            <span class="n">tcx</span><span class="p">,</span>
            <span class="n">state_adt_ref</span><span class="p">,</span>
            <span class="n">state_substs</span><span class="p">,</span>
            <span class="n">remap</span><span class="p">,</span>
            <span class="n">storage_liveness</span><span class="p">,</span>
            <span class="n">always_live_locals</span><span class="p">,</span>
            <span class="n">suspension_points</span><span class="p">:</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">(),</span>
            <span class="n">new_ret_local</span><span class="p">,</span>
            <span class="n">discr_ty</span><span class="p">,</span>
        <span class="p">};</span>
        <span class="n">transform</span><span class="nf">.visit_body</span><span class="p">(</span><span class="n">body</span><span class="p">);</span>

        <span class="c1">// Update our MIR struct to reflect the changes we've made</span>
        <span class="n">body</span><span class="py">.arg_count</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="c1">// self, resume arg</span>
        <span class="n">body</span><span class="py">.spread_arg</span> <span class="o">=</span> <span class="nb">None</span><span class="p">;</span>

        <span class="n">body</span><span class="py">.generator</span><span class="nf">.as_mut</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">()</span><span class="py">.yield_ty</span> <span class="o">=</span> <span class="nb">None</span><span class="p">;</span>
        <span class="n">body</span><span class="py">.generator</span><span class="nf">.as_mut</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">()</span><span class="py">.generator_layout</span> <span class="o">=</span> <span class="nf">Some</span><span class="p">(</span><span class="n">layout</span><span class="p">);</span>

        <span class="c1">// Insert `drop(generator_struct)` which is used to drop upvars for generators in</span>
        <span class="c1">// the unresumed state.</span>
        <span class="c1">// This is expanded to a drop ladder in `elaborate_generator_drops`.</span>
        <span class="k">let</span> <span class="n">drop_clean</span> <span class="o">=</span> <span class="nf">insert_clean_drop</span><span class="p">(</span><span class="n">body</span><span class="p">);</span>

        <span class="nf">dump_mir</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="nb">None</span><span class="p">,</span> <span class="s">"generator_pre-elab"</span><span class="p">,</span> <span class="o">&amp;</span><span class="mi">0</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="p">|</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">|</span> <span class="nf">Ok</span><span class="p">(()));</span>

        <span class="c1">// Expand `drop(generator_struct)` to a drop ladder which destroys upvars.</span>
        <span class="c1">// If any upvars are moved out of, drop elaboration will handle upvar destruction.</span>
        <span class="c1">// However we need to also elaborate the code generated by `insert_clean_drop`.</span>
        <span class="nf">elaborate_generator_drops</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="n">body</span><span class="p">);</span>

        <span class="nf">dump_mir</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="nb">None</span><span class="p">,</span> <span class="s">"generator_post-transform"</span><span class="p">,</span> <span class="o">&amp;</span><span class="mi">0</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="p">|</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">|</span> <span class="nf">Ok</span><span class="p">(()));</span>

        <span class="c1">// Create a copy of our MIR and use it to create the drop shim for the generator</span>
        <span class="k">let</span> <span class="n">drop_shim</span> <span class="o">=</span> <span class="nf">create_generator_drop_shim</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">transform</span><span class="p">,</span> <span class="n">gen_ty</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">drop_clean</span><span class="p">);</span>

        <span class="n">body</span><span class="py">.generator</span><span class="nf">.as_mut</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">()</span><span class="py">.generator_drop</span> <span class="o">=</span> <span class="nf">Some</span><span class="p">(</span><span class="n">drop_shim</span><span class="p">);</span>

        <span class="c1">// Create the Generator::resume function</span>
        <span class="nf">create_generator_resume_function</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="n">transform</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">can_return</span><span class="p">);</span>

        <span class="c1">// Run derefer to fix Derefs that are not in the first place</span>
        <span class="nf">deref_finder</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="n">body</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>第 85 行 <code class="language-plaintext highlighter-rouge">compute_layout</code> 计算出 <code class="language-plaintext highlighter-rouge">GeneratorLayout</code>，并在 111 行保存到 <code class="language-plaintext highlighter-rouge">body.generator</code> 中。这里的 <code class="language-plaintext highlighter-rouge">GeneratorLayout</code> 就是 <code class="language-plaintext highlighter-rouge">GeneratorState</code> 的内存空间，它分成两部分：<code class="language-plaintext highlighter-rouge">prefix</code> + <code class="language-plaintext highlighter-rouge">variants</code>。<code class="language-plaintext highlighter-rouge">prefix</code> 保存了会跨越 <code class="language-plaintext highlighter-rouge">suspend point</code> 的变量，<code class="language-plaintext highlighter-rouge">variants</code> 是不同的 state，其中保存了只会在当前 state 使用到的变量。</p>

<h2 id="generatorstate-的内存布局是如何计算的">GeneratorState 的内存布局是如何计算的？</h2>

<p>编译器在代码生成阶段会根据前面计算得到的 <code class="language-plaintext highlighter-rouge">GeneratorLayout</code> 算出最终的内存布局 <code class="language-plaintext highlighter-rouge">Layout</code>(compiler/rustc_middle/src/ty/layout.rs):</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cd">/// Compute the full generator layout.</span>
<span class="k">fn</span> <span class="nf">generator_layout</span><span class="p">(</span>
    <span class="o">&amp;</span><span class="k">self</span><span class="p">,</span>
    <span class="n">ty</span><span class="p">:</span> <span class="n">Ty</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">def_id</span><span class="p">:</span> <span class="nn">hir</span><span class="p">::</span><span class="nn">def_id</span><span class="p">::</span><span class="n">DefId</span><span class="p">,</span>
    <span class="n">substs</span><span class="p">:</span> <span class="n">SubstsRef</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">Layout</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">LayoutError</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="k">use</span> <span class="nn">SavedLocalEligibility</span><span class="p">::</span><span class="o">*</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">tcx</span> <span class="o">=</span> <span class="k">self</span><span class="py">.tcx</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">subst_field</span> <span class="o">=</span> <span class="p">|</span><span class="n">ty</span><span class="p">:</span> <span class="n">Ty</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;</span><span class="p">|</span> <span class="nf">EarlyBinder</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span><span class="nf">.subst</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="n">substs</span><span class="p">);</span>

    <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">info</span><span class="p">)</span> <span class="o">=</span> <span class="n">tcx</span><span class="nf">.generator_layout</span><span class="p">(</span><span class="n">def_id</span><span class="p">)</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">return</span> <span class="nf">Err</span><span class="p">(</span><span class="nn">LayoutError</span><span class="p">::</span><span class="nf">Unknown</span><span class="p">(</span><span class="n">ty</span><span class="p">));</span>
    <span class="p">};</span>
    <span class="k">let</span> <span class="p">(</span><span class="n">ineligible_locals</span><span class="p">,</span> <span class="n">assignments</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.generator_saved_local_eligibility</span><span class="p">(</span><span class="o">&amp;</span><span class="n">info</span><span class="p">);</span>

    <span class="c1">// Build a prefix layout, including "promoting" all ineligible</span>
    <span class="c1">// locals as part of the prefix. We compute the layout of all of</span>
    <span class="c1">// these fields at once to get optimal packing.</span>
    <span class="k">let</span> <span class="n">tag_index</span> <span class="o">=</span> <span class="n">substs</span><span class="nf">.as_generator</span><span class="p">()</span><span class="nf">.prefix_tys</span><span class="p">()</span><span class="nf">.count</span><span class="p">();</span>

    <span class="c1">// `info.variant_fields` already accounts for the reserved variants, so no need to add them.</span>
    <span class="k">let</span> <span class="n">max_discr</span> <span class="o">=</span> <span class="p">(</span><span class="n">info</span><span class="py">.variant_fields</span><span class="nf">.len</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="nb">u128</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">discr_int</span> <span class="o">=</span> <span class="nn">Integer</span><span class="p">::</span><span class="nf">fit_unsigned</span><span class="p">(</span><span class="n">max_discr</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">discr_int_ty</span> <span class="o">=</span> <span class="n">discr_int</span><span class="nf">.to_ty</span><span class="p">(</span><span class="n">tcx</span><span class="p">,</span> <span class="k">false</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">tag</span> <span class="o">=</span> <span class="nn">Scalar</span><span class="p">::</span><span class="n">Initialized</span> <span class="p">{</span>
        <span class="n">value</span><span class="p">:</span> <span class="nn">Primitive</span><span class="p">::</span><span class="nf">Int</span><span class="p">(</span><span class="n">discr_int</span><span class="p">,</span> <span class="k">false</span><span class="p">),</span>
        <span class="n">valid_range</span><span class="p">:</span> <span class="n">WrappingRange</span> <span class="p">{</span> <span class="n">start</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="p">:</span> <span class="n">max_discr</span> <span class="p">},</span>
    <span class="p">};</span>
    <span class="k">let</span> <span class="n">tag_layout</span> <span class="o">=</span> <span class="k">self</span><span class="py">.tcx</span><span class="nf">.intern_layout</span><span class="p">(</span><span class="nn">LayoutS</span><span class="p">::</span><span class="nf">scalar</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">));</span>
    <span class="k">let</span> <span class="n">tag_layout</span> <span class="o">=</span> <span class="n">TyAndLayout</span> <span class="p">{</span> <span class="n">ty</span><span class="p">:</span> <span class="n">discr_int_ty</span><span class="p">,</span> <span class="n">layout</span><span class="p">:</span> <span class="n">tag_layout</span> <span class="p">};</span>

    <span class="k">let</span> <span class="n">promoted_layouts</span> <span class="o">=</span> <span class="n">ineligible_locals</span>
        <span class="nf">.iter</span><span class="p">()</span>
        <span class="nf">.map</span><span class="p">(|</span><span class="n">local</span><span class="p">|</span> <span class="nf">subst_field</span><span class="p">(</span><span class="n">info</span><span class="py">.field_tys</span><span class="p">[</span><span class="n">local</span><span class="p">]))</span>
        <span class="nf">.map</span><span class="p">(|</span><span class="n">ty</span><span class="p">|</span> <span class="n">tcx</span><span class="nf">.mk_maybe_uninit</span><span class="p">(</span><span class="n">ty</span><span class="p">))</span>
        <span class="nf">.map</span><span class="p">(|</span><span class="n">ty</span><span class="p">|</span> <span class="k">self</span><span class="nf">.layout_of</span><span class="p">(</span><span class="n">ty</span><span class="p">));</span>
    <span class="k">let</span> <span class="n">prefix_layouts</span> <span class="o">=</span> <span class="n">substs</span>
        <span class="nf">.as_generator</span><span class="p">()</span>
        <span class="nf">.prefix_tys</span><span class="p">()</span>
        <span class="nf">.map</span><span class="p">(|</span><span class="n">ty</span><span class="p">|</span> <span class="k">self</span><span class="nf">.layout_of</span><span class="p">(</span><span class="n">ty</span><span class="p">))</span>
        <span class="nf">.chain</span><span class="p">(</span><span class="nn">iter</span><span class="p">::</span><span class="nf">once</span><span class="p">(</span><span class="nf">Ok</span><span class="p">(</span><span class="n">tag_layout</span><span class="p">)))</span>
        <span class="nf">.chain</span><span class="p">(</span><span class="n">promoted_layouts</span><span class="p">)</span>
        <span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">prefix</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.univariant_uninterned</span><span class="p">(</span>
        <span class="n">ty</span><span class="p">,</span>
        <span class="o">&amp;</span><span class="n">prefix_layouts</span><span class="p">,</span>
        <span class="o">&amp;</span><span class="nn">ReprOptions</span><span class="p">::</span><span class="nf">default</span><span class="p">(),</span>
        <span class="nn">StructKind</span><span class="p">::</span><span class="n">AlwaysSized</span><span class="p">,</span>
    <span class="p">)</span><span class="o">?</span><span class="p">;</span>

    <span class="k">let</span> <span class="p">(</span><span class="n">prefix_size</span><span class="p">,</span> <span class="n">prefix_align</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">prefix</span><span class="py">.size</span><span class="p">,</span> <span class="n">prefix</span><span class="py">.align</span><span class="p">);</span>

    <span class="c1">// Split the prefix layout into the "outer" fields (upvars and</span>
    <span class="c1">// discriminant) and the "promoted" fields. Promoted fields will</span>
    <span class="c1">// get included in each variant that requested them in</span>
    <span class="c1">// GeneratorLayout.</span>
    <span class="nd">debug!</span><span class="p">(</span><span class="s">"prefix = {:#?}"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">);</span>
    <span class="k">let</span> <span class="p">(</span><span class="n">outer_fields</span><span class="p">,</span> <span class="n">promoted_offsets</span><span class="p">,</span> <span class="n">promoted_memory_index</span><span class="p">)</span> <span class="o">=</span> <span class="k">match</span> <span class="n">prefix</span><span class="py">.fields</span> <span class="p">{</span>
        <span class="nn">FieldsShape</span><span class="p">::</span><span class="n">Arbitrary</span> <span class="p">{</span> <span class="k">mut</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">memory_index</span> <span class="p">}</span> <span class="k">=&gt;</span> <span class="p">{</span>
            <span class="k">let</span> <span class="k">mut</span> <span class="n">inverse_memory_index</span> <span class="o">=</span> <span class="nf">invert_mapping</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memory_index</span><span class="p">);</span>

            <span class="c1">// "a" (`0..b_start`) and "b" (`b_start..`) correspond to</span>
            <span class="c1">// "outer" and "promoted" fields respectively.</span>
            <span class="k">let</span> <span class="n">b_start</span> <span class="o">=</span> <span class="p">(</span><span class="n">tag_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="nb">u32</span><span class="p">;</span>
            <span class="k">let</span> <span class="n">offsets_b</span> <span class="o">=</span> <span class="n">offsets</span><span class="nf">.split_off</span><span class="p">(</span><span class="n">b_start</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">);</span>
            <span class="k">let</span> <span class="n">offsets_a</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">;</span>

            <span class="c1">// Disentangle the "a" and "b" components of `inverse_memory_index`</span>
            <span class="c1">// by preserving the order but keeping only one disjoint "half" each.</span>
            <span class="c1">// FIXME(eddyb) build a better abstraction for permutations, if possible.</span>
            <span class="k">let</span> <span class="n">inverse_memory_index_b</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;</span> <span class="o">=</span>
                <span class="n">inverse_memory_index</span><span class="nf">.iter</span><span class="p">()</span><span class="nf">.filter_map</span><span class="p">(|</span><span class="o">&amp;</span><span class="n">i</span><span class="p">|</span> <span class="n">i</span><span class="nf">.checked_sub</span><span class="p">(</span><span class="n">b_start</span><span class="p">))</span><span class="nf">.collect</span><span class="p">();</span>
            <span class="n">inverse_memory_index</span><span class="nf">.retain</span><span class="p">(|</span><span class="o">&amp;</span><span class="n">i</span><span class="p">|</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">b_start</span><span class="p">);</span>
            <span class="k">let</span> <span class="n">inverse_memory_index_a</span> <span class="o">=</span> <span class="n">inverse_memory_index</span><span class="p">;</span>

            <span class="c1">// Since `inverse_memory_index_{a,b}` each only refer to their</span>
            <span class="c1">// respective fields, they can be safely inverted</span>
            <span class="k">let</span> <span class="n">memory_index_a</span> <span class="o">=</span> <span class="nf">invert_mapping</span><span class="p">(</span><span class="o">&amp;</span><span class="n">inverse_memory_index_a</span><span class="p">);</span>
            <span class="k">let</span> <span class="n">memory_index_b</span> <span class="o">=</span> <span class="nf">invert_mapping</span><span class="p">(</span><span class="o">&amp;</span><span class="n">inverse_memory_index_b</span><span class="p">);</span>

            <span class="k">let</span> <span class="n">outer_fields</span> <span class="o">=</span>
                <span class="nn">FieldsShape</span><span class="p">::</span><span class="n">Arbitrary</span> <span class="p">{</span> <span class="n">offsets</span><span class="p">:</span> <span class="n">offsets_a</span><span class="p">,</span> <span class="n">memory_index</span><span class="p">:</span> <span class="n">memory_index_a</span> <span class="p">};</span>
            <span class="p">(</span><span class="n">outer_fields</span><span class="p">,</span> <span class="n">offsets_b</span><span class="p">,</span> <span class="n">memory_index_b</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">_</span> <span class="k">=&gt;</span> <span class="nd">bug!</span><span class="p">(),</span>
    <span class="p">};</span>

    <span class="k">let</span> <span class="k">mut</span> <span class="n">size</span> <span class="o">=</span> <span class="n">prefix</span><span class="py">.size</span><span class="p">;</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">align</span> <span class="o">=</span> <span class="n">prefix</span><span class="py">.align</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">variants</span> <span class="o">=</span> <span class="n">info</span>
        <span class="py">.variant_fields</span>
        <span class="nf">.iter_enumerated</span><span class="p">()</span>
        <span class="nf">.map</span><span class="p">(|(</span><span class="n">index</span><span class="p">,</span> <span class="n">variant_fields</span><span class="p">)|</span> <span class="p">{</span>
            <span class="c1">// Only include overlap-eligible fields when we compute our variant layout.</span>
            <span class="k">let</span> <span class="n">variant_only_tys</span> <span class="o">=</span> <span class="n">variant_fields</span>
                <span class="nf">.iter</span><span class="p">()</span>
                <span class="nf">.filter</span><span class="p">(|</span><span class="n">local</span><span class="p">|</span> <span class="k">match</span> <span class="n">assignments</span><span class="p">[</span><span class="o">**</span><span class="n">local</span><span class="p">]</span> <span class="p">{</span>
                    <span class="n">Unassigned</span> <span class="k">=&gt;</span> <span class="nd">bug!</span><span class="p">(),</span>
                    <span class="nf">Assigned</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">if</span> <span class="n">v</span> <span class="o">==</span> <span class="n">index</span> <span class="k">=&gt;</span> <span class="k">true</span><span class="p">,</span>
                    <span class="nf">Assigned</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="nd">bug!</span><span class="p">(</span><span class="s">"assignment does not match variant"</span><span class="p">),</span>
                    <span class="nf">Ineligible</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="k">false</span><span class="p">,</span>
                <span class="p">})</span>
                <span class="nf">.map</span><span class="p">(|</span><span class="n">local</span><span class="p">|</span> <span class="nf">subst_field</span><span class="p">(</span><span class="n">info</span><span class="py">.field_tys</span><span class="p">[</span><span class="o">*</span><span class="n">local</span><span class="p">]));</span>

            <span class="k">let</span> <span class="k">mut</span> <span class="n">variant</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.univariant_uninterned</span><span class="p">(</span>
                <span class="n">ty</span><span class="p">,</span>
                <span class="o">&amp;</span><span class="n">variant_only_tys</span>
                    <span class="nf">.map</span><span class="p">(|</span><span class="n">ty</span><span class="p">|</span> <span class="k">self</span><span class="nf">.layout_of</span><span class="p">(</span><span class="n">ty</span><span class="p">))</span>
                    <span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">()</span><span class="o">?</span><span class="p">,</span>
                <span class="o">&amp;</span><span class="nn">ReprOptions</span><span class="p">::</span><span class="nf">default</span><span class="p">(),</span>
                <span class="nn">StructKind</span><span class="p">::</span><span class="nf">Prefixed</span><span class="p">(</span><span class="n">prefix_size</span><span class="p">,</span> <span class="n">prefix_align</span><span class="py">.abi</span><span class="p">),</span>
            <span class="p">)</span><span class="o">?</span><span class="p">;</span>
            <span class="n">variant</span><span class="py">.variants</span> <span class="o">=</span> <span class="nn">Variants</span><span class="p">::</span><span class="n">Single</span> <span class="p">{</span> <span class="n">index</span> <span class="p">};</span>

            <span class="k">let</span> <span class="nn">FieldsShape</span><span class="p">::</span><span class="n">Arbitrary</span> <span class="p">{</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">memory_index</span> <span class="p">}</span> <span class="o">=</span> <span class="n">variant</span><span class="py">.fields</span> <span class="k">else</span> <span class="p">{</span>
                <span class="nd">bug!</span><span class="p">();</span>
            <span class="p">};</span>

            <span class="c1">// Now, stitch the promoted and variant-only fields back together in</span>
            <span class="c1">// the order they are mentioned by our GeneratorLayout.</span>
            <span class="c1">// Because we only use some subset (that can differ between variants)</span>
            <span class="c1">// of the promoted fields, we can't just pick those elements of the</span>
            <span class="c1">// `promoted_memory_index` (as we'd end up with gaps).</span>
            <span class="c1">// So instead, we build an "inverse memory_index", as if all of the</span>
            <span class="c1">// promoted fields were being used, but leave the elements not in the</span>
            <span class="c1">// subset as `INVALID_FIELD_IDX`, which we can filter out later to</span>
            <span class="c1">// obtain a valid (bijective) mapping.</span>
            <span class="k">const</span> <span class="n">INVALID_FIELD_IDX</span><span class="p">:</span> <span class="nb">u32</span> <span class="o">=</span> <span class="o">!</span><span class="mi">0</span><span class="p">;</span>
            <span class="k">let</span> <span class="k">mut</span> <span class="n">combined_inverse_memory_index</span> <span class="o">=</span>
                <span class="nd">vec!</span><span class="p">[</span><span class="n">INVALID_FIELD_IDX</span><span class="p">;</span> <span class="n">promoted_memory_index</span><span class="nf">.len</span><span class="p">()</span> <span class="o">+</span> <span class="n">memory_index</span><span class="nf">.len</span><span class="p">()];</span>
            <span class="k">let</span> <span class="k">mut</span> <span class="n">offsets_and_memory_index</span> <span class="o">=</span> <span class="nn">iter</span><span class="p">::</span><span class="nf">zip</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="n">memory_index</span><span class="p">);</span>
            <span class="k">let</span> <span class="n">combined_offsets</span> <span class="o">=</span> <span class="n">variant_fields</span>
                <span class="nf">.iter</span><span class="p">()</span>
                <span class="nf">.enumerate</span><span class="p">()</span>
                <span class="nf">.map</span><span class="p">(|(</span><span class="n">i</span><span class="p">,</span> <span class="n">local</span><span class="p">)|</span> <span class="p">{</span>
                    <span class="k">let</span> <span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">memory_index</span><span class="p">)</span> <span class="o">=</span> <span class="k">match</span> <span class="n">assignments</span><span class="p">[</span><span class="o">*</span><span class="n">local</span><span class="p">]</span> <span class="p">{</span>
                        <span class="n">Unassigned</span> <span class="k">=&gt;</span> <span class="nd">bug!</span><span class="p">(),</span>
                        <span class="nf">Assigned</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
                            <span class="k">let</span> <span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">memory_index</span><span class="p">)</span> <span class="o">=</span>
                                <span class="n">offsets_and_memory_index</span><span class="nf">.next</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">();</span>
                            <span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">promoted_memory_index</span><span class="nf">.len</span><span class="p">()</span> <span class="k">as</span> <span class="nb">u32</span> <span class="o">+</span> <span class="n">memory_index</span><span class="p">)</span>
                        <span class="p">}</span>
                        <span class="nf">Ineligible</span><span class="p">(</span><span class="n">field_idx</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
                            <span class="k">let</span> <span class="n">field_idx</span> <span class="o">=</span> <span class="n">field_idx</span><span class="nf">.unwrap</span><span class="p">()</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">;</span>
                            <span class="p">(</span><span class="n">promoted_offsets</span><span class="p">[</span><span class="n">field_idx</span><span class="p">],</span> <span class="n">promoted_memory_index</span><span class="p">[</span><span class="n">field_idx</span><span class="p">])</span>
                        <span class="p">}</span>
                    <span class="p">};</span>
                    <span class="n">combined_inverse_memory_index</span><span class="p">[</span><span class="n">memory_index</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span> <span class="k">as</span> <span class="nb">u32</span><span class="p">;</span>
                    <span class="n">offset</span>
                <span class="p">})</span>
                <span class="nf">.collect</span><span class="p">();</span>

            <span class="c1">// Remove the unused slots and invert the mapping to obtain the</span>
            <span class="c1">// combined `memory_index` (also see previous comment).</span>
            <span class="n">combined_inverse_memory_index</span><span class="nf">.retain</span><span class="p">(|</span><span class="o">&amp;</span><span class="n">i</span><span class="p">|</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">INVALID_FIELD_IDX</span><span class="p">);</span>
            <span class="k">let</span> <span class="n">combined_memory_index</span> <span class="o">=</span> <span class="nf">invert_mapping</span><span class="p">(</span><span class="o">&amp;</span><span class="n">combined_inverse_memory_index</span><span class="p">);</span>

            <span class="n">variant</span><span class="py">.fields</span> <span class="o">=</span> <span class="nn">FieldsShape</span><span class="p">::</span><span class="n">Arbitrary</span> <span class="p">{</span>
                <span class="n">offsets</span><span class="p">:</span> <span class="n">combined_offsets</span><span class="p">,</span>
                <span class="n">memory_index</span><span class="p">:</span> <span class="n">combined_memory_index</span><span class="p">,</span>
            <span class="p">};</span>

            <span class="n">size</span> <span class="o">=</span> <span class="n">size</span><span class="nf">.max</span><span class="p">(</span><span class="n">variant</span><span class="py">.size</span><span class="p">);</span>
            <span class="n">align</span> <span class="o">=</span> <span class="n">align</span><span class="nf">.max</span><span class="p">(</span><span class="n">variant</span><span class="py">.align</span><span class="p">);</span>
            <span class="nf">Ok</span><span class="p">(</span><span class="n">tcx</span><span class="nf">.intern_layout</span><span class="p">(</span><span class="n">variant</span><span class="p">))</span>
        <span class="p">})</span>
        <span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Result</span><span class="o">&lt;</span><span class="n">IndexVec</span><span class="o">&lt;</span><span class="n">VariantIdx</span><span class="p">,</span> <span class="n">_</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>

    <span class="n">size</span> <span class="o">=</span> <span class="n">size</span><span class="nf">.align_to</span><span class="p">(</span><span class="n">align</span><span class="py">.abi</span><span class="p">);</span>

    <span class="k">let</span> <span class="n">abi</span> <span class="o">=</span>
        <span class="k">if</span> <span class="n">prefix</span><span class="py">.abi</span><span class="nf">.is_uninhabited</span><span class="p">()</span> <span class="p">||</span> <span class="n">variants</span><span class="nf">.iter</span><span class="p">()</span><span class="nf">.all</span><span class="p">(|</span><span class="n">v</span><span class="p">|</span> <span class="n">v</span><span class="nf">.abi</span><span class="p">()</span><span class="nf">.is_uninhabited</span><span class="p">())</span> <span class="p">{</span>
            <span class="nn">Abi</span><span class="p">::</span><span class="n">Uninhabited</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="nn">Abi</span><span class="p">::</span><span class="n">Aggregate</span> <span class="p">{</span> <span class="n">sized</span><span class="p">:</span> <span class="k">true</span> <span class="p">}</span>
        <span class="p">};</span>

    <span class="k">let</span> <span class="n">layout</span> <span class="o">=</span> <span class="n">tcx</span><span class="nf">.intern_layout</span><span class="p">(</span><span class="n">LayoutS</span> <span class="p">{</span>
        <span class="n">variants</span><span class="p">:</span> <span class="nn">Variants</span><span class="p">::</span><span class="n">Multiple</span> <span class="p">{</span>
            <span class="n">tag</span><span class="p">,</span>
            <span class="n">tag_encoding</span><span class="p">:</span> <span class="nn">TagEncoding</span><span class="p">::</span><span class="n">Direct</span><span class="p">,</span>
            <span class="n">tag_field</span><span class="p">:</span> <span class="n">tag_index</span><span class="p">,</span>
            <span class="n">variants</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">fields</span><span class="p">:</span> <span class="n">outer_fields</span><span class="p">,</span>
        <span class="n">abi</span><span class="p">,</span>
        <span class="n">largest_niche</span><span class="p">:</span> <span class="n">prefix</span><span class="py">.largest_niche</span><span class="p">,</span>
        <span class="n">size</span><span class="p">,</span>
        <span class="n">align</span><span class="p">,</span>
    <span class="p">});</span>
    <span class="nd">debug!</span><span class="p">(</span><span class="s">"generator layout ({:?}): {:#?}"</span><span class="p">,</span> <span class="n">ty</span><span class="p">,</span> <span class="n">layout</span><span class="p">);</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="n">layout</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">LayoutS</code> 的定义为：</p>

<pre><code class="language-Rust">#[derive(PartialEq, Eq, Hash, HashStable_Generic)]
pub struct LayoutS&lt;'a&gt; {
    /// Says where the fields are located within the layout.
    pub fields: FieldsShape,

    /// Encodes information about multi-variant layouts.
    /// Even with `Multiple` variants, a layout still has its own fields! Those are then
    /// shared between all variants. One of them will be the discriminant,
    /// but e.g. generators can have more.
    ///
    /// To access all fields of this layout, both `fields` and the fields of the active variant
    /// must be taken into account.
    pub variants: Variants&lt;'a&gt;,

    /// The `abi` defines how this data is passed between functions, and it defines
    /// value restrictions via `valid_range`.
    ///
    /// Note that this is entirely orthogonal to the recursive structure defined by
    /// `variants` and `fields`; for example, `ManuallyDrop&lt;Result&lt;isize, isize&gt;&gt;` has
    /// `Abi::ScalarPair`! So, even with non-`Aggregate` `abi`, `fields` and `variants`
    /// have to be taken into account to find all fields of this layout.
    pub abi: Abi,

    /// The leaf scalar with the largest number of invalid values
    /// (i.e. outside of its `valid_range`), if it exists.
    pub largest_niche: Option&lt;Niche&gt;,

    pub align: AbiAndPrefAlign,
    pub size: Size,
}
</code></pre>

<p>根据定义，<code class="language-plaintext highlighter-rouge">fields</code> + <code class="language-plaintext highlighter-rouge">variants</code> 组成了 <code class="language-plaintext highlighter-rouge">GeneratorState</code> 的内存布局：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>To access all fields of this layout, both `fields` and the fields of the active variant must be taken into account.
</code></pre></div></div>

<p>在 <code class="language-plaintext highlighter-rouge">generator_layout</code> 函数中，<code class="language-plaintext highlighter-rouge">fields</code> 是 <code class="language-plaintext highlighter-rouge">outer_fields</code>，variants 是 <code class="language-plaintext highlighter-rouge">Variant::Multiple</code> 的实例，其中保存了 <code class="language-plaintext highlighter-rouge">variants</code> 和一个 <code class="language-plaintext highlighter-rouge">tag_field</code>。<code class="language-plaintext highlighter-rouge">outer_fields</code> 和 <code class="language-plaintext highlighter-rouge">variants</code> 均由 <code class="language-plaintext highlighter-rouge">prefix</code> 计算得到：</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Split the prefix layout into the "outer" fields (upvars and</span>
<span class="c1">// discriminant) and the "promoted" fields. Promoted fields will</span>
<span class="c1">// get included in each variant that requested them in</span>
<span class="c1">// GeneratorLayout</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">prefix</code> 的计算方式为：</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">tag_layout</span> <span class="o">=</span> <span class="k">self</span><span class="py">.tcx</span><span class="nf">.intern_layout</span><span class="p">(</span><span class="nn">LayoutS</span><span class="p">::</span><span class="nf">scalar</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">));</span>
<span class="k">let</span> <span class="n">tag_layout</span> <span class="o">=</span> <span class="n">TyAndLayout</span> <span class="p">{</span> <span class="n">ty</span><span class="p">:</span> <span class="n">discr_int_ty</span><span class="p">,</span> <span class="n">layout</span><span class="p">:</span> <span class="n">tag_layout</span> <span class="p">};</span>

<span class="k">let</span> <span class="n">promoted_layouts</span> <span class="o">=</span> <span class="n">ineligible_locals</span>
    <span class="nf">.iter</span><span class="p">()</span>
    <span class="nf">.map</span><span class="p">(|</span><span class="n">local</span><span class="p">|</span> <span class="nf">subst_field</span><span class="p">(</span><span class="n">info</span><span class="py">.field_tys</span><span class="p">[</span><span class="n">local</span><span class="p">]))</span>
    <span class="nf">.map</span><span class="p">(|</span><span class="n">ty</span><span class="p">|</span> <span class="n">tcx</span><span class="nf">.mk_maybe_uninit</span><span class="p">(</span><span class="n">ty</span><span class="p">))</span>
    <span class="nf">.map</span><span class="p">(|</span><span class="n">ty</span><span class="p">|</span> <span class="k">self</span><span class="nf">.layout_of</span><span class="p">(</span><span class="n">ty</span><span class="p">));</span>
<span class="k">let</span> <span class="n">prefix_layouts</span> <span class="o">=</span> <span class="n">substs</span>
    <span class="nf">.as_generator</span><span class="p">()</span>
    <span class="nf">.prefix_tys</span><span class="p">()</span>
    <span class="nf">.map</span><span class="p">(|</span><span class="n">ty</span><span class="p">|</span> <span class="k">self</span><span class="nf">.layout_of</span><span class="p">(</span><span class="n">ty</span><span class="p">))</span>
    <span class="nf">.chain</span><span class="p">(</span><span class="nn">iter</span><span class="p">::</span><span class="nf">once</span><span class="p">(</span><span class="nf">Ok</span><span class="p">(</span><span class="n">tag_layout</span><span class="p">)))</span>
    <span class="nf">.chain</span><span class="p">(</span><span class="n">promoted_layouts</span><span class="p">)</span>
    <span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
<span class="k">let</span> <span class="n">prefix</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.univariant_uninterned</span><span class="p">(</span>
    <span class="n">ty</span><span class="p">,</span>
    <span class="o">&amp;</span><span class="n">prefix_layouts</span><span class="p">,</span>
    <span class="o">&amp;</span><span class="nn">ReprOptions</span><span class="p">::</span><span class="nf">default</span><span class="p">(),</span>
    <span class="nn">StructKind</span><span class="p">::</span><span class="n">AlwaysSized</span><span class="p">,</span>
<span class="p">)</span><span class="o">?</span><span class="p">;</span>
</code></pre></div></div>

<p>其中 <code class="language-plaintext highlighter-rouge">prefix_tys()</code> 返回的就是前面提到的 <code class="language-plaintext highlighter-rouge">upvars</code>：</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cd">/// This is the types of the fields of a generator which are not stored in a</span>
<span class="cd">/// variant.</span>
<span class="nd">#[inline]</span>
<span class="k">pub</span> <span class="k">fn</span> <span class="nf">prefix_tys</span><span class="p">(</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">impl</span> <span class="nb">Iterator</span><span class="o">&lt;</span><span class="n">Item</span> <span class="o">=</span> <span class="n">Ty</span><span class="o">&lt;</span><span class="nv">'tcx</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="k">self</span><span class="nf">.upvar_tys</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div></div>

<p>因此，一个 <code class="language-plaintext highlighter-rouge">GeneratorState</code> 的 <code class="language-plaintext highlighter-rouge">Layout</code> 中会包含一个 <code class="language-plaintext highlighter-rouge">tag</code>，<code class="language-plaintext highlighter-rouge">upvars</code>，以及由不同 state 组成的 <code class="language-plaintext highlighter-rouge">variants</code>。回到 <code class="language-plaintext highlighter-rouge">root_heartbeat</code> 的例子，<code class="language-plaintext highlighter-rouge">streaming()</code> 中，除了 <code class="language-plaintext highlighter-rouge">request</code> 和 <code class="language-plaintext highlighter-rouge">response</code> 外，还会保存下参数中的 <code class="language-plaintext highlighter-rouge">request: Request&lt;S&gt;</code>，<code class="language-plaintext highlighter-rouge">path</code> 和 <code class="language-plaintext highlighter-rouge">codec</code>。</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">codec</code>: <code class="language-plaintext highlighter-rouge">tonic::codec::ProstCodec&lt;engula_api::server::v1::HeartbeatRequest, engula_api::server::v1::HeartbeatResponse&gt;</code> size 0 bytes</li>
  <li><code class="language-plaintext highlighter-rouge">request</code>: <code class="language-plaintext highlighter-rouge">tonic::Request&lt;futures::stream::Once&lt;futures::future::Ready&lt;engula_api::server::v1::HeartbeatRequest&gt;&gt;&gt;</code> size 144 bytes</li>
  <li><code class="language-plaintext highlighter-rouge">path</code>: <code class="language-plaintext highlighter-rouge">http::uri::path::PathAndQuery</code> size 40 bytes</li>
  <li>tag: u8</li>
</ul>

<p>最终的大小为：self(8 bytes) + request(144 bytes) + path(40 bytes) + uri(88 bytes) + request(240 bytes, http request) + response(32 bytes) + tag(1 byte, aligned to 8) = 560</p>

<blockquote>
  <p>此处 <code class="language-plaintext highlighter-rouge">uri</code> 是前面计算漏掉的变量。</p>
</blockquote>

<p>由于 <code class="language-plaintext highlighter-rouge">async fn</code> 的参数作为 captured variable，会放置在 <code class="language-plaintext highlighter-rouge">outer_fields</code> 中。如果一个非常大的参数层层传递到内部的某个 <code class="language-plaintext highlighter-rouge">async fn</code>，会被一层层放大，最终导致 <code class="language-plaintext highlighter-rouge">Future</code> 大小呈现指数增长。 19 年有一个 issue 已经指出了这个问题<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>。</p>

<h1 id="解决方案">解决方案？</h1>

<p>对于普通开发者，临时的解决办法有两点：</p>

<ol>
  <li>避免 pass by value，可以使用 <code class="language-plaintext highlighter-rouge">Arc</code> 或者 reference</li>
  <li>减少使用 <code class="language-plaintext highlighter-rouge">async fn</code>。对于 tail calling，可以直接使用 <code class="language-plaintext highlighter-rouge">impl Future</code>，避免无意义的 <code class="language-plaintext highlighter-rouge">await</code>。对于状态不复杂的 <code class="language-plaintext highlighter-rouge">async fn</code>，也可以考虑手写 <code class="language-plaintext highlighter-rouge">Future::poll()</code>。</li>
</ol>

<blockquote>
  <p>cpp 提供了右值引用，这类层层传递的变量可以被自然地优化；而 rust 依靠编译器优化，就得依靠生成的代码能满足优化的前置条件。</p>
</blockquote>

<p>当然，community 也有人提供了改进方案<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>。该方案可以简述如下：即将 upvars 保存到 <code class="language-plaintext highlighter-rouge">GeneratorState</code> 的 <code class="language-plaintext highlighter-rouge">unresumed</code> state 中 （每个 <code class="language-plaintext highlighter-rouge">GenerateState</code> 至少有三种 state: <code class="language-plaintext highlighter-rouge">unresumed</code>, <code class="language-plaintext highlighter-rouge">finished</code>, <code class="language-plaintext highlighter-rouge">paniced</code>, 以及用户定义的 <code class="language-plaintext highlighter-rouge">suspent_x</code>)。</p>

<p>不过因为 rust 编译器架构改成了 demand-deriven compilation，该方案碰到了 query 循环依赖的问题，
需要等待其他人先将修复 dest prop <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>。</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>https://github.com/rust-lang/rust/issues/62958 <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>https://github.com/rust-lang/rust/pull/89213 <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>https://github.com/rust-lang/rust/pull/96451 <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[背景 最近开始对 engula 进行性能测试，发现 async fn 的性能损耗非常大，这不符合 zero overhead abstraction，因此开始对 async fn 的性能做一些研究。 通过增加参数 -Z print-type-size，可以输出每种类型的大小。发现很多 generator 内存大小非常大，其中最不符合直觉的是下面这几个： print-type-size type: `std::future::from_generator::GenFuture&lt;[static generator@src/client/src/node_client.rs:39:69: 44:6]&gt;`: 1248 bytes, alignment: 8 bytes print-type-size field `.0`: 1248 bytes print-type-size type: `std::future::from_generator::GenFuture&lt;[static generator@src/client/src/node_client.rs:79:52: 83:6]&gt;`: 1408 bytes, alignment: 8 bytes print-type-size field `.0`: 1408 bytes print-type-size type: `std::future::from_generator::GenFuture&lt;[static generator@src/client/src/node_client.rs:88:51: 92:6]&gt;`: 1408 bytes, alignment: 8 bytes print-type-size field `.0`: 1408 bytes node_client.rs 是 tonic grpc client 的简单封装: use tonic::transport::Channel; #[derive(Debug, Clone)] pub struct Client { client: node_client::NodeClient&lt;Channel&gt;, } pub async fn root_heartbeat( &amp;self, req: HeartbeatRequest, ) -&gt; Result&lt;HeartbeatResponse, tonic::Status&gt; { let mut client = self.client.clone(); let res = client.root_heartbeat(req).await?; Ok(res.into_inner()) } node_client::NodeClient 是 tonic_build 生成的代码： impl&lt;T&gt; NodeClient&lt;T&gt; where T: tonic::client::GrpcService&lt;tonic::body::BoxBody&gt;, T::Error: Into&lt;StdError&gt;, T::ResponseBody: Body&lt;Data = Bytes&gt; + Send + 'static, &lt;T::ResponseBody as Body&gt;::Error: Into&lt;StdError&gt; + Send, { pub fn new(inner: T) -&gt; Self { let inner = tonic::client::Grpc::new(inner); Self { inner } } } pub async fn root_heartbeat( &amp;mut self, request: impl tonic::IntoRequest&lt;super::HeartbeatRequest&gt;, ) -&gt; Result&lt;tonic::Response&lt;super::HeartbeatResponse&gt;, tonic::Status&gt; { self.inner .ready() .await .map_err(|e| { tonic::Status::new( tonic::Code::Unknown, format!("Service was not ready: {}", e.into()), ) })?; let codec = tonic::codec::ProstCodec::default(); let path = http::uri::PathAndQuery::from_static( "/engula.server.v1.Node/RootHeartbeat", ); self.inner.unary(request.into_request(), path, codec).await } 也就是说，每次调用 Grpc::unary 需要在栈上开辟 1K+ 的空间。如果最后使用了 tokio::spawn，那么还需要将它复制到堆上。无论是内存分配还是复制上的开销，对于一个高性能存储服务都是不可接受的。并且随着 async fn 的调用层数增加，Future 大小还会呈现指数增长，这一点我后面会分析。 Grpc::unary 的 memory layout 是怎样的？ 那么，为何 Grpc::unary 返回的 Future 需要消耗 1K+ 的内存空间呢？ 在 tonic/src/client/grpc.rs 中，unary 最终被委托给 Grpc::streaming，后者调用 Channel::call 并返回 ResponseFuture。 /// Send a single unary gRPC request. pub async fn unary&lt;M1, M2, C&gt;( &amp;mut self, request: Request&lt;M1&gt;, path: PathAndQuery, codec: C, ) -&gt; Result&lt;Response&lt;M2&gt;, Status&gt; where T: GrpcService&lt;BoxBody&gt;, T::ResponseBody: Body + Send + 'static, &lt;T::ResponseBody as Body&gt;::Error: Into&lt;crate::Error&gt;, C: Codec&lt;Encode = M1, Decode = M2&gt;, M1: Send + Sync + 'static, M2: Send + Sync + 'static, { let request = request.map(|m| stream::once(future::ready(m))); self.client_streaming(request, path, codec).await } /// Send a client side streaming gRPC request. pub async fn client_streaming&lt;S, M1, M2, C&gt;( &amp;mut self, request: Request&lt;S&gt;, path: PathAndQuery, codec: C, ) -&gt; Result&lt;Response&lt;M2&gt;, Status&gt; where T: GrpcService&lt;BoxBody&gt;, T::ResponseBody: Body + Send + 'static, &lt;T::ResponseBody as Body&gt;::Error: Into&lt;crate::Error&gt;, S: Stream&lt;Item = M1&gt; + Send + 'static, C: Codec&lt;Encode = M1, Decode = M2&gt;, M1: Send + Sync + 'static, M2: Send + Sync + 'static, { let (mut parts, body, extensions) = self.streaming(request, path, codec).await?.into_parts(); futures_util::pin_mut!(body); let message = body .try_next() .await .map_err(|mut status| { status.metadata_mut().merge(parts.clone()); status })? .ok_or_else(|| Status::new(Code::Internal, "Missing response message."))?; if let Some(trailers) = body.trailers().await? { parts.merge(trailers); } Ok(Response::from_parts(parts, message, extensions)) } /// Send a bi-directional streaming gRPC request. pub async fn streaming&lt;S, M1, M2, C&gt;( &amp;mut self, request: Request&lt;S&gt;, path: PathAndQuery, mut codec: C, ) -&gt; Result&lt;Response&lt;Streaming&lt;M2&gt;&gt;, Status&gt; where T: GrpcService&lt;BoxBody&gt;, T::ResponseBody: Body + Send + 'static, &lt;T::ResponseBody as Body&gt;::Error: Into&lt;crate::Error&gt;, S: Stream&lt;Item = M1&gt; + Send + 'static, C: Codec&lt;Encode = M1, Decode = M2&gt;, M1: Send + Sync + 'static, M2: Send + Sync + 'static, { let mut parts = Parts::default(); parts.path_and_query = Some(path); let uri = Uri::from_parts(parts).expect("path_and_query only is valid Uri"); let request = request .map(|s| { encode_client( codec.encoder(), s, #[cfg(feature = "compression")] self.send_compression_encodings, ) }) .map(BoxBody::new); let mut request = request.into_http( uri, http::Method::POST, http::Version::HTTP_2, SanitizeHeaders::Yes, ); // Add the gRPC related HTTP headers request .headers_mut() .insert(TE, HeaderValue::from_static("trailers")); // Set the content type request .headers_mut() .insert(CONTENT_TYPE, HeaderValue::from_static("application/grpc")); #[cfg(feature = "compression")] { if let Some(encoding) = self.send_compression_encodings { request.headers_mut().insert( crate::codec::compression::ENCODING_HEADER, encoding.into_header_value(), ); } if let Some(header_value) = self .accept_compression_encodings .into_accept_encoding_header_value() { request.headers_mut().insert( crate::codec::compression::ACCEPT_ENCODING_HEADER, header_value, ); } } let response = self .inner .call(request) .await .map_err(|err| Status::from_error(err.into()))?; #[cfg(feature = "compression")] let encoding = CompressionEncoding::from_encoding_header( response.headers(), self.accept_compression_encodings, )?; let status_code = response.status(); let trailers_only_status = Status::from_header_map(response.headers()); // We do not need to check for trailers if the `grpc-status` header is present // with a valid code. let expect_additional_trailers = if let Some(status) = trailers_only_status { if status.code() != Code::Ok { return Err(status); } false } else { true }; let response = response.map(|body| { if expect_additional_trailers { Streaming::new_response( codec.decoder(), body, status_code, #[cfg(feature = "compression")] encoding, ) } else { Streaming::new_empty(codec.decoder(), body) } }); Ok(Response::from_http(response)) } 以前面的 root_heartbeat 为例，最终实例化的 streaming 的签名为： tonic::client::Grpc&lt;tonic::transport::Channel&gt;::streaming&lt; futures::stream::Once&lt; futures::future::Ready&lt; engula_api::server::v1::HeartbeatRequest&gt;&gt;, engula_api::server::v1::HeartbeatRequest, engula_api::server::v1::HeartbeatResponse, tonic::codec::ProstCodec&lt; engula_api::server::v1::HeartbeatRequest, engula_api::server::v1::HeartbeatResponse&gt;&gt; 而 async fn streaming() 脱糖后，经过 transform 生成的状态机的内存布局为： generator layout ([static generator@tonic::client::Grpc&lt;tonic::transport::Channel&gt;::streaming&lt;futures::stream::Once&lt;futures::future::Ready&lt;engula_api::server::v1::HeartbeatRequest&gt;&gt;, engula_api::server::v1::HeartbeatRequest, engula_api::server::v1::HeartbeatResponse, tonic::codec::ProstCodec&lt;engula_api::server::v1::HeartbeatRequest, engula_api::server::v1::HeartbeatResponse&gt;&gt;::{closure#0}]): Layout { size: Size(560 bytes), align: AbiAndPrefAlign { abi: Align(8 bytes), pref: Align(8 bytes), }, abi: Aggregate { sized: true, }, fields: Arbitrary { offsets: [ Size(0 bytes), Size(8 bytes), Size(152 bytes), Size(0 bytes), Size(552 bytes), ], } } 仔细分析 streaming 的代码可以发现，跨过 suspend point 的变量只有本地变量 request，预留空间 response: request: http::request::Request&lt;http_body::combinators::box_body::UnsyncBoxBody&lt;prost::bytes::Bytes, tonic::Status&gt;&gt; size = 240 bytes response: tonic::transport::channel::ResponseFuture size = 32 bytes 那么 request + response + tag （手写状态机的理论值）应该是远小于 560 bytes。到了 client_streaming 这里，内存空间就增长到了 1056 bytes。 async fn 的 layout 是如何计算的？ 这里进一步分析编译器内部是如何处理 async, await 和产生状态机的，看看不符合直觉的结果是如何产生的。 实际上 async fn 是 generator 的语法糖 async 和 await 都是语法糖，rust compiler 在 ast lowering 过程中进行了 desugar，并生成 hir。其中 async fn 会被替换为 generator (compiler/rustc_ast_lowering/src/item.rs)： fn lower_maybe_async_body( &amp;mut self, span: Span, decl: &amp;FnDecl, asyncness: Async, body: Option&lt;&amp;Block&gt;, ) -&gt; hir::BodyId { let closure_id = match asyncness { Async::Yes { closure_id, .. } =&gt; closure_id, Async::No =&gt; return self.lower_fn_body_block(span, decl, body), }; self.lower_body(|this| { let mut parameters: Vec&lt;hir::Param&lt;'_&gt;&gt; = Vec::new(); let mut statements: Vec&lt;hir::Stmt&lt;'_&gt;&gt; = Vec::new(); // Async function parameters are lowered into the closure body so that they are // captured and so that the drop order matches the equivalent non-async functions. // // from: // // async fn foo(&lt;pattern&gt;: &lt;ty&gt;, &lt;pattern&gt;: &lt;ty&gt;, &lt;pattern&gt;: &lt;ty&gt;) { // &lt;body&gt; // } // // into: // // fn foo(__arg0: &lt;ty&gt;, __arg1: &lt;ty&gt;, __arg2: &lt;ty&gt;) { // async move { // let __arg2 = __arg2; // let &lt;pattern&gt; = __arg2; // let __arg1 = __arg1; // let &lt;pattern&gt; = __arg1; // let __arg0 = __arg0; // let &lt;pattern&gt; = __arg0; // drop-temps { &lt;body&gt; } // see comments later in fn for details // } // } // // If `&lt;pattern&gt;` is a simple ident, then it is lowered to a single // `let &lt;pattern&gt; = &lt;pattern&gt;;` statement as an optimization. // // Note that the body is embedded in `drop-temps`; an // equivalent desugaring would be `return { &lt;body&gt; // };`. The key point is that we wish to drop all the // let-bound variables and temporaries created in the body // (and its tail expression!) before we drop the // parameters (c.f. rust-lang/rust#64512). for (index, parameter) in decl.inputs.iter().enumerate() { let parameter = this.lower_param(parameter); let span = parameter.pat.span; // Check if this is a binding pattern, if so, we can optimize and avoid adding a // `let &lt;pat&gt; = __argN;` statement. In this case, we do not rename the parameter. let (ident, is_simple_parameter) = match parameter.pat.kind { hir::PatKind::Binding( hir::BindingAnnotation::Unannotated | hir::BindingAnnotation::Mutable, _, ident, _, ) =&gt; (ident, true), // For `ref mut` or wildcard arguments, we can't reuse the binding, but // we can keep the same name for the parameter. // This lets rustdoc render it correctly in documentation. hir::PatKind::Binding(_, _, ident, _) =&gt; (ident, false), hir::PatKind::Wild =&gt; { (Ident::with_dummy_span(rustc_span::symbol::kw::Underscore), false) } _ =&gt; { // Replace the ident for bindings that aren't simple. let name = format!("__arg{}", index); let ident = Ident::from_str(&amp;name); (ident, false) } }; let desugared_span = this.mark_span_with_reason(DesugaringKind::Async, span, None); // Construct a parameter representing `__argN: &lt;ty&gt;` to replace the parameter of the // async function. // // If this is the simple case, this parameter will end up being the same as the // original parameter, but with a different pattern id. let stmt_attrs = this.attrs.get(&amp;parameter.hir_id.local_id).copied(); let (new_parameter_pat, new_parameter_id) = this.pat_ident(desugared_span, ident); let new_parameter = hir::Param { hir_id: parameter.hir_id, pat: new_parameter_pat, ty_span: this.lower_span(parameter.ty_span), span: this.lower_span(parameter.span), }; if is_simple_parameter { // If this is the simple case, then we only insert one statement that is // `let &lt;pat&gt; = &lt;pat&gt;;`. We re-use the original argument's pattern so that // `HirId`s are densely assigned. let expr = this.expr_ident(desugared_span, ident, new_parameter_id); let stmt = this.stmt_let_pat( stmt_attrs, desugared_span, Some(expr), parameter.pat, hir::LocalSource::AsyncFn, ); statements.push(stmt); } else { // If this is not the simple case, then we construct two statements: // // ``` // let __argN = __argN; // let &lt;pat&gt; = __argN; // ``` // // The first statement moves the parameter into the closure and thus ensures // that the drop order is correct. // // The second statement creates the bindings that the user wrote. // Construct the `let mut __argN = __argN;` statement. It must be a mut binding // because the user may have specified a `ref mut` binding in the next // statement. let (move_pat, move_id) = this.pat_ident_binding_mode( desugared_span, ident, hir::BindingAnnotation::Mutable, ); let move_expr = this.expr_ident(desugared_span, ident, new_parameter_id); let move_stmt = this.stmt_let_pat( None, desugared_span, Some(move_expr), move_pat, hir::LocalSource::AsyncFn, ); // Construct the `let &lt;pat&gt; = __argN;` statement. We re-use the original // parameter's pattern so that `HirId`s are densely assigned. let pattern_expr = this.expr_ident(desugared_span, ident, move_id); let pattern_stmt = this.stmt_let_pat( stmt_attrs, desugared_span, Some(pattern_expr), parameter.pat, hir::LocalSource::AsyncFn, ); statements.push(move_stmt); statements.push(pattern_stmt); }; parameters.push(new_parameter); } let body_span = body.map_or(span, |b| b.span); let async_expr = this.make_async_expr( CaptureBy::Value, closure_id, None, body_span, hir::AsyncGeneratorKind::Fn, |this| { // Create a block from the user's function body: let user_body = this.lower_block_expr_opt(body_span, body); // Transform into `drop-temps { &lt;user-body&gt; }`, an expression: let desugared_span = this.mark_span_with_reason(DesugaringKind::Async, user_body.span, None); let user_body = this.expr_drop_temps( desugared_span, this.arena.alloc(user_body), AttrVec::new(), ); // As noted above, create the final block like // // ``` // { // let $param_pattern = $raw_param; // ... // drop-temps { &lt;user-body&gt; } // } // ``` let body = this.block_all( desugared_span, this.arena.alloc_from_iter(statements), Some(user_body), ); this.expr_block(body, AttrVec::new()) }, ); ( this.arena.alloc_from_iter(parameters), this.expr(body_span, async_expr, AttrVec::new()), ) }) } async fn 被替换为 generator 后，它的参数作为 captured variable 保存在 closure 中，后续称它为 upvars，在计算 Layout 是会使用到。 await 则会被替换为 poll()(compiler/rustc_ast_lowering/src/expr.rs): /// Desugar `&lt;expr&gt;.await` into: /// ```ignore (pseudo-rust) /// match ::std::future::IntoFuture::into_future(&lt;expr&gt;) { /// mut __awaitee =&gt; loop { /// match unsafe { ::std::future::Future::poll( /// &lt;::std::pin::Pin&gt;::new_unchecked(&amp;mut __awaitee), /// ::std::future::get_context(task_context), /// ) } { /// ::std::task::Poll::Ready(result) =&gt; break result, /// ::std::task::Poll::Pending =&gt; {} /// } /// task_context = yield (); /// } /// } /// ``` fn lower_expr_await(&amp;mut self, dot_await_span: Span, expr: &amp;Expr) -&gt; hir::ExprKind&lt;'hir&gt; { let full_span = expr.span.to(dot_await_span); match self.generator_kind { Some(hir::GeneratorKind::Async(_)) =&gt; {} Some(hir::GeneratorKind::Gen) | None =&gt; { self.tcx.sess.emit_err(AwaitOnlyInAsyncFnAndBlocks { dot_await_span, item_span: self.current_item, }); } } let span = self.mark_span_with_reason(DesugaringKind::Await, dot_await_span, None); let gen_future_span = self.mark_span_with_reason( DesugaringKind::Await, full_span, self.allow_gen_future.clone(), ); let expr = self.lower_expr_mut(expr); let expr_hir_id = expr.hir_id; // Note that the name of this binding must not be changed to something else because // debuggers and debugger extensions expect it to be called `__awaitee`. They use // this name to identify what is being awaited by a suspended async functions. let awaitee_ident = Ident::with_dummy_span(sym::__awaitee); let (awaitee_pat, awaitee_pat_hid) = self.pat_ident_binding_mode(span, awaitee_ident, hir::BindingAnnotation::Mutable); let task_context_ident = Ident::with_dummy_span(sym::_task_context); // unsafe { // ::std::future::Future::poll( // ::std::pin::Pin::new_unchecked(&amp;mut __awaitee), // ::std::future::get_context(task_context), // ) // } let poll_expr = { let awaitee = self.expr_ident(span, awaitee_ident, awaitee_pat_hid); let ref_mut_awaitee = self.expr_mut_addr_of(span, awaitee); let task_context = if let Some(task_context_hid) = self.task_context { self.expr_ident_mut(span, task_context_ident, task_context_hid) } else { // Use of `await` outside of an async context, we cannot use `task_context` here. self.expr_err(span) }; let new_unchecked = self.expr_call_lang_item_fn_mut( span, hir::LangItem::PinNewUnchecked, arena_vec![self; ref_mut_awaitee], Some(expr_hir_id), ); let get_context = self.expr_call_lang_item_fn_mut( gen_future_span, hir::LangItem::GetContext, arena_vec![self; task_context], Some(expr_hir_id), ); let call = self.expr_call_lang_item_fn( span, hir::LangItem::FuturePoll, arena_vec![self; new_unchecked, get_context], Some(expr_hir_id), ); self.arena.alloc(self.expr_unsafe(call)) }; // `::std::task::Poll::Ready(result) =&gt; break result` let loop_node_id = self.next_node_id(); let loop_hir_id = self.lower_node_id(loop_node_id); let ready_arm = { let x_ident = Ident::with_dummy_span(sym::result); let (x_pat, x_pat_hid) = self.pat_ident(gen_future_span, x_ident); let x_expr = self.expr_ident(gen_future_span, x_ident, x_pat_hid); let ready_field = self.single_pat_field(gen_future_span, x_pat); let ready_pat = self.pat_lang_item_variant( span, hir::LangItem::PollReady, ready_field, Some(expr_hir_id), ); let break_x = self.with_loop_scope(loop_node_id, move |this| { let expr_break = hir::ExprKind::Break(this.lower_loop_destination(None), Some(x_expr)); this.arena.alloc(this.expr(gen_future_span, expr_break, AttrVec::new())) }); self.arm(ready_pat, break_x) }; // `::std::task::Poll::Pending =&gt; {}` let pending_arm = { let pending_pat = self.pat_lang_item_variant( span, hir::LangItem::PollPending, &amp;[], Some(expr_hir_id), ); let empty_block = self.expr_block_empty(span); self.arm(pending_pat, empty_block) }; let inner_match_stmt = { let match_expr = self.expr_match( span, poll_expr, arena_vec![self; ready_arm, pending_arm], hir::MatchSource::AwaitDesugar, ); self.stmt_expr(span, match_expr) }; // task_context = yield (); let yield_stmt = { let unit = self.expr_unit(span); let yield_expr = self.expr( span, hir::ExprKind::Yield(unit, hir::YieldSource::Await { expr: Some(expr_hir_id) }), AttrVec::new(), ); let yield_expr = self.arena.alloc(yield_expr); if let Some(task_context_hid) = self.task_context { let lhs = self.expr_ident(span, task_context_ident, task_context_hid); let assign = self.expr( span, hir::ExprKind::Assign(lhs, yield_expr, self.lower_span(span)), AttrVec::new(), ); self.stmt_expr(span, assign) } else { // Use of `await` outside of an async context. Return `yield_expr` so that we can // proceed with type checking. self.stmt(span, hir::StmtKind::Semi(yield_expr)) } }; let loop_block = self.block_all(span, arena_vec![self; inner_match_stmt, yield_stmt], None); // loop { .. } let loop_expr = self.arena.alloc(hir::Expr { hir_id: loop_hir_id, kind: hir::ExprKind::Loop( loop_block, None, hir::LoopSource::Loop, self.lower_span(span), ), span: self.lower_span(span), }); // mut __awaitee =&gt; loop { ... } let awaitee_arm = self.arm(awaitee_pat, loop_expr); // `match ::std::future::IntoFuture::into_future(&lt;expr&gt;) { ... }` let into_future_span = self.mark_span_with_reason( DesugaringKind::Await, dot_await_span, self.allow_into_future.clone(), ); let into_future_expr = self.expr_call_lang_item_fn( into_future_span, hir::LangItem::IntoFutureIntoFuture, arena_vec![self; expr], Some(expr_hir_id), ); // match &lt;into_future_expr&gt; { // mut __awaitee =&gt; loop { .. } // } hir::ExprKind::Match( into_future_expr, arena_vec![self; awaitee_arm], hir::MatchSource::AwaitDesugar, ) } generator 会被替换为 GeneratorState 此后 hir 会转换为 mir，generator 在 mir_transform 中被替换为 GeneratorState(compiler/rustc_mir_transform/src/generator.rs): impl&lt;'tcx&gt; MirPass&lt;'tcx&gt; for StateTransform { fn run_pass(&amp;self, tcx: TyCtxt&lt;'tcx&gt;, body: &amp;mut Body&lt;'tcx&gt;) { let Some(yield_ty) = body.yield_ty() else { // This only applies to generators return; }; assert!(body.generator_drop().is_none()); dump_mir(tcx, None, "generator_before", &amp;0, body, |_, _| Ok(())); // The first argument is the generator type passed by value let gen_ty = body.local_decls.raw[1].ty; // Get the interior types and substs which typeck computed let (upvars, interior, discr_ty, movable) = match *gen_ty.kind() { ty::Generator(_, substs, movability) =&gt; { let substs = substs.as_generator(); ( substs.upvar_tys().collect(), substs.witness(), substs.discr_ty(tcx), movability == hir::Movability::Movable, ) } _ =&gt; { tcx.sess .delay_span_bug(body.span, &amp;format!("unexpected generator type {}", gen_ty)); return; } }; // Compute GeneratorState&lt;yield_ty, return_ty&gt; let state_did = tcx.require_lang_item(LangItem::GeneratorState, None); let state_adt_ref = tcx.adt_def(state_did); let state_substs = tcx.intern_substs(&amp;[yield_ty.into(), body.return_ty().into()]); let ret_ty = tcx.mk_adt(state_adt_ref, state_substs); // We rename RETURN_PLACE which has type mir.return_ty to new_ret_local // RETURN_PLACE then is a fresh unused local with type ret_ty. let new_ret_local = replace_local(RETURN_PLACE, ret_ty, body, tcx); // We also replace the resume argument and insert an `Assign`. // This is needed because the resume argument `_2` might be live across a `yield`, in which // case there is no `Assign` to it that the transform can turn into a store to the generator // state. After the yield the slot in the generator state would then be uninitialized. let resume_local = Local::new(2); let new_resume_local = replace_local(resume_local, body.local_decls[resume_local].ty, body, tcx); // When first entering the generator, move the resume argument into its new local. let source_info = SourceInfo::outermost(body.span); let stmts = &amp;mut body.basic_blocks_mut()[BasicBlock::new(0)].statements; stmts.insert( 0, Statement { source_info, kind: StatementKind::Assign(Box::new(( new_resume_local.into(), Rvalue::Use(Operand::Move(resume_local.into())), ))), }, ); let always_live_locals = always_storage_live_locals(&amp;body); let liveness_info = locals_live_across_suspend_points(tcx, body, &amp;always_live_locals, movable); sanitize_witness(tcx, body, interior, upvars, &amp;liveness_info.saved_locals); if tcx.sess.opts.unstable_opts.validate_mir { let mut vis = EnsureGeneratorFieldAssignmentsNeverAlias { assigned_local: None, saved_locals: &amp;liveness_info.saved_locals, storage_conflicts: &amp;liveness_info.storage_conflicts, }; vis.visit_body(body); } // Extract locals which are live across suspension point into `layout` // `remap` gives a mapping from local indices onto generator struct indices // `storage_liveness` tells us which locals have live storage at suspension points let (remap, layout, storage_liveness) = compute_layout(liveness_info, body); let can_return = can_return(tcx, body, tcx.param_env(body.source.def_id())); // Run the transformation which converts Places from Local to generator struct // accesses for locals in `remap`. // It also rewrites `return x` and `yield y` as writing a new generator state and returning // GeneratorState::Complete(x) and GeneratorState::Yielded(y) respectively. let mut transform = TransformVisitor { tcx, state_adt_ref, state_substs, remap, storage_liveness, always_live_locals, suspension_points: Vec::new(), new_ret_local, discr_ty, }; transform.visit_body(body); // Update our MIR struct to reflect the changes we've made body.arg_count = 2; // self, resume arg body.spread_arg = None; body.generator.as_mut().unwrap().yield_ty = None; body.generator.as_mut().unwrap().generator_layout = Some(layout); // Insert `drop(generator_struct)` which is used to drop upvars for generators in // the unresumed state. // This is expanded to a drop ladder in `elaborate_generator_drops`. let drop_clean = insert_clean_drop(body); dump_mir(tcx, None, "generator_pre-elab", &amp;0, body, |_, _| Ok(())); // Expand `drop(generator_struct)` to a drop ladder which destroys upvars. // If any upvars are moved out of, drop elaboration will handle upvar destruction. // However we need to also elaborate the code generated by `insert_clean_drop`. elaborate_generator_drops(tcx, body); dump_mir(tcx, None, "generator_post-transform", &amp;0, body, |_, _| Ok(())); // Create a copy of our MIR and use it to create the drop shim for the generator let drop_shim = create_generator_drop_shim(tcx, &amp;transform, gen_ty, body, drop_clean); body.generator.as_mut().unwrap().generator_drop = Some(drop_shim); // Create the Generator::resume function create_generator_resume_function(tcx, transform, body, can_return); // Run derefer to fix Derefs that are not in the first place deref_finder(tcx, body); } } 第 85 行 compute_layout 计算出 GeneratorLayout，并在 111 行保存到 body.generator 中。这里的 GeneratorLayout 就是 GeneratorState 的内存空间，它分成两部分：prefix + variants。prefix 保存了会跨越 suspend point 的变量，variants 是不同的 state，其中保存了只会在当前 state 使用到的变量。 GeneratorState 的内存布局是如何计算的？ 编译器在代码生成阶段会根据前面计算得到的 GeneratorLayout 算出最终的内存布局 Layout(compiler/rustc_middle/src/ty/layout.rs): /// Compute the full generator layout. fn generator_layout( &amp;self, ty: Ty&lt;'tcx&gt;, def_id: hir::def_id::DefId, substs: SubstsRef&lt;'tcx&gt;, ) -&gt; Result&lt;Layout&lt;'tcx&gt;, LayoutError&lt;'tcx&gt;&gt; { use SavedLocalEligibility::*; let tcx = self.tcx; let subst_field = |ty: Ty&lt;'tcx&gt;| EarlyBinder(ty).subst(tcx, substs); let Some(info) = tcx.generator_layout(def_id) else { return Err(LayoutError::Unknown(ty)); }; let (ineligible_locals, assignments) = self.generator_saved_local_eligibility(&amp;info); // Build a prefix layout, including "promoting" all ineligible // locals as part of the prefix. We compute the layout of all of // these fields at once to get optimal packing. let tag_index = substs.as_generator().prefix_tys().count(); // `info.variant_fields` already accounts for the reserved variants, so no need to add them. let max_discr = (info.variant_fields.len() - 1) as u128; let discr_int = Integer::fit_unsigned(max_discr); let discr_int_ty = discr_int.to_ty(tcx, false); let tag = Scalar::Initialized { value: Primitive::Int(discr_int, false), valid_range: WrappingRange { start: 0, end: max_discr }, }; let tag_layout = self.tcx.intern_layout(LayoutS::scalar(self, tag)); let tag_layout = TyAndLayout { ty: discr_int_ty, layout: tag_layout }; let promoted_layouts = ineligible_locals .iter() .map(|local| subst_field(info.field_tys[local])) .map(|ty| tcx.mk_maybe_uninit(ty)) .map(|ty| self.layout_of(ty)); let prefix_layouts = substs .as_generator() .prefix_tys() .map(|ty| self.layout_of(ty)) .chain(iter::once(Ok(tag_layout))) .chain(promoted_layouts) .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;()?; let prefix = self.univariant_uninterned( ty, &amp;prefix_layouts, &amp;ReprOptions::default(), StructKind::AlwaysSized, )?; let (prefix_size, prefix_align) = (prefix.size, prefix.align); // Split the prefix layout into the "outer" fields (upvars and // discriminant) and the "promoted" fields. Promoted fields will // get included in each variant that requested them in // GeneratorLayout. debug!("prefix = {:#?}", prefix); let (outer_fields, promoted_offsets, promoted_memory_index) = match prefix.fields { FieldsShape::Arbitrary { mut offsets, memory_index } =&gt; { let mut inverse_memory_index = invert_mapping(&amp;memory_index); // "a" (`0..b_start`) and "b" (`b_start..`) correspond to // "outer" and "promoted" fields respectively. let b_start = (tag_index + 1) as u32; let offsets_b = offsets.split_off(b_start as usize); let offsets_a = offsets; // Disentangle the "a" and "b" components of `inverse_memory_index` // by preserving the order but keeping only one disjoint "half" each. // FIXME(eddyb) build a better abstraction for permutations, if possible. let inverse_memory_index_b: Vec&lt;_&gt; = inverse_memory_index.iter().filter_map(|&amp;i| i.checked_sub(b_start)).collect(); inverse_memory_index.retain(|&amp;i| i &lt; b_start); let inverse_memory_index_a = inverse_memory_index; // Since `inverse_memory_index_{a,b}` each only refer to their // respective fields, they can be safely inverted let memory_index_a = invert_mapping(&amp;inverse_memory_index_a); let memory_index_b = invert_mapping(&amp;inverse_memory_index_b); let outer_fields = FieldsShape::Arbitrary { offsets: offsets_a, memory_index: memory_index_a }; (outer_fields, offsets_b, memory_index_b) } _ =&gt; bug!(), }; let mut size = prefix.size; let mut align = prefix.align; let variants = info .variant_fields .iter_enumerated() .map(|(index, variant_fields)| { // Only include overlap-eligible fields when we compute our variant layout. let variant_only_tys = variant_fields .iter() .filter(|local| match assignments[**local] { Unassigned =&gt; bug!(), Assigned(v) if v == index =&gt; true, Assigned(_) =&gt; bug!("assignment does not match variant"), Ineligible(_) =&gt; false, }) .map(|local| subst_field(info.field_tys[*local])); let mut variant = self.univariant_uninterned( ty, &amp;variant_only_tys .map(|ty| self.layout_of(ty)) .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;()?, &amp;ReprOptions::default(), StructKind::Prefixed(prefix_size, prefix_align.abi), )?; variant.variants = Variants::Single { index }; let FieldsShape::Arbitrary { offsets, memory_index } = variant.fields else { bug!(); }; // Now, stitch the promoted and variant-only fields back together in // the order they are mentioned by our GeneratorLayout. // Because we only use some subset (that can differ between variants) // of the promoted fields, we can't just pick those elements of the // `promoted_memory_index` (as we'd end up with gaps). // So instead, we build an "inverse memory_index", as if all of the // promoted fields were being used, but leave the elements not in the // subset as `INVALID_FIELD_IDX`, which we can filter out later to // obtain a valid (bijective) mapping. const INVALID_FIELD_IDX: u32 = !0; let mut combined_inverse_memory_index = vec![INVALID_FIELD_IDX; promoted_memory_index.len() + memory_index.len()]; let mut offsets_and_memory_index = iter::zip(offsets, memory_index); let combined_offsets = variant_fields .iter() .enumerate() .map(|(i, local)| { let (offset, memory_index) = match assignments[*local] { Unassigned =&gt; bug!(), Assigned(_) =&gt; { let (offset, memory_index) = offsets_and_memory_index.next().unwrap(); (offset, promoted_memory_index.len() as u32 + memory_index) } Ineligible(field_idx) =&gt; { let field_idx = field_idx.unwrap() as usize; (promoted_offsets[field_idx], promoted_memory_index[field_idx]) } }; combined_inverse_memory_index[memory_index as usize] = i as u32; offset }) .collect(); // Remove the unused slots and invert the mapping to obtain the // combined `memory_index` (also see previous comment). combined_inverse_memory_index.retain(|&amp;i| i != INVALID_FIELD_IDX); let combined_memory_index = invert_mapping(&amp;combined_inverse_memory_index); variant.fields = FieldsShape::Arbitrary { offsets: combined_offsets, memory_index: combined_memory_index, }; size = size.max(variant.size); align = align.max(variant.align); Ok(tcx.intern_layout(variant)) }) .collect::&lt;Result&lt;IndexVec&lt;VariantIdx, _&gt;, _&gt;&gt;()?; size = size.align_to(align.abi); let abi = if prefix.abi.is_uninhabited() || variants.iter().all(|v| v.abi().is_uninhabited()) { Abi::Uninhabited } else { Abi::Aggregate { sized: true } }; let layout = tcx.intern_layout(LayoutS { variants: Variants::Multiple { tag, tag_encoding: TagEncoding::Direct, tag_field: tag_index, variants, }, fields: outer_fields, abi, largest_niche: prefix.largest_niche, size, align, }); debug!("generator layout ({:?}): {:#?}", ty, layout); Ok(layout) } LayoutS 的定义为： #[derive(PartialEq, Eq, Hash, HashStable_Generic)] pub struct LayoutS&lt;'a&gt; { /// Says where the fields are located within the layout. pub fields: FieldsShape, /// Encodes information about multi-variant layouts. /// Even with `Multiple` variants, a layout still has its own fields! Those are then /// shared between all variants. One of them will be the discriminant, /// but e.g. generators can have more. /// /// To access all fields of this layout, both `fields` and the fields of the active variant /// must be taken into account. pub variants: Variants&lt;'a&gt;, /// The `abi` defines how this data is passed between functions, and it defines /// value restrictions via `valid_range`. /// /// Note that this is entirely orthogonal to the recursive structure defined by /// `variants` and `fields`; for example, `ManuallyDrop&lt;Result&lt;isize, isize&gt;&gt;` has /// `Abi::ScalarPair`! So, even with non-`Aggregate` `abi`, `fields` and `variants` /// have to be taken into account to find all fields of this layout. pub abi: Abi, /// The leaf scalar with the largest number of invalid values /// (i.e. outside of its `valid_range`), if it exists. pub largest_niche: Option&lt;Niche&gt;, pub align: AbiAndPrefAlign, pub size: Size, } 根据定义，fields + variants 组成了 GeneratorState 的内存布局： To access all fields of this layout, both `fields` and the fields of the active variant must be taken into account. 在 generator_layout 函数中，fields 是 outer_fields，variants 是 Variant::Multiple 的实例，其中保存了 variants 和一个 tag_field。outer_fields 和 variants 均由 prefix 计算得到： // Split the prefix layout into the "outer" fields (upvars and // discriminant) and the "promoted" fields. Promoted fields will // get included in each variant that requested them in // GeneratorLayout prefix 的计算方式为： let tag_layout = self.tcx.intern_layout(LayoutS::scalar(self, tag)); let tag_layout = TyAndLayout { ty: discr_int_ty, layout: tag_layout }; let promoted_layouts = ineligible_locals .iter() .map(|local| subst_field(info.field_tys[local])) .map(|ty| tcx.mk_maybe_uninit(ty)) .map(|ty| self.layout_of(ty)); let prefix_layouts = substs .as_generator() .prefix_tys() .map(|ty| self.layout_of(ty)) .chain(iter::once(Ok(tag_layout))) .chain(promoted_layouts) .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;()?; let prefix = self.univariant_uninterned( ty, &amp;prefix_layouts, &amp;ReprOptions::default(), StructKind::AlwaysSized, )?; 其中 prefix_tys() 返回的就是前面提到的 upvars： /// This is the types of the fields of a generator which are not stored in a /// variant. #[inline] pub fn prefix_tys(self) -&gt; impl Iterator&lt;Item = Ty&lt;'tcx&gt;&gt; { self.upvar_tys() } 因此，一个 GeneratorState 的 Layout 中会包含一个 tag，upvars，以及由不同 state 组成的 variants。回到 root_heartbeat 的例子，streaming() 中，除了 request 和 response 外，还会保存下参数中的 request: Request&lt;S&gt;，path 和 codec。 codec: tonic::codec::ProstCodec&lt;engula_api::server::v1::HeartbeatRequest, engula_api::server::v1::HeartbeatResponse&gt; size 0 bytes request: tonic::Request&lt;futures::stream::Once&lt;futures::future::Ready&lt;engula_api::server::v1::HeartbeatRequest&gt;&gt;&gt; size 144 bytes path: http::uri::path::PathAndQuery size 40 bytes tag: u8 最终的大小为：self(8 bytes) + request(144 bytes) + path(40 bytes) + uri(88 bytes) + request(240 bytes, http request) + response(32 bytes) + tag(1 byte, aligned to 8) = 560 此处 uri 是前面计算漏掉的变量。 由于 async fn 的参数作为 captured variable，会放置在 outer_fields 中。如果一个非常大的参数层层传递到内部的某个 async fn，会被一层层放大，最终导致 Future 大小呈现指数增长。 19 年有一个 issue 已经指出了这个问题1。 解决方案？ 对于普通开发者，临时的解决办法有两点： 避免 pass by value，可以使用 Arc 或者 reference 减少使用 async fn。对于 tail calling，可以直接使用 impl Future，避免无意义的 await。对于状态不复杂的 async fn，也可以考虑手写 Future::poll()。 cpp 提供了右值引用，这类层层传递的变量可以被自然地优化；而 rust 依靠编译器优化，就得依靠生成的代码能满足优化的前置条件。 当然，community 也有人提供了改进方案2。该方案可以简述如下：即将 upvars 保存到 GeneratorState 的 unresumed state 中 （每个 GenerateState 至少有三种 state: unresumed, finished, paniced, 以及用户定义的 suspent_x)。 不过因为 rust 编译器架构改成了 demand-deriven compilation，该方案碰到了 query 循环依赖的问题， 需要等待其他人先将修复 dest prop 3。 https://github.com/rust-lang/rust/issues/62958 &#8617; https://github.com/rust-lang/rust/pull/89213 &#8617; https://github.com/rust-lang/rust/pull/96451 &#8617;]]></summary></entry><entry><title type="html">CockroachDB KV Source Code Reading Notes</title><link href="/2022/05/24/CockroachDB-Source-Code.html" rel="alternate" type="text/html" title="CockroachDB KV Source Code Reading Notes" /><published>2022-05-24T00:00:00+08:00</published><updated>2022-05-24T00:00:00+08:00</updated><id>/2022/05/24/CockroachDB-Source-Code</id><content type="html" xml:base="/2022/05/24/CockroachDB-Source-Code.html"><![CDATA[<h1 id="cockroachdb-kv">CockroachDB KV</h1>

<h2 id="entrance">Entrance</h2>

<p>In <code class="language-plaintext highlighter-rouge">pkg/cmd/cockroach.go</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">func</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">cli</span><span class="o">.</span><span class="n">Main</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In <code class="language-plaintext highlighter-rouge">pkg/cli/cli.go</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cockroachCmd</span><span class="o">.</span><span class="n">AddCommand</span><span class="p">(</span>
    <span class="n">startCmd</span><span class="p">,</span>
    <span class="n">initCmd</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<p>According <a href="http://doc.cockroachchina.baidu.com/#deploy/manual-deployment/on-premises/#step-3">cockroach db manual</a>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cockroach start --join xxx
cockroach init --host &lt;address of any node&gt;
</code></pre></div></div>

<p>So the setup logic lie in <code class="language-plaintext highlighter-rouge">startCmd</code>, and cluster bootstrap login lie in <code class="language-plaintext highlighter-rouge">initCmd</code>.</p>

<p>In <code class="language-plaintext highlighter-rouge">pkg/cli/start.go</code>, command <code class="language-plaintext highlighter-rouge">startCmd</code> will invoke <code class="language-plaintext highlighter-rouge">runStartJoin</code> -&gt; <code class="language-plaintext highlighter-rouge">runStart</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>func runStart() {
    var s *server.Server
    s, err = server.NewServer()
    s.PreStart()
    s.InitialStart()
    s.AcceptClients()
}
</code></pre></div></div>

<h2 id="start-node">Start Node</h2>

<p>In <code class="language-plaintext highlighter-rouge">Server::NewServer</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clock</span> <span class="o">=</span> <span class="n">hlc</span><span class="o">.</span><span class="n">NewClock</span><span class="p">()</span>
<span class="n">engines</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">CreateEngines</span><span class="p">()</span>
    <span class="n">eng</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">NewPebble</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">pebbleConfig</span><span class="p">)</span>
<span class="n">rpcContext</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">NewContext</span><span class="p">()</span>
<span class="n">grpcServer</span> <span class="o">=</span> <span class="n">newGRPCServer</span><span class="p">(</span><span class="n">rpcContext</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">gossip</span><span class="o">.</span><span class="n">New</span><span class="p">()</span>
<span class="n">distSender</span> <span class="o">=</span> <span class="n">kvcoord</span><span class="o">.</span><span class="n">NewDistSender</span><span class="p">()</span>  <span class="c">// `pkg/kv/kvclient/kvcoord/dist_sender.go`</span>
<span class="n">tcsFactory</span> <span class="o">=</span> <span class="n">kvcoord</span><span class="o">.</span><span class="n">NewTxnCoordSenderFactory</span><span class="p">(</span><span class="n">txnCoordSenderFactoryCfg</span><span class="p">,</span> <span class="n">distSender</span><span class="p">)</span>  <span class="c">// `pkg/kv/kvclient/kvcoord/txn_coord_sender_factory.go`</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">kv</span><span class="o">.</span><span class="n">NewDBWithContext</span><span class="p">(</span><span class="n">clock</span><span class="p">,</span> <span class="n">dbCtx</span><span class="p">)</span>
<span class="n">raftTransport</span> <span class="o">=</span> <span class="n">kvserver</span><span class="o">.</span><span class="n">NewRaftTransport</span><span class="p">()</span>
<span class="n">stores</span> <span class="o">=</span> <span class="n">kvserver</span><span class="o">.</span><span class="n">NewStores</span><span class="p">()</span>
<span class="n">tsDB</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">NewDB</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">tcsFactory</span><span class="p">)</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">NewNode</span><span class="p">()</span>
<span class="n">roachpb</span><span class="o">.</span><span class="n">RegisterInternalServer</span><span class="p">(</span><span class="n">grpcServer</span><span class="o">.</span><span class="n">Server</span><span class="p">,</span> <span class="n">node</span><span class="p">)</span>
<span class="n">kvserver</span><span class="o">.</span><span class="n">RegisterPerReplicaServer</span><span class="p">(</span><span class="n">grpcServer</span><span class="o">.</span><span class="n">Server</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">perReplicaServer</span><span class="p">)</span>
<span class="n">kvserver</span><span class="o">.</span><span class="n">RegisterPerStoreServer</span><span class="p">(</span><span class="n">grpcServer</span><span class="o">.</span><span class="n">Server</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">perReplicaServer</span><span class="p">)</span>
<span class="n">ctpb</span><span class="o">.</span><span class="n">RegisterSideTransportServer</span><span class="p">(</span><span class="n">grpcServer</span><span class="o">.</span><span class="n">Server</span><span class="p">,</span> <span class="n">ctReceiver</span><span class="p">)</span>
<span class="n">sqlServer</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">newSQLServer</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">sqlServerArgs</span><span class="p">)</span>
</code></pre></div></div>

<p>In <code class="language-plaintext highlighter-rouge">Server::PreStart</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span><span class="o">.</span><span class="n">rpcContext</span><span class="o">.</span><span class="n">SetLocalInternalServer</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">node</span><span class="p">)</span>
<span class="n">s</span><span class="o">.</span><span class="n">http</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">s</span><span class="o">.</span><span class="n">externalStorageBuilder</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">inspectEngineState</span> <span class="o">=</span> <span class="n">inspectEngines</span><span class="p">()</span>   <span class="c">// go through engines and constructs an initState. In `pkg/server/init.go`</span>
    <span class="n">storeIdent</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">kvserver</span><span class="o">.</span><span class="n">ReadStoreIdent</span><span class="p">()</span>
<span class="n">serverpb</span><span class="o">.</span><span class="n">RegisterInitServer</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">grpc</span><span class="o">.</span><span class="n">Server</span><span class="p">,</span> <span class="n">initServer</span><span class="p">)</span>  <span class="c">// support `service Init` in `pkg/server/serverpb/init.proto`.</span>
<span class="n">startListenRPCAndSQL</span><span class="p">()</span> <span class="c">// only start rpc server, but initialize sql server.</span>
<span class="n">configureGRPCGateway</span><span class="p">()</span>
<span class="n">startRPCServer</span><span class="p">()</span>
<span class="n">onInitServerReady</span><span class="p">()</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">initServer</span><span class="o">.</span><span class="n">ServeAndWait</span><span class="p">()</span>
    <span class="c">// bootstrapAddresses := cfg.FilterGossipBootstrapAddress() in `newInitServerConfig`. from func (cfg *Config) parseGossipBootstrapAddresses</span>
    <span class="n">s</span><span class="o">.</span><span class="n">startJoinLoop</span><span class="p">()</span> <span class="c">// continuously retries connecting to nodes specified in the join list, in order to determine what the cluster ID, node ID is.</span>
        <span class="n">s</span><span class="o">.</span><span class="n">attemptJoinIn</span><span class="p">()</span>
            <span class="n">send</span> <span class="n">JoinNodeRequest</span>
        <span class="n">s</span><span class="o">.</span><span class="n">initializeFirstStoreAfterJoin</span><span class="p">()</span>
            <span class="n">kvserver</span><span class="o">.</span><span class="n">InitEngines</span><span class="p">()</span>
    <span class="n">state</span> <span class="o">:=</span> <span class="o">&lt;-</span> <span class="n">s</span><span class="o">.</span><span class="n">joinCh</span>
<span class="n">s</span><span class="o">.</span><span class="n">rpcContext</span><span class="o">.</span><span class="n">NodeID</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">NodeID</span><span class="p">)</span>
<span class="n">runAsyncTask</span><span class="p">(</span><span class="s">"connect-gossip"</span><span class="p">)</span>  <span class="c">// only log</span>
<span class="n">s</span><span class="o">.</span><span class="n">gossip</span><span class="o">.</span><span class="n">Start</span><span class="p">()</span>
    <span class="n">g</span><span class="o">.</span><span class="n">setAddresses</span><span class="p">(</span><span class="n">addresses</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">server</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">g</span><span class="o">.</span><span class="n">bootstrap</span><span class="p">()</span>
    <span class="n">g</span><span class="o">.</span><span class="n">manage</span><span class="p">()</span>
<span class="n">s</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>  <span class="c">// In `pkg/server/node.go`</span>
<span class="n">s</span><span class="o">.</span><span class="n">replicationReporter</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">s</span><span class="o">.</span><span class="n">sqlServer</span><span class="o">.</span><span class="n">preStart</span><span class="p">()</span>
</code></pre></div></div>

<p>There are some comments in <code class="language-plaintext highlighter-rouge">PreStart</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// "bootstrapping problem": nodes need to connect to Gossip fairly</span>
<span class="c">// early, but what drives Gossip connectivity are the first range</span>
<span class="c">// replicas in the kv store. This in turn suggests opening the Gossip</span>
<span class="c">// server early. However, naively doing so also serves most other</span>
<span class="c">// services prematurely, which exposes a large surface of potentially</span>
<span class="c">// underinitialized services. This is avoided with some additional</span>
<span class="c">// complexity that can be summarized as follows:</span>
<span class="c">//</span>
<span class="c">// - before blocking trying to connect to the Gossip network, we already open</span>
<span class="c">//   the admin UI (so that its diagnostics are available)</span>
<span class="c">// - we also allow our Gossip and our connection health Ping service</span>
<span class="c">// - everything else returns Unavailable errors (which are retryable)</span>
<span class="c">// - once the node has started, unlock all RPCs.</span>
</code></pre></div></div>

<p>In <code class="language-plaintext highlighter-rouge">Node::start</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="o">.</span><span class="n">storeCfg</span><span class="o">.</span><span class="n">Gossip</span><span class="o">.</span><span class="n">NodeID</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">nodeDescriptor</span><span class="o">.</span><span class="n">NodeID</span><span class="p">)</span>
<span class="n">n</span><span class="o">.</span><span class="n">storeCfg</span><span class="o">.</span><span class="n">Gossip</span><span class="o">.</span><span class="n">SetNodeDescriptor</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">nodeDescriptor</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">e</span> <span class="o">:=</span> <span class="n">state</span><span class="o">.</span><span class="n">initializedEngines</span> <span class="p">{</span>
    <span class="n">s</span> <span class="o">:=</span> <span class="n">kvserver</span><span class="o">.</span><span class="n">NewStore</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>  <span class="c">// In `pkg/kv/kvserver/store.go`</span>
    <span class="n">s</span><span class="o">.</span><span class="n">Start</span><span class="p">()</span>
        <span class="c">// Iterate over all range descriptor, ignoring uncommitted version.</span>
        <span class="n">IterateRangeDescriptorFromDisk</span><span class="p">()</span>
            <span class="n">replica</span> <span class="o">=</span> <span class="n">newReplica</span><span class="p">()</span>  <span class="c">// In `pkg/kv/kvserver/replica_init.go`</span>
                <span class="n">newUnloadReplica</span><span class="p">()</span>
                <span class="n">loadRaftMuLockedReplicaMuLocked</span><span class="p">()</span>
                    <span class="n">lastIndex</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">stateLoader</span><span class="o">.</span><span class="n">LoadLastIndex</span><span class="p">()</span>
            <span class="n">s</span><span class="o">.</span><span class="n">addReplicaInternal</span><span class="p">(</span><span class="n">replica</span><span class="p">)</span>
        <span class="n">s</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">Transport</span><span class="o">.</span><span class="n">Listen</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">StoreID</span><span class="p">(),</span> <span class="n">s</span><span class="p">)</span>
        <span class="n">s</span><span class="o">.</span><span class="n">processRaft</span><span class="p">()</span>
        <span class="n">s</span><span class="o">.</span><span class="n">storeRebalancer</span><span class="o">.</span><span class="n">Start</span><span class="p">()</span> <span class="c">// rebalance is finished in store?</span>
        <span class="n">s</span><span class="o">.</span><span class="n">startGossip</span><span class="p">()</span>
        <span class="n">s</span><span class="o">.</span><span class="n">startLeaseRenewer</span><span class="p">()</span>

    <span class="n">n</span><span class="o">.</span><span class="n">addStore</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">n</span><span class="o">.</span><span class="n">storeCfg</span><span class="o">.</span><span class="n">Gossip</span><span class="o">.</span><span class="n">SetStorage</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">stores</span><span class="p">)</span>
<span class="n">n</span><span class="o">.</span><span class="n">startGossiping</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">stopper</span><span class="p">)</span>  <span class="c">// loops on a periodic ticker to gossip node-related information.</span>
    <span class="n">s</span><span class="o">.</span><span class="n">GossipStore</span><span class="p">()</span> <span class="c">// GossipStore broadcasts the store on the gossip network.</span>
</code></pre></div></div>

<p>In <code class="language-plaintext highlighter-rouge">Server::AcceptClients</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span><span class="o">.</span><span class="n">sqlServer</span><span class="o">.</span><span class="n">startServerSQL</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="start-store">Start Store</h3>

<p>In <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/store.go</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Store::Start
    ReadStoreIdent
    idalloc.NewAllocator
    intentResolver.New
    makeRaftLogTruncator
    txnrecovery.NewManager
    // Iterate over all range descriptor, ignoring uncommitted version.
    IterateRangeDescriptorFromDisk()
        replica = newReplica()  // In `pkg/kv/kvserver/replica_init.go`
            newUnloadReplica()
            loadRaftMuLockedReplicaMuLocked()
                lastIndex = r.stateLoader.LoadLastIndex()
        s.addReplicaInternal(replica)
    s.cfg.Transport.Listen(s.StoreID(), s)
	s.cfg.NodeLiveness.RegisterCallback(s.nodeIsLiveCallback)
    s.processRaft()
    s.storeRebalancer.Start() // rebalance is finished in store?
    s.startGossip()
    s.startLeaseRenewer()
    s.startRangefeedUpdator()
    NewStoreRebalancer()
</code></pre></div></div>

<h4 id="id-allocator">ID Allocator</h4>

<p>In <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/store.go</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// Create ID allocators.</span>
<span class="n">idAlloc</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">idalloc</span><span class="o">.</span><span class="n">NewAllocator</span><span class="p">(</span><span class="n">idalloc</span><span class="o">.</span><span class="n">Options</span><span class="p">{</span>
    <span class="n">AmbientCtx</span><span class="o">:</span>  <span class="n">s</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">AmbientCtx</span><span class="p">,</span>
    <span class="n">Key</span><span class="o">:</span>         <span class="n">keys</span><span class="o">.</span><span class="n">RangeIDGenerator</span><span class="p">,</span>
    <span class="n">Incrementer</span><span class="o">:</span> <span class="n">idalloc</span><span class="o">.</span><span class="n">DBIncrementer</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">db</span><span class="p">),</span>
    <span class="n">BlockSize</span><span class="o">:</span>   <span class="n">rangeIDAllocCount</span><span class="p">,</span>
    <span class="n">Stopper</span><span class="o">:</span>     <span class="n">s</span><span class="o">.</span><span class="n">stopper</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">Allocator</code> will allocate <code class="language-plaintext highlighter-rouge">rangeIDAllocCount</code> count from <code class="language-plaintext highlighter-rouge">DB</code> with key <code class="language-plaintext highlighter-rouge">keys.RangeIDGenerator</code>.</p>

<h2 id="bootstrap">Bootstrap</h2>

<p>In <code class="language-plaintext highlighter-rouge">pkg/cli/init.go</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">func</span> <span class="n">runInit</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">c</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">NewInitClient</span><span class="p">()</span>
    <span class="n">c</span><span class="o">.</span><span class="n">Bootstrap</span><span class="p">(</span><span class="n">BootstrapRequest</span> <span class="p">{})</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In <code class="language-plaintext highlighter-rouge">pkg/server/init.go</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">func</span> <span class="p">(</span><span class="n">s</span> <span class="o">*</span><span class="n">initServer</span><span class="p">)</span> <span class="n">Bootstrap</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">state</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">tryBootstrap</span><span class="p">()</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">s</span> <span class="o">*</span><span class="n">initServer</span><span class="p">)</span> <span class="n">tryBootstrap</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">bootstrapCluster</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In <code class="language-plaintext highlighter-rouge">pkg/server/node.go</code>, function <code class="language-plaintext highlighter-rouge">bootstrapCluster</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">kvserver</span><span class="o">.</span><span class="n">InitEngine</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">storeIdent</span><span class="p">)</span>
<span class="n">kvserver</span><span class="o">.</span><span class="n">WriteInitialClusterData</span><span class="p">()</span> <span class="c">// writes initialization data to an engine. It creates system ranges (filling in meta1 and meta2) and the default zone config.</span>
</code></pre></div></div>

<p>Question:</p>
<ul>
  <li>When the first range was creatiation?
In <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/store_init.go</code>:
    <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              <span class="n">desc</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="n">roachpb</span><span class="o">.</span><span class="n">RangeDescriptor</span><span class="p">{</span>
                      <span class="n">RangeID</span><span class="o">:</span>       <span class="n">rangeID</span><span class="p">,</span>
                      <span class="n">StartKey</span><span class="o">:</span>      <span class="n">startKey</span><span class="p">,</span>
                      <span class="n">EndKey</span><span class="o">:</span>        <span class="n">endKey</span><span class="p">,</span>
                      <span class="n">NextReplicaID</span><span class="o">:</span> <span class="m">2</span><span class="p">,</span>
              <span class="p">}</span>
              <span class="k">const</span> <span class="n">firstReplicaID</span> <span class="o">=</span> <span class="m">1</span>
              <span class="n">replicas</span> <span class="o">:=</span> <span class="p">[]</span><span class="n">roachpb</span><span class="o">.</span><span class="n">ReplicaDescriptor</span><span class="p">{</span>
                      <span class="p">{</span>
                              <span class="n">NodeID</span><span class="o">:</span>    <span class="n">FirstNodeID</span><span class="p">,</span>
                              <span class="n">StoreID</span><span class="o">:</span>   <span class="n">FirstStoreID</span><span class="p">,</span>
                              <span class="n">ReplicaID</span><span class="o">:</span> <span class="n">firstReplicaID</span><span class="p">,</span>
                      <span class="p">},</span>
              <span class="p">}</span>
              <span class="n">desc</span><span class="o">.</span><span class="n">SetReplicas</span><span class="p">(</span><span class="n">roachpb</span><span class="o">.</span><span class="n">MakeReplicaSet</span><span class="p">(</span><span class="n">replicas</span><span class="p">))</span>
</code></pre></div>    </div>
  </li>
  <li>How to determine whether a cluster has been bootstrapped when restarting?
    <ol>
      <li>In <code class="language-plaintext highlighter-rouge">Server::PreStart</code>, <code class="language-plaintext highlighter-rouge">inspectEngineState := InspectEngines()</code></li>
      <li>In <code class="language-plaintext highlighter-rouge">InitServer::ServeAndWait</code>, <code class="language-plaintext highlighter-rouge">s.inspectEngineState.bootstrapt()</code></li>
    </ol>
  </li>
  <li>When to start serving ranges?
See <code class="language-plaintext highlighter-rouge">Node::start</code> for details.</li>
  <li>What happen if no any join list was specified?
Report errors</li>
</ul>

<h2 id="join-node">Join Node</h2>

<p>In <code class="language-plaintext highlighter-rouge">pkg/server/node.go</code>, function <code class="language-plaintext highlighter-rouge">Join()</code>:</p>
<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">compareBinaryVersion</span><span class="p">()</span>
<span class="n">nodeID</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">allocateNodeID</span><span class="p">()</span>
    <span class="n">val</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">kv</span><span class="o">.</span><span class="n">IncrementValRetryable</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">NodeIDGenerator</span><span class="p">,</span> <span class="m">1</span><span class="p">)</span>
        <span class="n">db</span><span class="o">.</span><span class="n">Inc</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">inc</span><span class="p">)</span> <span class="c">// pkg/kv/db.go   var db *DB</span>
<span class="n">storeID</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">allocateStoreIDs</span><span class="p">()</span>
    <span class="n">val</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">kv</span><span class="o">.</span><span class="n">IncrementValRetryable</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">StoreIDGenerator</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>
<span class="c">// create liveness record, so what is the purpose of liveness record?</span>
<span class="n">n</span><span class="o">.</span><span class="n">storeCfg</span><span class="o">.</span><span class="n">NodeLiveness</span><span class="o">.</span><span class="n">CreateLivenessRecord</span><span class="p">()</span>
</code></pre></div></div>

<p>Questions:</p>
<ul>
  <li>What happen if receives <code class="language-plaintext highlighter-rouge">Join</code> requests?
Only check version and allocate NodeID. If a node has already bootstrapted, it won’t allocate new node id again (See PreStart() for details).</li>
  <li>What should to do for adding new table?
TODO</li>
  <li>Where is the master role for cockroachdb?
TODO</li>
</ul>

<h2 id="add-replica-on-store">Add Replica on Store</h2>

<p>In <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/store_create_replica.go</code>, function <code class="language-plaintext highlighter-rouge">getOrCreateReplica</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>getOrCreateReplica -&gt; tryGetOrCreateReplica
    // 1. current replica is removed, go back around
    // 2. drop messages from replica we known to be too old
    // 3. the current replica need to be removed, remove it and go back around
    // 4. drop staled msg silently
    // 5. check tombstone
    newUnloadedReplica
    Store::addReplicaToRangeMapLocked
    StateLoader::SetRangeReplicaID
    Replica::loadRaftMuLockedReplicaMuLocked
</code></pre></div></div>

<p>Questions:</p>
<ul>
  <li>When the new replica are created?
See above.</li>
</ul>

<h2 id="raft">Raft</h2>

<ol>
  <li>Initialize
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Node::start
 Store::processRaft
     raftScheduler::Start
         async raftScheduler::worker
     async raftScheduler::Wait
     async raftTickLoop
     async coalescedHeartbeatsLoop
</code></pre></div>    </div>
  </li>
  <li>run worker, in <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/store_raft.go</code> and <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/replica_raft.go</code>.
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>raftScheduler::worker
 raftScheduler::processTick
     Replica::tick(IsLiveMap)  // `pkg/kv/kvserver/replica_raft.go`
         RawNode::ReportUnreachable(Replica.unreachablesMu.remotes)
         Replica::maybeQuiesceRaftMuLockedReplicaMuLocked
         Replica::maybeTransferRaftLeadershipToLeaseholderLocked
         RawNode::Tick
 raftScheduler::processReady
     // See below apply parts.
 raftScheduler::processRequestQueue
     Store::withReplicaForRequest
         Store::getOrCreateReplica
         Store::processRaftRequestWithReplica
             Replica::stepRaftGroup
                 Replica::withRaftGroup
                     // if internal raft group is null, try create it
                     RawNode::Step
</code></pre></div>    </div>
  </li>
  <li>propose
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Node::Batch -&gt; Node::batchInternal
 Stores::Send(BatchRequest) -&gt; Stores::GetStore -&gt; Store::Send   // `pkg/kv/kvserver/store_send.go`
     Clock::Update  // Advances the local node's clock  to a high water mark from all nodes with which it has interacted.
     Store::GetReplica -&gt; Replica::Send -&gt; Replica::sendWithoutRangeID   // `pkg/kv/kvserver/replica_send.go`
         Replica::maybeInitializeRaftGroup      // If the internal Raft group is not initialized, create it and wake the leader.
             Replica::withRaftGroupLocked
                 Replica::maybeCampaignOnWakeLocked -&gt; Replica::campaignLocked
                     Store::enqueueRaftUpdateCheck -&gt; raftScheduler::EnqueueRaftReady
         Replica::executeBatchWithConcurrencyRetries
             Replica::executeReadOnlyBatch
             Replica::executeReadWriteBatch     // `pkg/kv/kvserver/replica_write.go`
                 Replica::applyTimestampCache
                 Replica::evalAndPropose        // `pkg/kv/kvserver/replica_raft.go`
                     Replica::requestToProposal // `pkg/kv/kvserver/replica_proposal.go`
                         Replica::evaluateProposal -&gt; Replica::evaluateWriteBatch
                             Replica::evaluate1PC
                             Replica::evaluateWriteBatchWithServersideRefreshes -&gt; Replica::evaluateWriteBatchWrapper -&gt; evaluateBatch  // `pkg/kv/kvserver/replica_evaluate.go`
                                 optimizePuts
                                 evaluateCommand
                                     batcheval.LookupCommand
                                     Command::EvalRO
                                     Command::EvalRW
                                         Put     // `pkg/kv/kvserver/batcheval/cmd_put.go`
                                             storage.MVCCPut
                                             storage.MVCCConditionalPut  // `pkg/storage/mvcc.go`
                     Replica::propose -&gt; propBuf::Insert
         Replica::executeAdminBatch   // No interaction with the spanlatch manager or the timestamp cache.
         Replica::maybeAddRangeInfoToResponse
     // if ranges are mismatched, try to suggest a more suitable range from this store.
</code></pre></div>    </div>
  </li>
  <li>apply
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Store::processReady -&gt; Replica::HandleRaftReady -&gt; Replica::HandleRaftReadyRaftMuLocked -&gt; Replica::withRaftGroupLocked
 propBuf::FlushLockedWithRaftGroup   // Question: will `propBuf::Insert` signal ready queue?
 RawNode::Ready
 Replica::applySnapshot
 Task::AckCommittedEntriesBeforeApplication  // `pkg/kv/kvserver/apply/task.go`
 Replica::sendRaftMessagesRaftMuLocked       // `pkg/kv/kvserver/replica_raft.go`
 Replica::append                             // `pkg/kv/kvserver/replica_raftstorage.go`
     storage.Writer::MVCCPut                 // Writer is `Store::Engine().NewUnindexedBatch`
     Batch::Commit
 Replica::sendRaftMessagesRaftMuLocked       // `pkg/kv/kvserver/replica_raft.go`
 Task::ApplyCommittedEntries -&gt; Task::ApplyOneBatch
     Batch::Stage(Command) -&gt; replicaAppBatch::Stage   // `pkg/kv/kvserver/replica_application_state_machine.go`
         Replica::ShouldApplyCommand
     Batch::ApplyToStateMachine              // StateMachine::NewBatch
     AppliedCommand::AckOutcomeAndFinish
 Replica::withRaftGroupLocked
     RawNode::Advance(Ready)
     Replica::campaignLocked     // if shouldCampaignAfterConfChange: if raft leader got moved, campaign the first remaning voter.
     Store::enqueueRaftUpdateCheck  // if RawNode::HasReady
</code></pre></div>    </div>
  </li>
  <li>transport
API defines in <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/storage_services.proto</code>:
    <div class="language-proto highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">service</span> <span class="n">MultiRaft</span> <span class="p">{</span>
 <span class="k">rpc</span> <span class="n">RaftMessageBatch</span> <span class="p">(</span><span class="n">stream</span> <span class="n">cockroach.kv.kvserver.kvserverpb.RaftMessageRequestBatch</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">stream</span> <span class="n">cockroach.kv.kvserver.kvserverpb.RaftMessageResponse</span><span class="p">)</span> <span class="p">{}</span>
 <span class="k">rpc</span> <span class="n">RaftSnapshot</span> <span class="p">(</span><span class="n">stream</span> <span class="n">cockroach.kv.kvserver.kvserverpb.SnapshotRequest</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">stream</span> <span class="n">cockroach.kv.kvserver.kvserverpb.SnapshotResponse</span><span class="p">)</span> <span class="p">{}</span>
 <span class="k">rpc</span> <span class="n">DelegateRaftSnapshot</span><span class="p">(</span><span class="n">stream</span> <span class="n">cockroach.kv.kvserver.kvserverpb.DelegateSnapshotRequest</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">stream</span> <span class="n">cockroach.kv.kvserver.kvserverpb.DelegateSnapshotResponse</span><span class="p">)</span> <span class="p">{}</span>
<span class="p">}</span>
</code></pre></div>    </div>
  </li>
</ol>

<p>The implementation lie in <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/raft_transport.go</code>, function is <code class="language-plaintext highlighter-rouge">RaftTransport::RaftMessageBatch</code>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RaftMessageBatch
    stream.Recv
    RaftTransport::handleRaftRequest
        RaftTransport::getHandler(StoreID)  // read handler of corresponding store ID
        Store::HandleRaftRequest            // `pkg/kv/kvserver/store_raft.go`: dispatches a raft message to the appropriate Replica.
            Store::HandleRaftUncoalescedRequest
                raftReceiveQueues::LoadOrCreate(RangeID)
                raftReceiveQueue::Append
            raftScheduler::EnqueueRaftRequest
    stream.Send(newRaftMessageResponse)
</code></pre></div></div>

<p>Questions:</p>
<ul>
  <li>Where the <code class="language-plaintext highlighter-rouge">conditional_put</code> is executed?
In file <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/batcheval/cmd_conditional_put.go</code>, it is invoked by <code class="language-plaintext highlighter-rouge">executeCommand</code>.</li>
  <li>What is the purpose of <code class="language-plaintext highlighter-rouge">CommandID</code>?
The command ID is equals <code class="language-plaintext highlighter-rouge">makeIDKey() -&gt; rand.Int64()</code>.
    <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// CmdIDKey is a Raft command id. This will be logged unredacted - keep it random.</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="rebalance">Rebalance</h2>

<p>In <code class="language-plaintext highlighter-rouge">pkg/kv/kvserver/store.go</code>, function <code class="language-plaintext highlighter-rouge">Store::Start</code>:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">NewStoreRebalancer</span>
<span class="n">StoreRebalancer</span><span class="o">::</span><span class="n">Start</span>
    <span class="c">// rebalanceStore iterates through the top K hottest ranges on this store and</span>
    <span class="c">// for each such range, performs a lease transfer if it determines that that</span>
    <span class="c">// will improve QPS balance across the stores in the cluster. After it runs out</span>
    <span class="c">// of leases to transfer away (i.e. because it couldn't find better</span>
    <span class="c">// replacements), it considers these ranges for replica rebalancing.</span>
    <span class="n">async</span> <span class="n">StoreRebalancer</span><span class="o">::</span><span class="n">rebalanceStore</span>
        <span class="n">StoreRebalancer</span><span class="o">::</span><span class="n">chooseLeaseToTransfer</span>
        <span class="n">replicateQueue</span><span class="o">::</span><span class="n">transferLease</span>
        <span class="n">StoreRebalancer</span><span class="o">::</span><span class="n">chooseRangeToRebalance</span>
        <span class="n">DB</span><span class="o">::</span><span class="n">AdminRelocateRange</span>
</code></pre></div></div>

<h2 id="db">DB</h2>

<p>DB is a database handle to a single cockroach cluster. A DB is safe for concurrent use by multiple goroutines.</p>

<p><code class="language-plaintext highlighter-rouge">kv.DB</code> interfaces:</p>
<ul>
  <li>Get</li>
  <li>GetForUpdate</li>
  <li>GetProto</li>
  <li>GetProtoTs</li>
  <li>Put</li>
  <li>PutInline</li>
  <li>CPut</li>
  <li>Inc</li>
  <li>Scan</li>
  <li>AdminSplit</li>
  <li>AdminMerge</li>
  <li>AdminRelocateRange</li>
  <li>AdminChangeReplicas</li>
  <li>etc …</li>
</ul>

<p>Put code path:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DB::Put -&gt; DB::Run(Batch) -&gt; DB::SendAndFail -&gt; DB::send -&gt; DB::sendUsingSender
    CrossRangeTxnWrapperSender::Send -&gt; DistSender::Send
        DistSender::initAndVerifyBatch
        keys.Range
        DistSender::divideAndSendParallelCommit
            DistSender::divideAndSendBatchToRanges
        DistSender::divideAndSendBatchToRanges
            RangeIterator::Seek
            DistSender::sendPartialBatch
                DistSender::sendToReplicas
                    DistSender::transportFactory
                    Transport::SendNext
</code></pre></div></div>

<h3 id="error-retry">Error Retry</h3>

<p>TODO</p>

<h3 id="range-cache">Range Cache</h3>

<p>TODO</p>

<h3 id="txn">Txn</h3>

<p>TODO</p>]]></content><author><name></name></author><summary type="html"><![CDATA[CockroachDB KV Entrance In pkg/cmd/cockroach.go: func main() { cli.Main() } In pkg/cli/cli.go: cockroachCmd.AddCommand( startCmd, initCmd, ) According cockroach db manual: cockroach start --join xxx cockroach init --host &lt;address of any node&gt; So the setup logic lie in startCmd, and cluster bootstrap login lie in initCmd. In pkg/cli/start.go, command startCmd will invoke runStartJoin -&gt; runStart: func runStart() { var s *server.Server s, err = server.NewServer() s.PreStart() s.InitialStart() s.AcceptClients() } Start Node In Server::NewServer: clock = hlc.NewClock() engines = cfg.CreateEngines() eng, err = storage.NewPebble(ctx, pebbleConfig) rpcContext = rpc.NewContext() grpcServer = newGRPCServer(rpcContext) g = gossip.New() distSender = kvcoord.NewDistSender() // `pkg/kv/kvclient/kvcoord/dist_sender.go` tcsFactory = kvcoord.NewTxnCoordSenderFactory(txnCoordSenderFactoryCfg, distSender) // `pkg/kv/kvclient/kvcoord/txn_coord_sender_factory.go` db = kv.NewDBWithContext(clock, dbCtx) raftTransport = kvserver.NewRaftTransport() stores = kvserver.NewStores() tsDB = ts.NewDB(db, tcsFactory) node = NewNode() roachpb.RegisterInternalServer(grpcServer.Server, node) kvserver.RegisterPerReplicaServer(grpcServer.Server, node.perReplicaServer) kvserver.RegisterPerStoreServer(grpcServer.Server, node.perReplicaServer) ctpb.RegisterSideTransportServer(grpcServer.Server, ctReceiver) sqlServer, err := newSQLServer(ctx, sqlServerArgs) In Server::PreStart: s.rpcContext.SetLocalInternalServer(s.node) s.http.start() s.externalStorageBuilder.init() inspectEngineState = inspectEngines() // go through engines and constructs an initState. In `pkg/server/init.go` storeIdent, err = kvserver.ReadStoreIdent() serverpb.RegisterInitServer(s.grpc.Server, initServer) // support `service Init` in `pkg/server/serverpb/init.proto`. startListenRPCAndSQL() // only start rpc server, but initialize sql server. configureGRPCGateway() startRPCServer() onInitServerReady() state = initServer.ServeAndWait() // bootstrapAddresses := cfg.FilterGossipBootstrapAddress() in `newInitServerConfig`. from func (cfg *Config) parseGossipBootstrapAddresses s.startJoinLoop() // continuously retries connecting to nodes specified in the join list, in order to determine what the cluster ID, node ID is. s.attemptJoinIn() send JoinNodeRequest s.initializeFirstStoreAfterJoin() kvserver.InitEngines() state := &lt;- s.joinCh s.rpcContext.NodeID.set(state.NodeID) runAsyncTask("connect-gossip") // only log s.gossip.Start() g.setAddresses(addresses) g.server.start() g.bootstrap() g.manage() s.node.start() // In `pkg/server/node.go` s.replicationReporter.start() s.sqlServer.preStart() There are some comments in PreStart: // "bootstrapping problem": nodes need to connect to Gossip fairly // early, but what drives Gossip connectivity are the first range // replicas in the kv store. This in turn suggests opening the Gossip // server early. However, naively doing so also serves most other // services prematurely, which exposes a large surface of potentially // underinitialized services. This is avoided with some additional // complexity that can be summarized as follows: // // - before blocking trying to connect to the Gossip network, we already open // the admin UI (so that its diagnostics are available) // - we also allow our Gossip and our connection health Ping service // - everything else returns Unavailable errors (which are retryable) // - once the node has started, unlock all RPCs. In Node::start: n.storeCfg.Gossip.NodeID.set(n.nodeDescriptor.NodeID) n.storeCfg.Gossip.SetNodeDescriptor.set(n.nodeDescriptor) for _, e := state.initializedEngines { s := kvserver.NewStore(e) // In `pkg/kv/kvserver/store.go` s.Start() // Iterate over all range descriptor, ignoring uncommitted version. IterateRangeDescriptorFromDisk() replica = newReplica() // In `pkg/kv/kvserver/replica_init.go` newUnloadReplica() loadRaftMuLockedReplicaMuLocked() lastIndex = r.stateLoader.LoadLastIndex() s.addReplicaInternal(replica) s.cfg.Transport.Listen(s.StoreID(), s) s.processRaft() s.storeRebalancer.Start() // rebalance is finished in store? s.startGossip() s.startLeaseRenewer() n.addStore(s) } n.storeCfg.Gossip.SetStorage(n.stores) n.startGossiping(n.stopper) // loops on a periodic ticker to gossip node-related information. s.GossipStore() // GossipStore broadcasts the store on the gossip network. In Server::AcceptClients: s.sqlServer.startServerSQL() Start Store In pkg/kv/kvserver/store.go: Store::Start ReadStoreIdent idalloc.NewAllocator intentResolver.New makeRaftLogTruncator txnrecovery.NewManager // Iterate over all range descriptor, ignoring uncommitted version. IterateRangeDescriptorFromDisk() replica = newReplica() // In `pkg/kv/kvserver/replica_init.go` newUnloadReplica() loadRaftMuLockedReplicaMuLocked() lastIndex = r.stateLoader.LoadLastIndex() s.addReplicaInternal(replica) s.cfg.Transport.Listen(s.StoreID(), s) s.cfg.NodeLiveness.RegisterCallback(s.nodeIsLiveCallback) s.processRaft() s.storeRebalancer.Start() // rebalance is finished in store? s.startGossip() s.startLeaseRenewer() s.startRangefeedUpdator() NewStoreRebalancer() ID Allocator In pkg/kv/kvserver/store.go: // Create ID allocators. idAlloc, err := idalloc.NewAllocator(idalloc.Options{ AmbientCtx: s.cfg.AmbientCtx, Key: keys.RangeIDGenerator, Incrementer: idalloc.DBIncrementer(s.db), BlockSize: rangeIDAllocCount, Stopper: s.stopper, } The Allocator will allocate rangeIDAllocCount count from DB with key keys.RangeIDGenerator. Bootstrap In pkg/cli/init.go: func runInit() { c, err := NewInitClient() c.Bootstrap(BootstrapRequest {}) } In pkg/server/init.go: func (s *initServer) Bootstrap() { state, err = s.tryBootstrap() } func (s *initServer) tryBootstrap() { return bootstrapCluster() } In pkg/server/node.go, function bootstrapCluster: kvserver.InitEngine(engine, storeIdent) kvserver.WriteInitialClusterData() // writes initialization data to an engine. It creates system ranges (filling in meta1 and meta2) and the default zone config. Question: When the first range was creatiation? In pkg/kv/kvserver/store_init.go: desc := &amp;roachpb.RangeDescriptor{ RangeID: rangeID, StartKey: startKey, EndKey: endKey, NextReplicaID: 2, } const firstReplicaID = 1 replicas := []roachpb.ReplicaDescriptor{ { NodeID: FirstNodeID, StoreID: FirstStoreID, ReplicaID: firstReplicaID, }, } desc.SetReplicas(roachpb.MakeReplicaSet(replicas)) How to determine whether a cluster has been bootstrapped when restarting? In Server::PreStart, inspectEngineState := InspectEngines() In InitServer::ServeAndWait, s.inspectEngineState.bootstrapt() When to start serving ranges? See Node::start for details. What happen if no any join list was specified? Report errors Join Node In pkg/server/node.go, function Join(): compareBinaryVersion() nodeID, err := allocateNodeID() val, err := kv.IncrementValRetryable(ctx, db, keys.NodeIDGenerator, 1) db.Inc(ctx, key, inc) // pkg/kv/db.go var db *DB storeID, err := allocateStoreIDs() val, err := kv.IncrementValRetryable(ctx, db, keys.StoreIDGenerator, count) // create liveness record, so what is the purpose of liveness record? n.storeCfg.NodeLiveness.CreateLivenessRecord() Questions: What happen if receives Join requests? Only check version and allocate NodeID. If a node has already bootstrapted, it won’t allocate new node id again (See PreStart() for details). What should to do for adding new table? TODO Where is the master role for cockroachdb? TODO Add Replica on Store In pkg/kv/kvserver/store_create_replica.go, function getOrCreateReplica: getOrCreateReplica -&gt; tryGetOrCreateReplica // 1. current replica is removed, go back around // 2. drop messages from replica we known to be too old // 3. the current replica need to be removed, remove it and go back around // 4. drop staled msg silently // 5. check tombstone newUnloadedReplica Store::addReplicaToRangeMapLocked StateLoader::SetRangeReplicaID Replica::loadRaftMuLockedReplicaMuLocked Questions: When the new replica are created? See above. Raft Initialize Node::start Store::processRaft raftScheduler::Start async raftScheduler::worker async raftScheduler::Wait async raftTickLoop async coalescedHeartbeatsLoop run worker, in pkg/kv/kvserver/store_raft.go and pkg/kv/kvserver/replica_raft.go. raftScheduler::worker raftScheduler::processTick Replica::tick(IsLiveMap) // `pkg/kv/kvserver/replica_raft.go` RawNode::ReportUnreachable(Replica.unreachablesMu.remotes) Replica::maybeQuiesceRaftMuLockedReplicaMuLocked Replica::maybeTransferRaftLeadershipToLeaseholderLocked RawNode::Tick raftScheduler::processReady // See below apply parts. raftScheduler::processRequestQueue Store::withReplicaForRequest Store::getOrCreateReplica Store::processRaftRequestWithReplica Replica::stepRaftGroup Replica::withRaftGroup // if internal raft group is null, try create it RawNode::Step propose Node::Batch -&gt; Node::batchInternal Stores::Send(BatchRequest) -&gt; Stores::GetStore -&gt; Store::Send // `pkg/kv/kvserver/store_send.go` Clock::Update // Advances the local node's clock to a high water mark from all nodes with which it has interacted. Store::GetReplica -&gt; Replica::Send -&gt; Replica::sendWithoutRangeID // `pkg/kv/kvserver/replica_send.go` Replica::maybeInitializeRaftGroup // If the internal Raft group is not initialized, create it and wake the leader. Replica::withRaftGroupLocked Replica::maybeCampaignOnWakeLocked -&gt; Replica::campaignLocked Store::enqueueRaftUpdateCheck -&gt; raftScheduler::EnqueueRaftReady Replica::executeBatchWithConcurrencyRetries Replica::executeReadOnlyBatch Replica::executeReadWriteBatch // `pkg/kv/kvserver/replica_write.go` Replica::applyTimestampCache Replica::evalAndPropose // `pkg/kv/kvserver/replica_raft.go` Replica::requestToProposal // `pkg/kv/kvserver/replica_proposal.go` Replica::evaluateProposal -&gt; Replica::evaluateWriteBatch Replica::evaluate1PC Replica::evaluateWriteBatchWithServersideRefreshes -&gt; Replica::evaluateWriteBatchWrapper -&gt; evaluateBatch // `pkg/kv/kvserver/replica_evaluate.go` optimizePuts evaluateCommand batcheval.LookupCommand Command::EvalRO Command::EvalRW Put // `pkg/kv/kvserver/batcheval/cmd_put.go` storage.MVCCPut storage.MVCCConditionalPut // `pkg/storage/mvcc.go` Replica::propose -&gt; propBuf::Insert Replica::executeAdminBatch // No interaction with the spanlatch manager or the timestamp cache. Replica::maybeAddRangeInfoToResponse // if ranges are mismatched, try to suggest a more suitable range from this store. apply Store::processReady -&gt; Replica::HandleRaftReady -&gt; Replica::HandleRaftReadyRaftMuLocked -&gt; Replica::withRaftGroupLocked propBuf::FlushLockedWithRaftGroup // Question: will `propBuf::Insert` signal ready queue? RawNode::Ready Replica::applySnapshot Task::AckCommittedEntriesBeforeApplication // `pkg/kv/kvserver/apply/task.go` Replica::sendRaftMessagesRaftMuLocked // `pkg/kv/kvserver/replica_raft.go` Replica::append // `pkg/kv/kvserver/replica_raftstorage.go` storage.Writer::MVCCPut // Writer is `Store::Engine().NewUnindexedBatch` Batch::Commit Replica::sendRaftMessagesRaftMuLocked // `pkg/kv/kvserver/replica_raft.go` Task::ApplyCommittedEntries -&gt; Task::ApplyOneBatch Batch::Stage(Command) -&gt; replicaAppBatch::Stage // `pkg/kv/kvserver/replica_application_state_machine.go` Replica::ShouldApplyCommand Batch::ApplyToStateMachine // StateMachine::NewBatch AppliedCommand::AckOutcomeAndFinish Replica::withRaftGroupLocked RawNode::Advance(Ready) Replica::campaignLocked // if shouldCampaignAfterConfChange: if raft leader got moved, campaign the first remaning voter. Store::enqueueRaftUpdateCheck // if RawNode::HasReady transport API defines in pkg/kv/kvserver/storage_services.proto: service MultiRaft { rpc RaftMessageBatch (stream cockroach.kv.kvserver.kvserverpb.RaftMessageRequestBatch) returns (stream cockroach.kv.kvserver.kvserverpb.RaftMessageResponse) {} rpc RaftSnapshot (stream cockroach.kv.kvserver.kvserverpb.SnapshotRequest) returns (stream cockroach.kv.kvserver.kvserverpb.SnapshotResponse) {} rpc DelegateRaftSnapshot(stream cockroach.kv.kvserver.kvserverpb.DelegateSnapshotRequest) returns (stream cockroach.kv.kvserver.kvserverpb.DelegateSnapshotResponse) {} } The implementation lie in pkg/kv/kvserver/raft_transport.go, function is RaftTransport::RaftMessageBatch: RaftMessageBatch stream.Recv RaftTransport::handleRaftRequest RaftTransport::getHandler(StoreID) // read handler of corresponding store ID Store::HandleRaftRequest // `pkg/kv/kvserver/store_raft.go`: dispatches a raft message to the appropriate Replica. Store::HandleRaftUncoalescedRequest raftReceiveQueues::LoadOrCreate(RangeID) raftReceiveQueue::Append raftScheduler::EnqueueRaftRequest stream.Send(newRaftMessageResponse) Questions: Where the conditional_put is executed? In file pkg/kv/kvserver/batcheval/cmd_conditional_put.go, it is invoked by executeCommand. What is the purpose of CommandID? The command ID is equals makeIDKey() -&gt; rand.Int64(). // CmdIDKey is a Raft command id. This will be logged unredacted - keep it random. Rebalance In pkg/kv/kvserver/store.go, function Store::Start: NewStoreRebalancer StoreRebalancer::Start // rebalanceStore iterates through the top K hottest ranges on this store and // for each such range, performs a lease transfer if it determines that that // will improve QPS balance across the stores in the cluster. After it runs out // of leases to transfer away (i.e. because it couldn't find better // replacements), it considers these ranges for replica rebalancing. async StoreRebalancer::rebalanceStore StoreRebalancer::chooseLeaseToTransfer replicateQueue::transferLease StoreRebalancer::chooseRangeToRebalance DB::AdminRelocateRange DB DB is a database handle to a single cockroach cluster. A DB is safe for concurrent use by multiple goroutines. kv.DB interfaces: Get GetForUpdate GetProto GetProtoTs Put PutInline CPut Inc Scan AdminSplit AdminMerge AdminRelocateRange AdminChangeReplicas etc … Put code path: DB::Put -&gt; DB::Run(Batch) -&gt; DB::SendAndFail -&gt; DB::send -&gt; DB::sendUsingSender CrossRangeTxnWrapperSender::Send -&gt; DistSender::Send DistSender::initAndVerifyBatch keys.Range DistSender::divideAndSendParallelCommit DistSender::divideAndSendBatchToRanges DistSender::divideAndSendBatchToRanges RangeIterator::Seek DistSender::sendPartialBatch DistSender::sendToReplicas DistSender::transportFactory Transport::SendNext Error Retry TODO Range Cache TODO Txn TODO]]></summary></entry><entry><title type="html">Shrinking Logs by Safely Discarding Commands</title><link href="/2022/03/31/Shrinking-Logs-by-Safely-Discarding-Commands.html" rel="alternate" type="text/html" title="Shrinking Logs by Safely Discarding Commands" /><published>2022-03-31T00:00:00+08:00</published><updated>2022-03-31T00:00:00+08:00</updated><id>/2022/03/31/Shrinking-Logs-by-Safely-Discarding-Commands</id><content type="html" xml:base="/2022/03/31/Shrinking-Logs-by-Safely-Discarding-Commands.html"><![CDATA[<h2 id="log-based-protocols">Log based protocols</h2>

<p><img src="/uploads/images/2022/shrinking-log-by-discarding-records-1.png" alt="Figure 1: log based protocols" /></p>

<p>Log 主要用于保证日志持久化、按照固定顺序复制以获得 consistent state。一个标准的 log-based protocol 需要按照一定顺序将 record 追加到 log 中，完成持久化后才响应 client。恢复时，从快照中拿到一个 index，从这个点开始回放日志，最终保证状态与恢复前一致。</p>

<h2 id="主要设计">主要设计</h2>

<p><img src="/uploads/images/2022/shrinking-log-by-discarding-records-2.png" alt="Figure 2: stable" /></p>

<p>记录到日志中的 record 之间可能存在 overwrite，比如两个相邻的 write 操作，都更新了某个 key，那么实际上只有后一个操作需要持久化。着这个思路下，每次获取一批需要持久化的 records，将他们的更新先记录到一个 hash table 上。如果存在 overwrite 的情况，只记录下最后一个 key-value。</p>

<p>通过这种方式，能够减小写入到持久化设备的 record 大小，从而增加了吞吐。</p>

<p>这篇论文实际参考价值不大，里面涉及到的设计思路实际上在工业环境中效果不大。比如在支持 MVCC 的 key value 数据库中，更新之间基本上不存在 overwrite。一些可以 merge 的操作，也大都在写 log 前完成。不过论文的 Introduction 和 Releated Work 倒是可以当作综述阅读。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Log based protocols Log 主要用于保证日志持久化、按照固定顺序复制以获得 consistent state。一个标准的 log-based protocol 需要按照一定顺序将 record 追加到 log 中，完成持久化后才响应 client。恢复时，从快照中拿到一个 index，从这个点开始回放日志，最终保证状态与恢复前一致。 主要设计 记录到日志中的 record 之间可能存在 overwrite，比如两个相邻的 write 操作，都更新了某个 key，那么实际上只有后一个操作需要持久化。着这个思路下，每次获取一批需要持久化的 records，将他们的更新先记录到一个 hash table 上。如果存在 overwrite 的情况，只记录下最后一个 key-value。 通过这种方式，能够减小写入到持久化设备的 record 大小，从而增加了吞吐。 这篇论文实际参考价值不大，里面涉及到的设计思路实际上在工业环境中效果不大。比如在支持 MVCC 的 key value 数据库中，更新之间基本上不存在 overwrite。一些可以 merge 的操作，也大都在写 log 前完成。不过论文的 Introduction 和 Releated Work 倒是可以当作综述阅读。]]></summary></entry><entry><title type="html">Achieving High Throughput and Elasticity in a Large-than-Memory Store</title><link href="/papers/2022/03/30/Achieving-High-Throughput-and-Elasticity-in-a-Large-than-Memory-Store.html" rel="alternate" type="text/html" title="Achieving High Throughput and Elasticity in a Large-than-Memory Store" /><published>2022-03-30T00:00:00+08:00</published><updated>2022-03-30T00:00:00+08:00</updated><id>/papers/2022/03/30/Achieving-High-Throughput-and-Elasticity-in-a-Large-than-Memory-Store</id><content type="html" xml:base="/papers/2022/03/30/Achieving-High-Throughput-and-Elasticity-in-a-Large-than-Memory-Store.html"><![CDATA[<h2 id="背景">背景</h2>

<p>如果数据都来自同一台机器，那么可以用导入、索引数据达到 100Mops/s 的单机 multi-core key-value stores 处理。而实际上现在有数十亿的数据需要处理，所以数据必须经过网络传输，并通过云的弹性能力创建足够的实例进行服务。为了满足这个需求，Shadowfax 在 FASTER 的基础上，构建了一个具有快速数据迁移能力的高性能分布式 key-value store。</p>

<h2 id="基本设计">基本设计</h2>

<p><img src="/uploads/images/2022/shadowfox-1.png" alt="Figure 1: shadowfox design" /></p>

<h3 id="per-core-per-thread-but-shared-everthing">Per core per thread but Shared Everthing</h3>

<p>Shadowfox 的设计目标是能够充分利用 CPU 资源，提高系统吞吐。减少核间通信、竞争是提高 CPU 资源的关键。</p>

<p>一种可行的方式是 shared nothing，每个 thread 有一个单独的 FASTER 实例，实例间互不影响。这需要路由请求到与之对应的 FASTER 线程上去，仍然不能避免跨线程协调。一个改进的方式是每个 client 和每个 server thread 都建立连接，将路由的工作交给 client 完成。但是这也要求 client 做跨线程协调，同时让连接数量暴涨。</p>

<p>Shadowfox 采用的则是 shared everthing 的方式，每个线程共享一个 FASTER 实例。FASTER 提供了一种延迟通信的机制，使得它在多核下仍能取得非常高的并发。每个 client 和一个指定的 server thread 建立 session，这个 thread 负责处理该 client 的所有请求。</p>

<p>另外一个需要考虑的是网络部分。网络收发包需要消耗大量的 CPU 资源。Shadowfox 通过将网络请求 offload 到智能卡处理，节省出来的 CPU 资源用于提升吞吐。</p>

<p>这样设计的好处是：</p>

<ul>
  <li>避免竞争。同一个 client 的请求（来自相同 session）由同一个 thread 处理，不需要跨线程协调。</li>
  <li>充分 batch，提高 pipeline。同一个 session 的请求可以充分 batch，以减少 per-packet 的开销。</li>
  <li>client 异步提交请求，避免 head-of-line blocking。因为 Shadowfox 随时会发生 reconfiguration，而 session 中的请求是有序的，发生 reconfiguration 时 client 能够知道哪些 request 一定失败。</li>
</ul>

<h3 id="hash-partition-and-view-number">Hash partition and View number</h3>

<p>Shadowfox 将数据通过 hash range 划分的方式分布到不同的 server 中。每个 server 负责服务一个 hash range。为了识别出 reconfiguration，每个 server 为当前的 hash range 计数（view number），每次 reconfiguration 发生时递增。</p>

<p>view number 需要和 reconfiguration 一起持久化到 meta server 中。</p>

<p>view number 的好处：</p>
<ul>
  <li>检查请求范围时只需要比较 view number 即可，不需要依次对比请求。</li>
  <li>允许进行异步、延迟执行的 record ownership change。</li>
</ul>

<p>第二项时通过 asynchronous global cut 实现的。所谓 asynchronous global cut，其实只是通过 epoch based protection 异步地更新 view number，并将这个变化通过 session 异步地传播给 client。这个方式非常简单，无需多说，但是要取得论文中提到的保证同一时间没有任何两个 server 服务相同区间，还需要 migration 机制参与。</p>

<blockquote>
  <p>This cut unambiguously ensures no two servers concurrently serve operations on an overlapping hash range. This approach is free of synchronous coordination, helping maintain high throughput.</p>
</blockquote>

<h3 id="migration">Migration</h3>

<p>Migration 机制可以看作两阶段提交，首先 source 发送 PrepForTransfer RPC 给 target，通知 target block 所有更大 view number 的请求。等这阶段完成后，source 就提升自己的 view number，并等待所有线程同步变更（一旦线程知道 view number 提升了，就会拒绝 staled request，交由 client 重试）。所有线程的 view number 一致后，就进入下一阶段，source 发送 TransferedOwnership RPC 给 target，这个时候 target 就开始服务请求了。</p>

<p>Shadowfox 的 migration 可以分为两个阶段，正如上文所述，需要先通过提升 view number 完成 record ownership transfer，此后再异步地传输数据给 target。</p>

<p>异步传输期间，尽管 target 已经拿到 ownership，在 source 同步这部分 record 给 target 前，它都不能服务这部分数据。</p>

<blockquote>
  <p>这中间显然有一个 gap，怎么看都不是异步的。。。</p>
</blockquote>

<p>当然，Shadowfox 为了减小这个 gap，会在开始 migration 前，对请求做一个 sampling，并将涉及到的 hot records 附带在 TransferedOwnership RPC 中一并发送给 target。这样 target 就能尽快的为 hot records 提供服务。</p>

<p>等到所有 record 都同步完成，migration 就算结束。整个过程可以组成一个状态机，如下图：</p>

<p><img src="/uploads/images/2022/shadowfox-2.png" alt="Figure 2: Migration states" /></p>

<p>一部分 record 可能没有在内存中，在 SSD 里，Shadowfox 可以将这部分 record 写到共享存储上，这样 target 就可以直接读取这部分 record 而不是等 source 复制给它。</p>

<h4 id="fault-tolerance">Fault tolerance</h4>

<p>为了保证容错，source 和 target 在标记 complete 前，需要创建一份 checkpoint，如果之后任何一台机器故障，都可以通过 checkpoint 恢复数据。如果时在迁移过程中发生了故障，则 shadowfox 会取消迁移操作，并将迁移涉及到的 hash range 迁移回 source。</p>

<p>如果某个机器不可用，shadowfox 需要从这条机器撤销其 record 的所有权，这是通过 lease 完成的。</p>

<h2 id="评估">评估</h2>

<p><img src="/uploads/images/2022/shadowfox-3.png" alt="Figure 3: throughput during migrate" /></p>

<p>看起来 migrate 和 scale up 仍然对 throughput 有较大影响。</p>

<p><img src="/uploads/images/2022/shadowfox-4.png" alt="Figure 4: Number of pending operations during scale up" /></p>

<p>同时看起来在迁移过程中，被 block 的请求数量也不少。</p>]]></content><author><name></name></author><category term="papers" /><category term="live-migration," /><category term="shared-everything," /><category term="epoch-based-protection" /><summary type="html"><![CDATA[背景 如果数据都来自同一台机器，那么可以用导入、索引数据达到 100Mops/s 的单机 multi-core key-value stores 处理。而实际上现在有数十亿的数据需要处理，所以数据必须经过网络传输，并通过云的弹性能力创建足够的实例进行服务。为了满足这个需求，Shadowfax 在 FASTER 的基础上，构建了一个具有快速数据迁移能力的高性能分布式 key-value store。 基本设计 Per core per thread but Shared Everthing Shadowfox 的设计目标是能够充分利用 CPU 资源，提高系统吞吐。减少核间通信、竞争是提高 CPU 资源的关键。 一种可行的方式是 shared nothing，每个 thread 有一个单独的 FASTER 实例，实例间互不影响。这需要路由请求到与之对应的 FASTER 线程上去，仍然不能避免跨线程协调。一个改进的方式是每个 client 和每个 server thread 都建立连接，将路由的工作交给 client 完成。但是这也要求 client 做跨线程协调，同时让连接数量暴涨。 Shadowfox 采用的则是 shared everthing 的方式，每个线程共享一个 FASTER 实例。FASTER 提供了一种延迟通信的机制，使得它在多核下仍能取得非常高的并发。每个 client 和一个指定的 server thread 建立 session，这个 thread 负责处理该 client 的所有请求。 另外一个需要考虑的是网络部分。网络收发包需要消耗大量的 CPU 资源。Shadowfox 通过将网络请求 offload 到智能卡处理，节省出来的 CPU 资源用于提升吞吐。 这样设计的好处是： 避免竞争。同一个 client 的请求（来自相同 session）由同一个 thread 处理，不需要跨线程协调。 充分 batch，提高 pipeline。同一个 session 的请求可以充分 batch，以减少 per-packet 的开销。 client 异步提交请求，避免 head-of-line blocking。因为 Shadowfox 随时会发生 reconfiguration，而 session 中的请求是有序的，发生 reconfiguration 时 client 能够知道哪些 request 一定失败。 Hash partition and View number Shadowfox 将数据通过 hash range 划分的方式分布到不同的 server 中。每个 server 负责服务一个 hash range。为了识别出 reconfiguration，每个 server 为当前的 hash range 计数（view number），每次 reconfiguration 发生时递增。 view number 需要和 reconfiguration 一起持久化到 meta server 中。 view number 的好处： 检查请求范围时只需要比较 view number 即可，不需要依次对比请求。 允许进行异步、延迟执行的 record ownership change。 第二项时通过 asynchronous global cut 实现的。所谓 asynchronous global cut，其实只是通过 epoch based protection 异步地更新 view number，并将这个变化通过 session 异步地传播给 client。这个方式非常简单，无需多说，但是要取得论文中提到的保证同一时间没有任何两个 server 服务相同区间，还需要 migration 机制参与。 This cut unambiguously ensures no two servers concurrently serve operations on an overlapping hash range. This approach is free of synchronous coordination, helping maintain high throughput. Migration Migration 机制可以看作两阶段提交，首先 source 发送 PrepForTransfer RPC 给 target，通知 target block 所有更大 view number 的请求。等这阶段完成后，source 就提升自己的 view number，并等待所有线程同步变更（一旦线程知道 view number 提升了，就会拒绝 staled request，交由 client 重试）。所有线程的 view number 一致后，就进入下一阶段，source 发送 TransferedOwnership RPC 给 target，这个时候 target 就开始服务请求了。 Shadowfox 的 migration 可以分为两个阶段，正如上文所述，需要先通过提升 view number 完成 record ownership transfer，此后再异步地传输数据给 target。 异步传输期间，尽管 target 已经拿到 ownership，在 source 同步这部分 record 给 target 前，它都不能服务这部分数据。 这中间显然有一个 gap，怎么看都不是异步的。。。 当然，Shadowfox 为了减小这个 gap，会在开始 migration 前，对请求做一个 sampling，并将涉及到的 hot records 附带在 TransferedOwnership RPC 中一并发送给 target。这样 target 就能尽快的为 hot records 提供服务。 等到所有 record 都同步完成，migration 就算结束。整个过程可以组成一个状态机，如下图： 一部分 record 可能没有在内存中，在 SSD 里，Shadowfox 可以将这部分 record 写到共享存储上，这样 target 就可以直接读取这部分 record 而不是等 source 复制给它。 Fault tolerance 为了保证容错，source 和 target 在标记 complete 前，需要创建一份 checkpoint，如果之后任何一台机器故障，都可以通过 checkpoint 恢复数据。如果时在迁移过程中发生了故障，则 shadowfox 会取消迁移操作，并将迁移涉及到的 hash range 迁移回 source。 如果某个机器不可用，shadowfox 需要从这条机器撤销其 record 的所有权，这是通过 lease 完成的。 评估 看起来 migrate 和 scale up 仍然对 throughput 有较大影响。 同时看起来在迁移过程中，被 block 的请求数量也不少。]]></summary></entry><entry><title type="html">OpLog - a library for scaling update heavy data structures</title><link href="/2022/03/30/OpLog-a-library-for-scaling-update-heavy-data-structures.html" rel="alternate" type="text/html" title="OpLog - a library for scaling update heavy data structures" /><published>2022-03-30T00:00:00+08:00</published><updated>2022-03-30T00:00:00+08:00</updated><id>/2022/03/30/OpLog-a-library-for-scaling-update-heavy-data-structures</id><content type="html" xml:base="/2022/03/30/OpLog-a-library-for-scaling-update-heavy-data-structures.html"><![CDATA[<h2 id="背景">背景</h2>

<p>在 multi-core scaling read-heavy data structure 上已经有了很多有用的技术，比如 Read-copy-update。但是 update-heavy 的数据结构还鲜有通用的方案。显然，对于 update-heavy 的数据结构来说，只要在读之前，将数据准备好就行。OpLog 针对这部分场景，提出了一种通用的 scaling update-heavy data structures 实现方式。</p>

<h2 id="思路">思路</h2>

<p>OpLog 的解决办法是为每个数据结构准备一个 per-core 的日志，写操作只需要将其追加到日志中即可。在读时，按照时间顺序合并日志并应用到数据结构上。这样的设计方式有几个好处：</p>

<ul>
  <li>Batching updates：通过延迟执行，很多 update 操作可以直接合并，计数操作，原来的 N 次 +1 操作可以合并为一次 +N</li>
  <li>Absorbing updates: 比如先执行 put，之后 delete，那么无需执行任何操作</li>
</ul>

<p>OpLog 作为一种通用的设计思路，还需要考虑到尽管某个实现需要解决 update-heavy 的问题，但是只有少数 update-heavy 的实例才会通过 OpLog 收益，多数情况下 per-core 的日志对这部分实例是一个负担。OpLog 只对最近使用过的对象设置 log，如果一个对象长期未更新，那么 OpLog 可以回收这部分空间。</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">Counter</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Object</span><span class="o">&lt;</span><span class="n">CounterLog</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="nc">IncOp</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Op</span> <span class="p">{</span>
        <span class="kt">void</span> <span class="n">exec</span><span class="p">(</span><span class="kt">uint64_t</span><span class="o">*</span> <span class="n">v</span><span class="p">)</span> <span class="p">{</span> <span class="o">*</span><span class="n">v</span> <span class="o">=</span> <span class="o">*</span><span class="n">v</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span> <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">struct</span> <span class="nc">DecOp</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Op</span> <span class="p">{</span>
        <span class="kt">void</span> <span class="n">exec</span><span class="p">(</span><span class="kt">uint64_t</span><span class="o">*</span> <span class="n">v</span><span class="p">)</span> <span class="p">{</span> <span class="o">*</span><span class="n">v</span> <span class="o">=</span> <span class="o">*</span><span class="n">v</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="p">}</span>
    <span class="p">}</span>

    <span class="kt">void</span> <span class="n">inc</span><span class="p">()</span> <span class="p">{</span> <span class="n">log</span><span class="p">(</span><span class="n">IncOp</span><span class="p">());</span> <span class="p">}</span>
    <span class="kt">void</span> <span class="n">dec</span><span class="p">()</span> <span class="p">{</span> <span class="n">log</span><span class="p">(</span><span class="n">DecOp</span><span class="p">());</span> <span class="p">}</span>

    <span class="kt">uint64_t</span> <span class="n">read</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">synchronize</span><span class="p">();</span>
        <span class="kt">uint64_t</span> <span class="n">r</span> <span class="o">=</span> <span class="n">val_</span><span class="p">;</span>
        <span class="n">unlock</span><span class="p">();</span>
        <span class="k">return</span> <span class="n">r</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kt">uint64_t</span> <span class="n">val_</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="nc">CounterLog</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Log</span> <span class="p">{</span>
    <span class="kt">void</span> <span class="n">push</span><span class="p">(</span><span class="n">Op</span><span class="o">*</span> <span class="n">op</span><span class="p">)</span> <span class="p">{</span> <span class="n">op</span><span class="o">-&gt;</span><span class="n">exec</span><span class="p">(</span><span class="o">&amp;</span><span class="n">val_</span><span class="p">);</span> <span class="p">}</span>

    <span class="k">static</span> <span class="kt">void</span> <span class="n">apply</span><span class="p">(</span><span class="n">CounterLog</span><span class="o">*</span> <span class="n">qs</span><span class="p">[],</span> <span class="n">Counter</span><span class="o">*</span> <span class="n">c</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">for_each_log</span><span class="p">(</span><span class="n">CounterLog</span><span class="o">*</span> <span class="n">q</span><span class="p">,</span> <span class="n">qs</span><span class="p">)</span>
            <span class="n">c</span><span class="o">-&gt;</span><span class="n">val_</span> <span class="o">+=</span> <span class="n">q</span><span class="o">-&gt;</span><span class="n">val_</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kt">uint64_t</span> <span class="n">val_</span><span class="p">;</span>
<span class="p">};</span>
</code></pre></div></div>

<p>论文中有使用 OpLog 实现 Counter 的例子。<code class="language-plaintext highlighter-rouge">inc</code> 和 <code class="language-plaintext highlighter-rouge">dec</code> 操作生成一个 OP 并记录到 log 中，读操作需要先加锁，合并 log 并应用到 counter 上，再返回 <code class="language-plaintext highlighter-rouge">val_</code>。</p>

<h2 id="评估">评估</h2>

<p>一般会认为 OpLog 的实现对 read 不友好。不过论文也做了一个 benchmark。</p>

<p><img src="/uploads/images/2022/OpLog-update-heavy-data-structures.png" alt="Figure 1 fork-turncate" /></p>

<p>结果显示，OpLog 对一些 read periodically 的数据结构也有性能改善。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[背景 在 multi-core scaling read-heavy data structure 上已经有了很多有用的技术，比如 Read-copy-update。但是 update-heavy 的数据结构还鲜有通用的方案。显然，对于 update-heavy 的数据结构来说，只要在读之前，将数据准备好就行。OpLog 针对这部分场景，提出了一种通用的 scaling update-heavy data structures 实现方式。 思路 OpLog 的解决办法是为每个数据结构准备一个 per-core 的日志，写操作只需要将其追加到日志中即可。在读时，按照时间顺序合并日志并应用到数据结构上。这样的设计方式有几个好处： Batching updates：通过延迟执行，很多 update 操作可以直接合并，计数操作，原来的 N 次 +1 操作可以合并为一次 +N Absorbing updates: 比如先执行 put，之后 delete，那么无需执行任何操作 OpLog 作为一种通用的设计思路，还需要考虑到尽管某个实现需要解决 update-heavy 的问题，但是只有少数 update-heavy 的实例才会通过 OpLog 收益，多数情况下 per-core 的日志对这部分实例是一个负担。OpLog 只对最近使用过的对象设置 log，如果一个对象长期未更新，那么 OpLog 可以回收这部分空间。 struct Counter : public Object&lt;CounterLog&gt; { struct IncOp : public Op { void exec(uint64_t* v) { *v = *v + 1; } } struct DecOp : public Op { void exec(uint64_t* v) { *v = *v - 1; } } void inc() { log(IncOp()); } void dec() { log(DecOp()); } uint64_t read() { synchronize(); uint64_t r = val_; unlock(); return r; } uint64_t val_; }; struct CounterLog : public Log { void push(Op* op) { op-&gt;exec(&amp;val_); } static void apply(CounterLog* qs[], Counter* c) { for_each_log(CounterLog* q, qs) c-&gt;val_ += q-&gt;val_; } uint64_t val_; }; 论文中有使用 OpLog 实现 Counter 的例子。inc 和 dec 操作生成一个 OP 并记录到 log 中，读操作需要先加锁，合并 log 并应用到 counter 上，再返回 val_。 评估 一般会认为 OpLog 的实现对 read 不友好。不过论文也做了一个 benchmark。 结果显示，OpLog 对一些 read periodically 的数据结构也有性能改善。]]></summary></entry><entry><title type="html">HotRing - A Hotspot Aware In-Memory Key-Value Store</title><link href="/papers/2022/03/29/HotRing-A-Hotspot-Aware-In-Memory-Key-Value-Store.html" rel="alternate" type="text/html" title="HotRing - A Hotspot Aware In-Memory Key-Value Store" /><published>2022-03-29T00:00:00+08:00</published><updated>2022-03-29T00:00:00+08:00</updated><id>/papers/2022/03/29/HotRing-A-Hotspot-Aware-In-Memory-Key-Value-Store</id><content type="html" xml:base="/papers/2022/03/29/HotRing-A-Hotspot-Aware-In-Memory-Key-Value-Store.html"><![CDATA[<p>在 Alibaba 的生产环境中，KVS 的请求里有 50%-90% 只访问了 1% 的数据。如下图：</p>

<p><img src="/uploads/images/2022/hotring-1.png" alt="Figure 1: Access ratio of different keys." /></p>

<p>实现 KVS 有很多可用的索引结构，其中 HASH 用得最多。目前的 HASH 算法并没有优化热点访问，也就是说读取一条热点数据，所付出的代价和读取其他数据是一样的。如下图，传统 HASH INDEX 结构的热点数据可能分布在 collision chaining 的任意位置。</p>

<p><img src="/uploads/images/2022/hotring-2.png" alt="Figure 2: The conventional hash index structure" /></p>

<p>理想情况下，查找一条数据的内存访问次数应该和它的冷热层度负相关。</p>

<p><img src="/uploads/images/2022/hotring-3.png" alt="Figure 3: Expected memory accesses for an index lookup" /></p>

<p>想要达到理想的情况，需要解决两个问题：</p>
<ol>
  <li>检测并适应 hotspot shift</li>
  <li>concurrent access</li>
</ol>

<h2 id="hotring">HotRing</h2>

<p>论文的做法是：针对问题 1，将传统哈希表中的 collision chain 替换成 ordered-ring。如果热点发生迁移，那么直接将 bucket header 指向新的热点 item 即可。针对问题 2，采用 lock-free 设计。</p>

<p><img src="/uploads/images/2022/hotring-4.png" alt="Figure 4: The index structure of HotRing" /></p>

<p>ordered ring 的结构如上图所示，整个 ring 首尾相连，一旦发现热点迁移，只需要将 bucket 的 header 更新到新热点 item 即可。这样做的好处是热点迁移时无需重新给 ring 上数据排序。</p>

<p>查找时从 header 开始，遍历整个 ring ；同时 Ring 上的数据会按照 <code class="language-plaintext highlighter-rouge">&lt;tag, key&gt;</code> 的顺序插入到合适的位置。这样做的目的是：</p>
<ul>
  <li>tag 主要用来避免对 key 的比较</li>
  <li>顺序则是用于查询时判断 ring 是否结束，否则查找时可能会受到并发更新操作的影响，无法判断是否已经遍历完整个 ring。</li>
</ul>

<p><img src="/uploads/images/2022/hotring-5.png" alt="Figure 5: Lookup Termination" /></p>

<p>此外，排序还有另一个好处，根据 termination 条件，平均查找次数约为传统 collision chain 实现方式的一半。</p>

<h2 id="hotspot-shift-identification">Hotspot Shift Identification</h2>

<p>由于 hash 的 strongly uniformed distribution，可以认为热点数据也分布在各个 bucket 中，热点迁移识别的工作主要在 bucket 内部。</p>

<p>论文提出了两种识别方式：</p>
<ol>
  <li>random movement</li>
  <li>statistical sampling</li>
</ol>

<p>第一种方式是每隔 R 个请求，如果第 R 个请求是 hot access，则不做任何改变；如果第 R 个请求是 cold access ，那么这个请求对应的 item 会成为新的 hot item。</p>

<p>这种方式是一个简单的概率实现，其缺点也非常明显：参数 R 的大小显著影响热点识别效果；如果数据访问频率分布是均匀的，或者 collision ring 中有多个热点，那么 head pointer 可能会频繁在这些热点中跳变；</p>

<p>另一种方式则是在 item 里记录下访问次数，根据次数选择出合适的 item 来作为新的 hot item。</p>

<blockquote>
  <p>猜想：是否可以使用 thread-local 级别的数据采样算法，来得到更为精确的数据，同时也避免了不必要的 CAS 操作？</p>
</blockquote>

<p><img src="/uploads/images/2022/hotring-6.png" alt="Figure 6: Index Format" /></p>

<p>如上图所示，每个 head pointer 的前 16bits 和 item pointer 其中的 14 bits 用于存储采样信息。其中 Active 表示在这条 collision ring 上开启采样，它主要是为了进行优化：为了确保采样不对正常读写造成影响，默认情况下 Active 为 false；每 R 个请求进行一次判断，如果仍然是 hot access，则认为目前的 hot item 仍然是准确的；否则才设置 Active 为 true。一旦 Active 被设置，后续请求需要同时使用 CAS 更新 Total Counter 和 Item 的 Counter。</p>

<p>采样完成后，最后一个访问的线程负责计算 collision ring 上每个 item 的访问频率，并调整 hot item。（先清除 Active 的标记）</p>

<h3 id="write-intensive-hotspot-with-rcu">Write-Intensive Hotspot with RCU</h3>

<p>HotRing 上的 key 是通过 read-copy-update 操作进行的。更改一个 key 时，需要遍历整个 collision ring ，找到待更新的 key 的前项，并更改其指针到新 item 上。所以更新操作的 Counter 应该需要记录到 hot item 的前一项中，这样算法就会选择前一项作为 hot item，因更新操作所需要的访问次数也因此降低。</p>

<p><img src="/uploads/images/2022/hotring-7.png" alt="Figure 7: Update a Hot Item A with RCU makes item F hot" /></p>

<h2 id="concurrent">Concurrent</h2>

<ul>
  <li>read: 读操作从 head pointer 开始遍历 HotRing，直到碰到终止条件</li>
  <li>insert: 找到合适位置，更新前一项的 Next Item Address 即可</li>
</ul>

<p>update 和 deletion 会复杂一些。对于 update，如果 value 在 8 字节内，可以直接通过 CAS 进行 in-place 更新。否则，需要使用两阶段提交的策略来避免异常。</p>

<p><img src="/uploads/images/2022/hotring-8.png" alt="Figure 8: Concurrent issues" /></p>

<p>如果 read-copy-update 和其他更新操作同时执行，就会上图所示的异常。以 RCU Update &amp; Insert 为例，由于 update B 和 insert C 同时进行，C 负责更新 B 的 Next Item Address，而此时 B’ 更新了 A 的 Next Item Address，最终 C 丢失，无法被访问。</p>

<p>解决方式是在 update\delete 某个 item 时，先标记上 Occupied bit，这样其他尝试更新该 Next Item Address 的请求会失败并进行重试，所以后续对这个 Item 进行的操作就是安全的。</p>

<h3 id="head-pointer-movement">Head Pointer Movement</h3>

<p>head pointer 同样也会受到并发操作的影响，主要有两种情况：</p>
<ol>
  <li>热点迁移导致的 head pointer 更新</li>
  <li>其他 update 和 deletion 操作</li>
</ol>

<p>对于 case 1，head pointer 在迁移前，需要设置新 hot item 为 Occupied 保证这个过程中该节点不会被 update 或 delete。</p>

<p>对于 update head pointer 指向的 item，只需要在替换时设置上新 item 的 Occupied 即可；对于 delete head pointer 指向的 item，还需要设置 head pointer 指向的新 item 的 Occupied。</p>

<h2 id="lock-free-rehash">Lock free Rehash</h2>

<p>传统的 Hash Table 使用 load factor 来出发 rehash，这个过程显然没有考虑到 hotspot 的影响。HotRing 使用 access overhead 来出发 rehash。</p>

<p>由于 HotRing 是有序的，rehash 时只需要从中间某个位置断开，生成两个新的 HotRing 即可。这个阶段主要分为三步：</p>

<p><img src="/uploads/images/2022/hotring-9.png" alt="Figure 9: Rehash" /></p>

<h2 id="评估">评估</h2>

<p>略</p>]]></content><author><name></name></author><category term="papers" /><category term="concurrent" /><summary type="html"><![CDATA[在 Alibaba 的生产环境中，KVS 的请求里有 50%-90% 只访问了 1% 的数据。如下图： 实现 KVS 有很多可用的索引结构，其中 HASH 用得最多。目前的 HASH 算法并没有优化热点访问，也就是说读取一条热点数据，所付出的代价和读取其他数据是一样的。如下图，传统 HASH INDEX 结构的热点数据可能分布在 collision chaining 的任意位置。 理想情况下，查找一条数据的内存访问次数应该和它的冷热层度负相关。 想要达到理想的情况，需要解决两个问题： 检测并适应 hotspot shift concurrent access HotRing 论文的做法是：针对问题 1，将传统哈希表中的 collision chain 替换成 ordered-ring。如果热点发生迁移，那么直接将 bucket header 指向新的热点 item 即可。针对问题 2，采用 lock-free 设计。 ordered ring 的结构如上图所示，整个 ring 首尾相连，一旦发现热点迁移，只需要将 bucket 的 header 更新到新热点 item 即可。这样做的好处是热点迁移时无需重新给 ring 上数据排序。 查找时从 header 开始，遍历整个 ring ；同时 Ring 上的数据会按照 &lt;tag, key&gt; 的顺序插入到合适的位置。这样做的目的是： tag 主要用来避免对 key 的比较 顺序则是用于查询时判断 ring 是否结束，否则查找时可能会受到并发更新操作的影响，无法判断是否已经遍历完整个 ring。 此外，排序还有另一个好处，根据 termination 条件，平均查找次数约为传统 collision chain 实现方式的一半。 Hotspot Shift Identification 由于 hash 的 strongly uniformed distribution，可以认为热点数据也分布在各个 bucket 中，热点迁移识别的工作主要在 bucket 内部。 论文提出了两种识别方式： random movement statistical sampling 第一种方式是每隔 R 个请求，如果第 R 个请求是 hot access，则不做任何改变；如果第 R 个请求是 cold access ，那么这个请求对应的 item 会成为新的 hot item。 这种方式是一个简单的概率实现，其缺点也非常明显：参数 R 的大小显著影响热点识别效果；如果数据访问频率分布是均匀的，或者 collision ring 中有多个热点，那么 head pointer 可能会频繁在这些热点中跳变； 另一种方式则是在 item 里记录下访问次数，根据次数选择出合适的 item 来作为新的 hot item。 猜想：是否可以使用 thread-local 级别的数据采样算法，来得到更为精确的数据，同时也避免了不必要的 CAS 操作？ 如上图所示，每个 head pointer 的前 16bits 和 item pointer 其中的 14 bits 用于存储采样信息。其中 Active 表示在这条 collision ring 上开启采样，它主要是为了进行优化：为了确保采样不对正常读写造成影响，默认情况下 Active 为 false；每 R 个请求进行一次判断，如果仍然是 hot access，则认为目前的 hot item 仍然是准确的；否则才设置 Active 为 true。一旦 Active 被设置，后续请求需要同时使用 CAS 更新 Total Counter 和 Item 的 Counter。 采样完成后，最后一个访问的线程负责计算 collision ring 上每个 item 的访问频率，并调整 hot item。（先清除 Active 的标记） Write-Intensive Hotspot with RCU HotRing 上的 key 是通过 read-copy-update 操作进行的。更改一个 key 时，需要遍历整个 collision ring ，找到待更新的 key 的前项，并更改其指针到新 item 上。所以更新操作的 Counter 应该需要记录到 hot item 的前一项中，这样算法就会选择前一项作为 hot item，因更新操作所需要的访问次数也因此降低。 Concurrent read: 读操作从 head pointer 开始遍历 HotRing，直到碰到终止条件 insert: 找到合适位置，更新前一项的 Next Item Address 即可 update 和 deletion 会复杂一些。对于 update，如果 value 在 8 字节内，可以直接通过 CAS 进行 in-place 更新。否则，需要使用两阶段提交的策略来避免异常。 如果 read-copy-update 和其他更新操作同时执行，就会上图所示的异常。以 RCU Update &amp; Insert 为例，由于 update B 和 insert C 同时进行，C 负责更新 B 的 Next Item Address，而此时 B’ 更新了 A 的 Next Item Address，最终 C 丢失，无法被访问。 解决方式是在 update\delete 某个 item 时，先标记上 Occupied bit，这样其他尝试更新该 Next Item Address 的请求会失败并进行重试，所以后续对这个 Item 进行的操作就是安全的。 Head Pointer Movement head pointer 同样也会受到并发操作的影响，主要有两种情况： 热点迁移导致的 head pointer 更新 其他 update 和 deletion 操作 对于 case 1，head pointer 在迁移前，需要设置新 hot item 为 Occupied 保证这个过程中该节点不会被 update 或 delete。 对于 update head pointer 指向的 item，只需要在替换时设置上新 item 的 Occupied 即可；对于 delete head pointer 指向的 item，还需要设置 head pointer 指向的新 item 的 Occupied。 Lock free Rehash 传统的 Hash Table 使用 load factor 来出发 rehash，这个过程显然没有考虑到 hotspot 的影响。HotRing 使用 access overhead 来出发 rehash。 由于 HotRing 是有序的，rehash 时只需要从中间某个位置断开，生成两个新的 HotRing 即可。这个阶段主要分为三步： 评估 略]]></summary></entry><entry><title type="html">探究 Linux 下 TCP 的 RST Packet</title><link href="/network/2019/01/26/Linux-TCP-Rst.html" rel="alternate" type="text/html" title="探究 Linux 下 TCP 的 RST Packet" /><published>2019-01-26T15:13:00+08:00</published><updated>2019-01-26T15:13:00+08:00</updated><id>/network/2019/01/26/Linux-TCP-Rst</id><content type="html" xml:base="/network/2019/01/26/Linux-TCP-Rst.html"><![CDATA[<blockquote>
  <p>注：<strong>本文结论来自网络，真实性未考究，请批判性阅读，如果谬误，请斧正。</strong>本文所讨论内容，均假设工作环境为 Linux 服务器。</p>
</blockquote>

<p>作为 TCP 不可或缺的一部分，TCP 包头的 <code class="language-plaintext highlighter-rouge">RST</code> 为 $1$ 时，表示重置，关闭异常链接。发送 RST 包关闭连接时，不必等缓冲区的包都发出去，直接就丢弃缓存区的包发送 <code class="language-plaintext highlighter-rouge">RST</code> 包。而接收端收到 <code class="language-plaintext highlighter-rouge">RST</code> 包后，也不必发送 <code class="language-plaintext highlighter-rouge">ACK</code> 包来确认。TCP 处理程序会在自己认为的异常时刻发送 <code class="language-plaintext highlighter-rouge">RST</code> 包。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>14:59:23.379829 IP localhost.62412 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>R], <span class="nb">seq </span>4127385762, win 0, length 0
</code></pre></div></div>

<p><em>通过 tcpdump 观察，<code class="language-plaintext highlighter-rouge">Flags [R]</code> 表示该包携带了 <code class="language-plaintext highlighter-rouge">RST</code> 。</em></p>

<p><code class="language-plaintext highlighter-rouge">RST</code> 主要用在三种场景中，保证 TCP 链接的安全性，三种场景分别是：1、到不存在端口的连接请求；2、异常终止连接；3、检测半打开连接。接下来看看 <code class="language-plaintext highlighter-rouge">RST</code> 的具体表现。</p>

<h1 id="三种错误">三种错误</h1>

<p>内核中的 TCP 协议栈将收到 <code class="language-plaintext highlighter-rouge">RST</code> 的场景分为三种，并抛出了对应的错误。</p>

<h2 id="connection-refused">connection refused</h2>

<p>当内核中的 TCP 协议栈收到了 <code class="language-plaintext highlighter-rouge">SYN</code> 请求，但是该端口上没有处于监听状态，则相应 <code class="language-plaintext highlighter-rouge">RST</code>，此时 client 看到的便是 <code class="language-plaintext highlighter-rouge">connection refused</code>。</p>

<h2 id="broken-pipe">broken pipe</h2>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">fd</code> is connected to a pipe or socket whose reading end is closed.  When this happens the writing process will also receive a SIGPIPE signal.(Thus, the write return value is seen only if the program catches, blocks or ignores this signal.)</p>
</blockquote>

<p>简单的说，如果<strong>已知</strong>远端读通道已经被关闭，而应用程序仍然在调用 <code class="language-plaintext highlighter-rouge">write</code>(2) 尝试向 socket 中写入数据，TCP 协议栈便会抛出 <code class="language-plaintext highlighter-rouge">broken pipe</code>。</p>

<h2 id="connection-reset-by-peer">connection reset by peer</h2>

<blockquote>
  <p>A network connection was closed for reasons outside the control of the local host, such as by the remote machine rebooting or an unrecoverable protocol violation.</p>
</blockquote>

<p>如果远端已经 <code class="language-plaintext highlighter-rouge">close</code>(2) 连接了，本地服务仍发送了数据，此时 TCP 协议栈便会抛出 <code class="language-plaintext highlighter-rouge">connection reset by peer</code>。</p>

<h1 id="broken-pipe-和-connection-reset-by-peer">broken pipe 和 connection reset by peer</h1>

<p>无论是 <code class="language-plaintext highlighter-rouge">broken pipe</code> 还是 <code class="language-plaintext highlighter-rouge">connection reset by peer</code>，都是收到 <code class="language-plaintext highlighter-rouge">RST</code> 的表现，二者有何不同呢？</p>

<p>为了进一步研究，这里尝试着构建两个场景，分别重现 <code class="language-plaintext highlighter-rouge">broken pipe</code> 和 <code class="language-plaintext highlighter-rouge">connection reset by peer</code>。</p>

<h2 id="重现-broken-pipe">重现 broken pipe</h2>

<p>首先，在服务中监听端口，每个连接分多次写入数据，然后关闭连接。</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">server</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">Acceptor</span> <span class="n">acceptor</span> <span class="o">=</span> <span class="n">Socket</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">InetAddress</span> <span class="n">address</span> <span class="o">=</span> <span class="n">InetAddress</span><span class="o">::</span><span class="n">parseV4</span><span class="p">(</span><span class="s">"127.0.0.1"</span><span class="p">,</span> <span class="mi">9490</span><span class="p">);</span>
    <span class="n">acceptor</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">address</span><span class="p">);</span>
    <span class="n">acceptor</span><span class="p">.</span><span class="n">listen</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>

    <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">msg1</span> <span class="o">=</span> <span class="s">"hello"</span><span class="p">,</span> <span class="o">*</span><span class="n">msg2</span> <span class="o">=</span> <span class="s">"world"</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">Connection</span> <span class="n">conn</span> <span class="o">=</span> <span class="n">acceptor</span><span class="p">.</span><span class="n">accept</span><span class="p">();</span>
        <span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>                        <span class="c1">// wait client shutdown</span>
        <span class="n">conn</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">msg1</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">msg1</span><span class="p">));</span>  <span class="c1">// write success, but RST recieved</span>
        <span class="n">conn</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">msg2</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">msg2</span><span class="p">));</span>  <span class="c1">// throw `broken pipe`</span>
    <span class="p">}</span> <span class="c1">// RAII close conn socket</span>
<span class="p">}</span> <span class="c1">// RAII close acceptor socket</span>
</code></pre></div></div>

<p>然后客户端连接到服务端，并立即关闭连接。</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">client</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">Connector</span> <span class="n">connector</span> <span class="o">=</span> <span class="n">Socket</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">InetAddress</span> <span class="n">address</span> <span class="o">=</span> <span class="n">InetAddress</span><span class="o">::</span><span class="n">parseV4</span><span class="p">(</span><span class="s">"127.0.0.1"</span><span class="p">,</span> <span class="mi">9490</span><span class="p">);</span>
    <span class="n">connector</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">address</span><span class="p">);</span>
<span class="p">}</span> <span class="c1">// RAII close connector socket</span>
</code></pre></div></div>

<p>通过 tcpdump 观察程序运行时请求：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> lo <span class="s1">'(src host 127.0.0.1) and (port 9490)'</span>  <span class="nt">-B</span> 4096
14:59:13.376906 IP localhost.62412 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>S], <span class="nb">seq </span>4127385760, win 43690, options <span class="o">[</span>mss 65495,sackOK,TS val 168040030 ecr 0,nop,wscale 10], length 0
14:59:13.376919 IP localhost.9490 <span class="o">&gt;</span> localhost.62412: Flags <span class="o">[</span>S.], <span class="nb">seq </span>2306780414, ack 4127385761, win 43690, options <span class="o">[</span>mss 65495,sackOK,TS val 168040030 ecr 168040030,nop,wscale 10], length 0
14:59:13.376928 IP localhost.62412 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>.], ack 1, win 43, options <span class="o">[</span>nop,nop,TS val 168040030 ecr 168040030], length 0
14:59:13.377089 IP localhost.9490 <span class="o">&gt;</span> localhost.62412: Flags <span class="o">[</span>P.], <span class="nb">seq </span>1:2, ack 1, win 43, options <span class="o">[</span>nop,nop,TS val 168040030 ecr 168040030], length 1
14:59:13.377223 IP localhost.62412 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>.], ack 2, win 43, options <span class="o">[</span>nop,nop,TS val 168040030 ecr 168040030], length 0
14:59:14.377352 IP localhost.9490 <span class="o">&gt;</span> localhost.62412: Flags <span class="o">[</span>P.], <span class="nb">seq </span>2:3, ack 1, win 43, options <span class="o">[</span>nop,nop,TS val 168040280 ecr 168040030], length 1
14:59:14.377439 IP localhost.62412 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>.], ack 3, win 43, options <span class="o">[</span>nop,nop,TS val 168040280 ecr 168040280], length 0
// ....
14:59:22.379462 IP localhost.9490 <span class="o">&gt;</span> localhost.62412: Flags <span class="o">[</span>P.], <span class="nb">seq </span>10:11, ack 1, win 43, options <span class="o">[</span>nop,nop,TS val 168042281 ecr 168042031], length 1
14:59:22.379489 IP localhost.62412 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>.], ack 11, win 43, options <span class="o">[</span>nop,nop,TS val 168042281 ecr 168042281], length 0
14:59:22.379626 IP localhost.62412 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>F.], <span class="nb">seq </span>1, ack 11, win 43, options <span class="o">[</span>nop,nop,TS val 168042281 ecr 168042281], length 0
14:59:22.382190 IP localhost.9490 <span class="o">&gt;</span> localhost.62412: Flags <span class="o">[</span>.], ack 2, win 43, options <span class="o">[</span>nop,nop,TS val 168042282 ecr 168042281], length 0
14:59:23.379808 IP localhost.9490 <span class="o">&gt;</span> localhost.62412: Flags <span class="o">[</span>P.], <span class="nb">seq </span>11:12, ack 2, win 43, options <span class="o">[</span>nop,nop,TS val 168042531 ecr 168042281], length 1
14:59:23.379829 IP localhost.62412 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>R], <span class="nb">seq </span>4127385762, win 0, length 0
</code></pre></div></div>

<p><em>上述 log 为实验过程中，和上面上面的代码略有出入。</em></p>

<p>可以观察到，client <code class="language-plaintext highlighter-rouge">close</code>(2)，发送了 <code class="language-plaintext highlighter-rouge">FIN</code> 给 server，并收到了 <code class="language-plaintext highlighter-rouge">ACK</code>。server 此时再次尝试 <code class="language-plaintext highlighter-rouge">write</code>(2)，便抛出了 <code class="language-plaintext highlighter-rouge">broken pipe</code> 异常。</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">try</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">server</span><span class="p">();</span>
    <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">Exception</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">e</span><span class="p">.</span><span class="n">what</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><em><code class="language-plaintext highlighter-rouge">server</code> 调用方式。</em></p>

<h3 id="sigpipe-与-broken-pipe">SIGPIPE 与 broken pipe</h3>

<p>按照预期，当 socket 抛出 <code class="language-plaintext highlighter-rouge">broken pipe</code> 时，会被最外层 <code class="language-plaintext highlighter-rouge">try</code> 和 <code class="language-plaintext highlighter-rouge">catch</code> 抓住，并输出。实际上运行结果为：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./server
<span class="nv">$ </span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$?</span>
141
<span class="nv">$ </span>
</code></pre></div></div>

<p><em>某次 server 端运行结果，没有任何输出，程序返回值为 $141$。</em></p>

<p>内核中 TCP 栈如果已经接收到 <code class="language-plaintext highlighter-rouge">RST</code>，那么下一次使用 <code class="language-plaintext highlighter-rouge">write</code>(2) 时，除了会返回 <code class="language-plaintext highlighter-rouge">broken pipe</code> 外，还会产生 <code class="language-plaintext highlighter-rouge">SIGPIPE</code>，默认情况下这个信号会终止整个进程，当然你并不想让进程被 <code class="language-plaintext highlighter-rouge">SIGPIPE</code> 信号杀死。对 server 来说，为了不被 <code class="language-plaintext highlighter-rouge">SIGPIPE</code> 信号杀死，那就需要忽略 <code class="language-plaintext highlighter-rouge">SIGPIPE</code> 信号：</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">signal</span><span class="p">(</span><span class="n">SIGPIPE</span><span class="p">,</span> <span class="n">SIG_IGN</span><span class="p">);</span>
</code></pre></div></div>

<p>最后，让我们整体分析下 <code class="language-plaintext highlighter-rouge">broken pipe</code> 产生方式：</p>

<ol>
  <li>client 发送了 <code class="language-plaintext highlighter-rouge">FIN</code> 给 server；</li>
  <li>server 仍给 client 发送数据，client 回复 <code class="language-plaintext highlighter-rouge">RST</code>；</li>
  <li>server 收到 <code class="language-plaintext highlighter-rouge">RST</code> 后，再次给 client 发送数据；往一个已经收到 <code class="language-plaintext highlighter-rouge">RST</code> 的 socket 继续写入数据，将引起 <code class="language-plaintext highlighter-rouge">SIGPIPE</code> 信号，<code class="language-plaintext highlighter-rouge">write</code>(2) 返回 <code class="language-plaintext highlighter-rouge">EPIPE</code>。</li>
</ol>

<h2 id="重现-connection-reset-by-peer">重现 <code class="language-plaintext highlighter-rouge">connection reset by peer</code></h2>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">server</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">Acceptor</span> <span class="n">acceptor</span> <span class="o">=</span> <span class="n">Socket</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">InetAddress</span> <span class="n">address</span> <span class="o">=</span> <span class="n">InetAddress</span><span class="o">::</span><span class="n">parseV4</span><span class="p">(</span><span class="s">"127.0.0.1"</span><span class="p">,</span> <span class="mi">9490</span><span class="p">);</span>
    <span class="n">acceptor</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">address</span><span class="p">);</span>
    <span class="n">acceptor</span><span class="p">.</span><span class="n">listen</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>

    <span class="k">while</span> <span class="p">(</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">Connection</span> <span class="n">conn</span> <span class="o">=</span> <span class="n">acceptor</span><span class="p">.</span><span class="n">accept</span><span class="p">();</span>
        <span class="n">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>                       <span class="c1">// 给拔网线留下足够的时间</span>
    <span class="p">}</span> <span class="c1">// RAII close conn socket</span>
<span class="p">}</span> <span class="c1">// RAII close acceptor socket</span>
</code></pre></div></div>

<p><em>模拟服务端断线重启。</em></p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">client</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">Connector</span> <span class="n">connector</span> <span class="o">=</span> <span class="n">Socket</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">InetAddress</span> <span class="n">address</span> <span class="o">=</span> <span class="n">InetAddress</span><span class="o">::</span><span class="n">parseV4</span><span class="p">(</span><span class="s">"127.0.0.1"</span><span class="p">,</span> <span class="mi">9490</span><span class="p">);</span>
    <span class="n">connector</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="n">address</span><span class="p">);</span>
    <span class="n">sleep</span><span class="p">(</span><span class="mi">120</span><span class="p">);</span> 

    <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">msg</span> <span class="o">=</span> <span class="s">"hello"</span><span class="p">;</span>
    <span class="n">connector</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">msg</span><span class="p">));</span>
<span class="p">}</span> <span class="c1">// RAII close connector socket</span>
</code></pre></div></div>

<p><em>一段时间后，再给服务器发送请求，此时服务器已经重启。</em></p>

<p>这里构造了这样一个场景，与客户端建立连接后，服务端由于不可抗力，比如断电，未能发送 <code class="language-plaintext highlighter-rouge">FIN</code> 给客户端。当服务器重启后，内核中 TCP 协议栈收到了客户端的数据包，回应 <code class="language-plaintext highlighter-rouge">RST</code>，此时客户端抛出 <code class="language-plaintext highlighter-rouge">connection reset by peer</code>。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> lo <span class="s1">'(src host 127.0.0.1) and (port 9490)'</span>  <span class="nt">-B</span> 4096
15:43:12.638464 IP localhost.21316 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>S], <span class="nb">seq </span>3640034867, win 43690, options <span class="o">[</span>mss 65495,sackOK,TS val 168699846 ecr 0,nop,wscale 10], length 0
15:43:12.638478 IP localhost.9490 <span class="o">&gt;</span> localhost.21316: Flags <span class="o">[</span>S.], <span class="nb">seq </span>485213568, ack 3640034868, win 43690, options <span class="o">[</span>mss 65495,sackOK,TS val 168699846 ecr 168699846,nop,wscale 10], length 0
15:43:16.639791 IP localhost.9490 <span class="o">&gt;</span> localhost.21316: Flags <span class="o">[</span>P.], <span class="nb">seq </span>5:6, ack 6, win 43, options <span class="o">[</span>nop,nop,TS val 168700846 ecr 168700596], length 1
15:43:16.639807 IP localhost.21316 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>.], ack 6, win 43, options <span class="o">[</span>nop,nop,TS val 168700846 ecr 168700846], length 0
15:43:17.640127 IP localhost.9490 <span class="o">&gt;</span> localhost.21316: Flags <span class="o">[</span>P.], <span class="nb">seq </span>6:7, ack 6, win 43, options <span class="o">[</span>nop,nop,TS val 168701096 ecr 168700846], length 1
15:43:17.640137 IP localhost.21316 <span class="o">&gt;</span> localhost.9490: Flags <span class="o">[</span>.], ack 7, win 43, options <span class="o">[</span>nop,nop,TS val 168701096 ecr 168701096], length 0
15:43:18.170130 IP localhost.9490 <span class="o">&gt;</span> localhost.21316: Flags <span class="o">[</span>R.], <span class="nb">seq </span>7, ack 6, win 43, options <span class="o">[</span>nop,nop,TS val 168701228 ecr 168701096], length 0
</code></pre></div></div>

<p><em>某次模拟 <code class="language-plaintext highlighter-rouge">connection reset by peer</code>。</em></p>

<hr />

<p>这里从读写两个角度来看 <code class="language-plaintext highlighter-rouge">RST</code>，如果已经 <code class="language-plaintext highlighter-rouge">ACK</code> 远端的 <code class="language-plaintext highlighter-rouge">FIN</code> 包：</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">read</code>(2) ：返回 0，表示 eof；</li>
  <li><code class="language-plaintext highlighter-rouge">write</code>(2) ：远端返回 <code class="language-plaintext highlighter-rouge">RST</code>，抛出 <code class="language-plaintext highlighter-rouge">broken pipe</code>；</li>
</ol>

<p>如果尚未接收到远端的 <code class="language-plaintext highlighter-rouge">FIN</code> 包，无论读写操作，收到 <code class="language-plaintext highlighter-rouge">RST</code> 时，抛出 <code class="language-plaintext highlighter-rouge">connection reset by peer</code>。</p>

<h2 id="what-more-">what more ？</h2>

<p>除了上述几个场景外，还有其他可能吗？</p>

<h3 id="强行关闭">强行关闭</h3>

<p>正常关闭 TCP 链接时，主动关闭一方会进入 <code class="language-plaintext highlighter-rouge">TIME_WAIT</code> 状态，等待 2MSL（报文段最大生存时间-Maximum Segment Lifetime，根据具体的实现不同，这个值会不同），此时该端口处于不可用状态。</p>

<p>解决 <code class="language-plaintext highlighter-rouge">TIME_WAIT</code> 有三种手段：</p>

<ol>
  <li>设置 <code class="language-plaintext highlighter-rouge">SO_REUSEADDR</code> 和 <code class="language-plaintext highlighter-rouge">SO_REUSEPORT</code>；</li>
  <li>修改 <code class="language-plaintext highlighter-rouge">TIME_WAIT</code> 等待时长；</li>
  <li>设置 <code class="language-plaintext highlighter-rouge">SO_LINGER</code>，强行关闭。</li>
</ol>

<p>设置 socket 选项 <code class="language-plaintext highlighter-rouge">SO_LINGER</code> 为 <code class="language-plaintext highlighter-rouge">(on, 0)</code> 后，<code class="language-plaintext highlighter-rouge">close</code>(2) 将立即向对端发送 <code class="language-plaintext highlighter-rouge">RST</code>，这种关闭方式称为“强行关闭”。而被动关闭方却不知道对端已经彻底断开，所以紧接着的读写操作，引发 <code class="language-plaintext highlighter-rouge">connection reset by peer</code>。</p>

<h3 id="数据滞留">数据滞留</h3>

<p>socket 关闭时，如果接收窗口仍有数据滞留，那么会直接发送 <code class="language-plaintext highlighter-rouge">RST</code> ，不会进入正常的 <code class="language-plaintext highlighter-rouge">FIN</code> 流程。可以参考：<a href="http://cs.ecs.baylor.edu/~donahoo/practical/CSockets/TCPRST.pdf">TCP RST: Calling close() on a socket with data in the receive queue</a>。</p>

<p>和“强行关闭”一样，数据滞留也会导致被动关闭方引发 <code class="language-plaintext highlighter-rouge">connection reset by peer</code>，这样造成的结果是：如果你的服务各种指标正常，但是有非常多的 <code class="language-plaintext highlighter-rouge">connection reset by peer</code> 警告，可能就是服务上游超时 <code class="language-plaintext highlighter-rouge">close</code>(2) socket，而由于接收窗口仍有数据滞留，发送了 <code class="language-plaintext highlighter-rouge">RST</code>。</p>

<h1 id="references">References</h1>

<p>[1] <a href="/2017/05/26/Linux-TCP-%E7%BC%96%E7%A8%8B/">Linux TCP 编程</a></p>

<p>[2] <a href="http://senlinzhan.github.io/2017/03/02/sigpipe/">网络编程中 SIGPIPE 信号</a></p>

<p>[3] <a href="http://xiangruix.com/2016/01/12/tcp-closed-without-fin/">Linux 下 TCP 连接断开未发送 FIN</a></p>

<p>[4] <a href="http://itindex.net/detail/56132-tcp-time-wait">TCP关闭连接(为什么会能Time_wait,Close_wait?)</a></p>]]></content><author><name></name></author><category term="Network" /><category term="Linux" /><category term="TCP/IP" /><category term="Socket" /><summary type="html"><![CDATA[注：本文结论来自网络，真实性未考究，请批判性阅读，如果谬误，请斧正。本文所讨论内容，均假设工作环境为 Linux 服务器。 作为 TCP 不可或缺的一部分，TCP 包头的 RST 为 $1$ 时，表示重置，关闭异常链接。发送 RST 包关闭连接时，不必等缓冲区的包都发出去，直接就丢弃缓存区的包发送 RST 包。而接收端收到 RST 包后，也不必发送 ACK 包来确认。TCP 处理程序会在自己认为的异常时刻发送 RST 包。 14:59:23.379829 IP localhost.62412 &gt; localhost.9490: Flags [R], seq 4127385762, win 0, length 0 通过 tcpdump 观察，Flags [R] 表示该包携带了 RST 。 RST 主要用在三种场景中，保证 TCP 链接的安全性，三种场景分别是：1、到不存在端口的连接请求；2、异常终止连接；3、检测半打开连接。接下来看看 RST 的具体表现。 三种错误 内核中的 TCP 协议栈将收到 RST 的场景分为三种，并抛出了对应的错误。 connection refused 当内核中的 TCP 协议栈收到了 SYN 请求，但是该端口上没有处于监听状态，则相应 RST，此时 client 看到的便是 connection refused。 broken pipe fd is connected to a pipe or socket whose reading end is closed. When this happens the writing process will also receive a SIGPIPE signal.(Thus, the write return value is seen only if the program catches, blocks or ignores this signal.) 简单的说，如果已知远端读通道已经被关闭，而应用程序仍然在调用 write(2) 尝试向 socket 中写入数据，TCP 协议栈便会抛出 broken pipe。 connection reset by peer A network connection was closed for reasons outside the control of the local host, such as by the remote machine rebooting or an unrecoverable protocol violation. 如果远端已经 close(2) 连接了，本地服务仍发送了数据，此时 TCP 协议栈便会抛出 connection reset by peer。 broken pipe 和 connection reset by peer 无论是 broken pipe 还是 connection reset by peer，都是收到 RST 的表现，二者有何不同呢？ 为了进一步研究，这里尝试着构建两个场景，分别重现 broken pipe 和 connection reset by peer。 重现 broken pipe 首先，在服务中监听端口，每个连接分多次写入数据，然后关闭连接。 int server() { Acceptor acceptor = Socket::create(AF_INET, SOCK_STREAM, 0); InetAddress address = InetAddress::parseV4("127.0.0.1", 9490); acceptor.bind(address); acceptor.listen(10); const char *msg1 = "hello", *msg2 = "world"; while (true) { Connection conn = acceptor.accept(); sleep(1); // wait client shutdown conn.write(msg1, strlen(msg1)); // write success, but RST recieved conn.write(msg2, strlen(msg2)); // throw `broken pipe` } // RAII close conn socket } // RAII close acceptor socket 然后客户端连接到服务端，并立即关闭连接。 int client() { Connector connector = Socket::create(AF_INET, SOCK_STREAM, 0); InetAddress address = InetAddress::parseV4("127.0.0.1", 9490); connector.connect(address); } // RAII close connector socket 通过 tcpdump 观察程序运行时请求： $ sudo tcpdump -i lo '(src host 127.0.0.1) and (port 9490)' -B 4096 14:59:13.376906 IP localhost.62412 &gt; localhost.9490: Flags [S], seq 4127385760, win 43690, options [mss 65495,sackOK,TS val 168040030 ecr 0,nop,wscale 10], length 0 14:59:13.376919 IP localhost.9490 &gt; localhost.62412: Flags [S.], seq 2306780414, ack 4127385761, win 43690, options [mss 65495,sackOK,TS val 168040030 ecr 168040030,nop,wscale 10], length 0 14:59:13.376928 IP localhost.62412 &gt; localhost.9490: Flags [.], ack 1, win 43, options [nop,nop,TS val 168040030 ecr 168040030], length 0 14:59:13.377089 IP localhost.9490 &gt; localhost.62412: Flags [P.], seq 1:2, ack 1, win 43, options [nop,nop,TS val 168040030 ecr 168040030], length 1 14:59:13.377223 IP localhost.62412 &gt; localhost.9490: Flags [.], ack 2, win 43, options [nop,nop,TS val 168040030 ecr 168040030], length 0 14:59:14.377352 IP localhost.9490 &gt; localhost.62412: Flags [P.], seq 2:3, ack 1, win 43, options [nop,nop,TS val 168040280 ecr 168040030], length 1 14:59:14.377439 IP localhost.62412 &gt; localhost.9490: Flags [.], ack 3, win 43, options [nop,nop,TS val 168040280 ecr 168040280], length 0 // .... 14:59:22.379462 IP localhost.9490 &gt; localhost.62412: Flags [P.], seq 10:11, ack 1, win 43, options [nop,nop,TS val 168042281 ecr 168042031], length 1 14:59:22.379489 IP localhost.62412 &gt; localhost.9490: Flags [.], ack 11, win 43, options [nop,nop,TS val 168042281 ecr 168042281], length 0 14:59:22.379626 IP localhost.62412 &gt; localhost.9490: Flags [F.], seq 1, ack 11, win 43, options [nop,nop,TS val 168042281 ecr 168042281], length 0 14:59:22.382190 IP localhost.9490 &gt; localhost.62412: Flags [.], ack 2, win 43, options [nop,nop,TS val 168042282 ecr 168042281], length 0 14:59:23.379808 IP localhost.9490 &gt; localhost.62412: Flags [P.], seq 11:12, ack 2, win 43, options [nop,nop,TS val 168042531 ecr 168042281], length 1 14:59:23.379829 IP localhost.62412 &gt; localhost.9490: Flags [R], seq 4127385762, win 0, length 0 上述 log 为实验过程中，和上面上面的代码略有出入。 可以观察到，client close(2)，发送了 FIN 给 server，并收到了 ACK。server 此时再次尝试 write(2)，便抛出了 broken pipe 异常。 int main(int argc, char** argv) { try { return server(); } catch (Exception&amp; e) { cout &lt;&lt; e.what() &lt;&lt; endl; return -1; } } server 调用方式。 SIGPIPE 与 broken pipe 按照预期，当 socket 抛出 broken pipe 时，会被最外层 try 和 catch 抓住，并输出。实际上运行结果为： $ ./server $ $ echo $? 141 $ 某次 server 端运行结果，没有任何输出，程序返回值为 $141$。 内核中 TCP 栈如果已经接收到 RST，那么下一次使用 write(2) 时，除了会返回 broken pipe 外，还会产生 SIGPIPE，默认情况下这个信号会终止整个进程，当然你并不想让进程被 SIGPIPE 信号杀死。对 server 来说，为了不被 SIGPIPE 信号杀死，那就需要忽略 SIGPIPE 信号： signal(SIGPIPE, SIG_IGN); 最后，让我们整体分析下 broken pipe 产生方式： client 发送了 FIN 给 server； server 仍给 client 发送数据，client 回复 RST； server 收到 RST 后，再次给 client 发送数据；往一个已经收到 RST 的 socket 继续写入数据，将引起 SIGPIPE 信号，write(2) 返回 EPIPE。 重现 connection reset by peer int server() { Acceptor acceptor = Socket::create(AF_INET, SOCK_STREAM, 0); InetAddress address = InetAddress::parseV4("127.0.0.1", 9490); acceptor.bind(address); acceptor.listen(10); while (true) { Connection conn = acceptor.accept(); sleep(10); // 给拔网线留下足够的时间 } // RAII close conn socket } // RAII close acceptor socket 模拟服务端断线重启。 int client() { Connector connector = Socket::create(AF_INET, SOCK_STREAM, 0); InetAddress address = InetAddress::parseV4("127.0.0.1", 9490); connector.connect(address); sleep(120); const char *msg = "hello"; connector.write(msg, strlen(msg)); } // RAII close connector socket 一段时间后，再给服务器发送请求，此时服务器已经重启。 这里构造了这样一个场景，与客户端建立连接后，服务端由于不可抗力，比如断电，未能发送 FIN 给客户端。当服务器重启后，内核中 TCP 协议栈收到了客户端的数据包，回应 RST，此时客户端抛出 connection reset by peer。 $ sudo tcpdump -i lo '(src host 127.0.0.1) and (port 9490)' -B 4096 15:43:12.638464 IP localhost.21316 &gt; localhost.9490: Flags [S], seq 3640034867, win 43690, options [mss 65495,sackOK,TS val 168699846 ecr 0,nop,wscale 10], length 0 15:43:12.638478 IP localhost.9490 &gt; localhost.21316: Flags [S.], seq 485213568, ack 3640034868, win 43690, options [mss 65495,sackOK,TS val 168699846 ecr 168699846,nop,wscale 10], length 0 15:43:16.639791 IP localhost.9490 &gt; localhost.21316: Flags [P.], seq 5:6, ack 6, win 43, options [nop,nop,TS val 168700846 ecr 168700596], length 1 15:43:16.639807 IP localhost.21316 &gt; localhost.9490: Flags [.], ack 6, win 43, options [nop,nop,TS val 168700846 ecr 168700846], length 0 15:43:17.640127 IP localhost.9490 &gt; localhost.21316: Flags [P.], seq 6:7, ack 6, win 43, options [nop,nop,TS val 168701096 ecr 168700846], length 1 15:43:17.640137 IP localhost.21316 &gt; localhost.9490: Flags [.], ack 7, win 43, options [nop,nop,TS val 168701096 ecr 168701096], length 0 15:43:18.170130 IP localhost.9490 &gt; localhost.21316: Flags [R.], seq 7, ack 6, win 43, options [nop,nop,TS val 168701228 ecr 168701096], length 0 某次模拟 connection reset by peer。 这里从读写两个角度来看 RST，如果已经 ACK 远端的 FIN 包： read(2) ：返回 0，表示 eof； write(2) ：远端返回 RST，抛出 broken pipe； 如果尚未接收到远端的 FIN 包，无论读写操作，收到 RST 时，抛出 connection reset by peer。 what more ？ 除了上述几个场景外，还有其他可能吗？ 强行关闭 正常关闭 TCP 链接时，主动关闭一方会进入 TIME_WAIT 状态，等待 2MSL（报文段最大生存时间-Maximum Segment Lifetime，根据具体的实现不同，这个值会不同），此时该端口处于不可用状态。 解决 TIME_WAIT 有三种手段： 设置 SO_REUSEADDR 和 SO_REUSEPORT； 修改 TIME_WAIT 等待时长； 设置 SO_LINGER，强行关闭。 设置 socket 选项 SO_LINGER 为 (on, 0) 后，close(2) 将立即向对端发送 RST，这种关闭方式称为“强行关闭”。而被动关闭方却不知道对端已经彻底断开，所以紧接着的读写操作，引发 connection reset by peer。 数据滞留 socket 关闭时，如果接收窗口仍有数据滞留，那么会直接发送 RST ，不会进入正常的 FIN 流程。可以参考：TCP RST: Calling close() on a socket with data in the receive queue。 和“强行关闭”一样，数据滞留也会导致被动关闭方引发 connection reset by peer，这样造成的结果是：如果你的服务各种指标正常，但是有非常多的 connection reset by peer 警告，可能就是服务上游超时 close(2) socket，而由于接收窗口仍有数据滞留，发送了 RST。 References [1] Linux TCP 编程 [2] 网络编程中 SIGPIPE 信号 [3] Linux 下 TCP 连接断开未发送 FIN [4] TCP关闭连接(为什么会能Time_wait,Close_wait?)]]></summary></entry><entry><title type="html">nsq read notes</title><link href="/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/2019/01/03/nsq-read-notes.html" rel="alternate" type="text/html" title="nsq read notes" /><published>2019-01-03T08:00:00+08:00</published><updated>2019-01-03T08:00:00+08:00</updated><id>/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/2019/01/03/nsq-read-notes</id><content type="html" xml:base="/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/2019/01/03/nsq-read-notes.html"><![CDATA[<h1 id="nsqd">nsqd</h1>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">topicMap</span> <span class="k">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="o">*</span><span class="n">Topic</span>
<span class="n">clientMap</span> <span class="k">map</span><span class="p">[</span><span class="n">id</span><span class="p">]</span><span class="o">*</span><span class="n">Client</span>
</code></pre></div></div>

<h2 id="初始化过程">初始化过程</h2>

<ol>
  <li>new</li>
  <li>load meta data</li>
  <li>persist meta data</li>
  <li>main
    <ol>
      <li>listen tcp &amp; http port, start server</li>
      <li>start queueScanLoop, lookupLoop, statsLoop</li>
    </ol>
  </li>
</ol>

<p>有新连接到达时，会生成 connection 的 client，保存到 nsqd 的 clientMap 中，同时启动 goroutine 负责 client 的 messagePump。conn 所在的 goroutine 之后会负责读客户端的命令，并执行以及返回结果。可执行命令如下：</p>

<ol>
  <li>IDENTIFY: 表名身份</li>
  <li>FIN: 在 client 绑定的 channel 上，完成一条消息（调用 channel.FinishMessage），同时会更新当前 client 的 metrics 信息，以及状态</li>
  <li>RDY: 更新 client ready count</li>
  <li>REQ: 在 client 绑定的 channel 上，把一条消息重新送入队列（调用 channel.RequeueMessage），同时更新 metrics 和状态。这条消息会被放入 defered 队列，延后执行</li>
  <li>PUB: 往某个 client 有权限的 topic 发送一条消息（调用 topic.PutMessage），更新 metrics 状态</li>
  <li>MPUB: 和 PUB 一样，不过接收多条消息</li>
  <li>DPUB: 和 PUB 一样，不过会被放入 defered 队列</li>
  <li>NOP: 最简单，啥也不干</li>
  <li>TOUCH: 在 client 绑定的 channel 上，重置一条消息的过期时间（调用 channel.TouchMessage)</li>
  <li>SUB: 将 client 绑定到 channel 上，如果 topic 和 channel 任一个属于 “”, 且 topic 或 channel 正在关闭， client 会不断重试绑定操作。</li>
  <li>CLS: 关闭连接</li>
  <li>AUTH: 授权</li>
</ol>

<p>client 有多种状态：init, disconnect, connect, subscribe, closing ，状态迁移由一系列命令执行顺序决定。除此外还有 ready 状态，client 通过 RDY 更新了自己的 ready count，表示 client 最多同时处理多少条消息，如果 inflight count &gt;= ready count，则未 ready，需要等待。</p>

<p>client 使用 SUB 进入 subscribe 模式，该模式只能进入一次，进入后 messagePumb 会接收到 subEvent，然后从对应 channel 中读取 message 发送到 client 里。</p>

<h2 id="topic">topic</h2>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">messageChan</span> <span class="k">chan</span> <span class="o">*</span><span class="n">Message</span>
<span class="n">backendChan</span> <span class="n">BackendChan</span>
<span class="n">channelsMap</span> <span class="k">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="n">Channels</span>
</code></pre></div></div>

<h3 id="topic-创建流程">topic 创建流程</h3>

<ol>
  <li>new topic, save to topicMap</li>
  <li>lookup each lookupd, get all channels in topic $TOPIC</li>
  <li>skip “#ephemeral” and create channels</li>
  <li>start topic messagePump</li>
</ol>

<h3 id="delete-channel">delete channel</h3>

<ol>
  <li>remove from topic channelsMap</li>
  <li>mark channel deleted</li>
  <li>if left channels is zero, and topic is ephemeral, delete topic self</li>
</ol>

<h3 id="put-messages">put messages</h3>

<ol>
  <li>try put message into memory message channel</li>
  <li>fallthrough into backend queue, most case into disk, but ephemeral just ignore</li>
  <li>update message count</li>
</ol>

<h3 id="message-pump">message pump</h3>

<ol>
  <li>read message from memory message channel</li>
  <li>else read from backend message</li>
  <li>else update channel status</li>
  <li>copy memory into each channels in current topic
    <ol>
      <li>if message is defered, put into channels defered</li>
      <li>else put into normal channels</li>
    </ol>
  </li>
</ol>

<h2 id="channel">channel</h2>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clients</span> <span class="k">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="n">Consumer</span>
<span class="n">backend</span> <span class="n">BackendQueue</span>
<span class="n">memoryChan</span> <span class="k">chan</span> <span class="o">*</span><span class="n">Message</span>
<span class="n">deferedMessages</span> <span class="k">map</span><span class="p">[</span><span class="n">MessageID</span><span class="p">]</span><span class="o">*</span><span class="n">Message</span>
<span class="n">defredPQ</span> <span class="n">PriorityQueue</span>
<span class="n">inFlightMessages</span> <span class="k">map</span><span class="p">[</span><span class="n">MessageID</span><span class="p">]</span><span class="o">*</span><span class="n">Message</span>
<span class="n">inFlightPQ</span> <span class="n">PriorityQueue</span>
</code></pre></div></div>

<p>channel put message 和 topic put message 类似。put defered message 会把 message 放在deferedMessages 中，并加入 deferedPQ 中。如果 defered 时间到了，使用正常流程 put。clients 提供了 Add 和 Remove 接口，但管理职责不是 channel 的。</p>

<h1 id="nsqlookupd">nsqlookupd</h1>

<h2 id="nsqlookupd-数据组织方式">nsqlookupd 数据组织方式</h2>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
	<span class="p">{</span><span class="s">"client"</span><span class="p">,</span> <span class="s">""</span><span class="p">,</span> <span class="s">""</span><span class="p">}</span> <span class="o">=&gt;</span> <span class="p">{</span>
		<span class="s">"127.0.0.1:9490"</span> <span class="o">=&gt;</span> <span class="n">Producer</span><span class="p">{</span><span class="s">"127.0.0.1:8081"</span><span class="p">},</span>
		<span class="s">"127.0.0.1:9491"</span> <span class="o">=&gt;</span> <span class="n">Producer</span><span class="p">{</span><span class="s">"127.0.0.1:8081"</span><span class="p">},</span>
	<span class="p">},</span>

	<span class="p">{</span><span class="s">"channel"</span><span class="p">,</span> <span class="s">"topic_a"</span><span class="p">,</span> <span class="s">"channel_a"</span><span class="p">}</span> <span class="o">=&gt;</span> <span class="p">{</span>
		<span class="s">"ip1"</span> <span class="o">=&gt;</span> <span class="n">Producer</span><span class="p">{</span><span class="s">"addr"</span><span class="p">},</span>
	<span class="p">},</span>
	<span class="p">{</span><span class="s">"topic"</span><span class="p">,</span> <span class="s">"topic_a"</span><span class="p">,</span> <span class="s">""</span><span class="p">}</span> <span class="o">=&gt;</span> <span class="p">{</span>
		<span class="s">"ip1"</span> <span class="o">=&gt;</span> <span class="n">Producer</span><span class="p">{</span><span class="s">"addr_1"</span><span class="p">},</span>
		<span class="s">"ip2"</span> <span class="o">=&gt;</span> <span class="n">Producer</span><span class="p">{</span><span class="s">"addr2"</span><span class="p">},</span>
	<span class="p">},</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="nsqd---nsqlookupd-交互">nsqd &lt;-&gt; nsqlookupd 交互</h2>

<ol>
  <li>connect: send “  V1”</li>
  <li>ping: send “PING “
    <ol>
      <li>nsqlookupd update peer info’s lastUpdate</li>
      <li>response “OK”</li>
    </ol>
  </li>
  <li>identify: send “IDENTIFY LEN(data) data”
    <ol>
      <li>remote addr as id</li>
      <li>load broadcase address, tcp port, http port, version</li>
      <li>update peer info’s lastUpdate</li>
      <li>add producer to db: Registration{“client”} =&gt; PeerInfo{id}</li>
      <li>response {tcp_port, http_port, version, hostname, broadcast_address}</li>
    </ol>
  </li>
  <li>register: send “REGISTER TOPIC [CHANNEL]”
    <ol>
      <li>read topic and channel name</li>
      <li>if channel name exists:
        <ol>
          <li>add producer to db: Registration{“channel”, $TOPIC, $CHANNEL} =&gt; PeerInfo{id}</li>
        </ol>
      </li>
      <li>add producer to db: Registration{“topic”, $TOPIC, “”} =&gt; PeerInfo{id}</li>
      <li>response “OK”</li>
    </ol>
  </li>
  <li>unregister: send “UNREGISTER TOPIC [CHANNEL]”
    <ol>
      <li>read topic and channel name</li>
      <li>if channel name exists:
        <ol>
          <li>remove producer from db: Registration{“channel”, $TOPIC, $CHANNEL}</li>
          <li>remove registration for channel has suffix “#ephemeral” if left producer is zero</li>
        </ol>
      </li>
      <li>else:
        <ol>
          <li>find all registrations of channel of $TOPIC</li>
          <li>remove all channels of current peer</li>
          <li>remove producer form db: Registration{“topic”, $TOPIC, “”}</li>
        </ol>
      </li>
      <li>response “OK”</li>
    </ol>
  </li>
</ol>

<h2 id="nsqlookupd-support-http-request">nsqlookupd support http request</h2>

<ol>
  <li>GET /lookup?topic=topic_name
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
 </span><span class="nl">"channels"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"channel1"</span><span class="p">],</span><span class="w">
 </span><span class="nl">"producers"</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="w">

 </span><span class="p">}],</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li>GET /topics</li>
  <li>GET /channels?topic=topic_name</li>
  <li>GET /nodes</li>
  <li>POST /topic/create?topic=</li>
  <li>POST /topic/delete?topic=</li>
  <li>POST /channel/create?topic=topic&amp;channel=channel</li>
  <li>POST /channel/delete?topic=&amp;channel=</li>
  <li>POST /topic/tombstone?topic=topic_name&amp;node=node_id</li>
</ol>]]></content><author><name></name></author><category term="消息中间件" /><category term="Nsq," /><category term="MessageQueue" /><summary type="html"><![CDATA[nsqd topicMap map[string]*Topic clientMap map[id]*Client 初始化过程 new load meta data persist meta data main listen tcp &amp; http port, start server start queueScanLoop, lookupLoop, statsLoop 有新连接到达时，会生成 connection 的 client，保存到 nsqd 的 clientMap 中，同时启动 goroutine 负责 client 的 messagePump。conn 所在的 goroutine 之后会负责读客户端的命令，并执行以及返回结果。可执行命令如下： IDENTIFY: 表名身份 FIN: 在 client 绑定的 channel 上，完成一条消息（调用 channel.FinishMessage），同时会更新当前 client 的 metrics 信息，以及状态 RDY: 更新 client ready count REQ: 在 client 绑定的 channel 上，把一条消息重新送入队列（调用 channel.RequeueMessage），同时更新 metrics 和状态。这条消息会被放入 defered 队列，延后执行 PUB: 往某个 client 有权限的 topic 发送一条消息（调用 topic.PutMessage），更新 metrics 状态 MPUB: 和 PUB 一样，不过接收多条消息 DPUB: 和 PUB 一样，不过会被放入 defered 队列 NOP: 最简单，啥也不干 TOUCH: 在 client 绑定的 channel 上，重置一条消息的过期时间（调用 channel.TouchMessage) SUB: 将 client 绑定到 channel 上，如果 topic 和 channel 任一个属于 “”, 且 topic 或 channel 正在关闭， client 会不断重试绑定操作。 CLS: 关闭连接 AUTH: 授权 client 有多种状态：init, disconnect, connect, subscribe, closing ，状态迁移由一系列命令执行顺序决定。除此外还有 ready 状态，client 通过 RDY 更新了自己的 ready count，表示 client 最多同时处理多少条消息，如果 inflight count &gt;= ready count，则未 ready，需要等待。 client 使用 SUB 进入 subscribe 模式，该模式只能进入一次，进入后 messagePumb 会接收到 subEvent，然后从对应 channel 中读取 message 发送到 client 里。 topic messageChan chan *Message backendChan BackendChan channelsMap map[string]Channels topic 创建流程 new topic, save to topicMap lookup each lookupd, get all channels in topic $TOPIC skip “#ephemeral” and create channels start topic messagePump delete channel remove from topic channelsMap mark channel deleted if left channels is zero, and topic is ephemeral, delete topic self put messages try put message into memory message channel fallthrough into backend queue, most case into disk, but ephemeral just ignore update message count message pump read message from memory message channel else read from backend message else update channel status copy memory into each channels in current topic if message is defered, put into channels defered else put into normal channels channel clients map[string]Consumer backend BackendQueue memoryChan chan *Message deferedMessages map[MessageID]*Message defredPQ PriorityQueue inFlightMessages map[MessageID]*Message inFlightPQ PriorityQueue channel put message 和 topic put message 类似。put defered message 会把 message 放在deferedMessages 中，并加入 deferedPQ 中。如果 defered 时间到了，使用正常流程 put。clients 提供了 Add 和 Remove 接口，但管理职责不是 channel 的。 nsqlookupd nsqlookupd 数据组织方式 { {"client", "", ""} =&gt; { "127.0.0.1:9490" =&gt; Producer{"127.0.0.1:8081"}, "127.0.0.1:9491" =&gt; Producer{"127.0.0.1:8081"}, }, {"channel", "topic_a", "channel_a"} =&gt; { "ip1" =&gt; Producer{"addr"}, }, {"topic", "topic_a", ""} =&gt; { "ip1" =&gt; Producer{"addr_1"}, "ip2" =&gt; Producer{"addr2"}, }, } nsqd &lt;-&gt; nsqlookupd 交互 connect: send “ V1” ping: send “PING “ nsqlookupd update peer info’s lastUpdate response “OK” identify: send “IDENTIFY LEN(data) data” remote addr as id load broadcase address, tcp port, http port, version update peer info’s lastUpdate add producer to db: Registration{“client”} =&gt; PeerInfo{id} response {tcp_port, http_port, version, hostname, broadcast_address} register: send “REGISTER TOPIC [CHANNEL]” read topic and channel name if channel name exists: add producer to db: Registration{“channel”, $TOPIC, $CHANNEL} =&gt; PeerInfo{id} add producer to db: Registration{“topic”, $TOPIC, “”} =&gt; PeerInfo{id} response “OK” unregister: send “UNREGISTER TOPIC [CHANNEL]” read topic and channel name if channel name exists: remove producer from db: Registration{“channel”, $TOPIC, $CHANNEL} remove registration for channel has suffix “#ephemeral” if left producer is zero else: find all registrations of channel of $TOPIC remove all channels of current peer remove producer form db: Registration{“topic”, $TOPIC, “”} response “OK” nsqlookupd support http request GET /lookup?topic=topic_name { "channels": ["channel1"], "producers": [{ }], } GET /topics GET /channels?topic=topic_name GET /nodes POST /topic/create?topic= POST /topic/delete?topic= POST /channel/create?topic=topic&amp;channel=channel POST /channel/delete?topic=&amp;channel= POST /topic/tombstone?topic=topic_name&amp;node=node_id]]></summary></entry></feed>